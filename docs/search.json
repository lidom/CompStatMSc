[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Statistics (M.Sc.)",
    "section": "",
    "text": "Day \n    Time \n    Lecture Hall \n  \n \n\n  \n    Monday \n    12:15-13:45 \n    Jur / Hörsaal K \n  \n  \n    Thursday \n    14:15-15:45 \n    Jur / RS 0.017 \n  \n\n\n\n\n\n\n\n\n\n\nOnline resources (datasets, etc.) for the book can be found HERE.\neWhiteboard for the lecture notes.\nThis online script\n\nThe above links to the lecture materials can also be found at eCampus\n\n\n\n\nYou can use the Zulip-Chat CompStat (M.Sc.) to post questions, share codes, etc. Happy sharing and discussing!"
  },
  {
    "objectID": "Ch1_Stochastic_Simulation.html",
    "href": "Ch1_Stochastic_Simulation.html",
    "title": "2  Random Variable Generation",
    "section": "",
    "text": "Main:\n\nMonte Carlo Statistical Methods, Robert, C., and Casella, G., Ch. 2\n\nFurther:\n\nNon-Uniform Random Variate Generation, Devroye, L.\nNonparametric Density Estimation: The L1 View, Devroye, L., Ch. 8\nMonte Carlo and Quasi-Monte Carlo Sampling, Lemieux, C., Ch. 2 and 3"
  },
  {
    "objectID": "Ch1_Stochastic_Simulation.html#uniform-simulation",
    "href": "Ch1_Stochastic_Simulation.html#uniform-simulation",
    "title": "2  Random Variable Generation",
    "section": "2.1 Uniform Simulation",
    "text": "2.1 Uniform Simulation\nGeneral procedure:\n\nUsually, a random integer with values uniformly in \\([0,m]\\) with a large integer \\(m\\) is generated.\nTo achieve a random number in \\([0, 1]\\), we divide this number by \\(m\\).\nFrom this (pseudo) uniform random numbers we can generate random numbers of almost any other distribution.\n\nThere are many different Random Number Generators (RNGs), we consider the most simple class of RNGs:\n\nLinear Congruential Generators\n\nHere the \\(i\\)th random integer \\(u_i\\) is generated by \\[u_i=(a u_{i-1}+c) \\,\\mathrm{mod}\\, m,\\]\nwhere \\(u_0\\) is chosen fixed and called seed. Further “\\(b\\,\\mathrm{mod}\\,c\\)” denotes the remainder of the division of \\(b\\) by \\(c\\), and:\n\n\\(m\\), with \\(0<m\\), is called the “modulus”,\n\\(a\\), with \\(0<a<m\\), is called the “multiplier”,\n\\(c\\), with \\(0\\leq c<m\\), is called the “increment”.\n\n\n\n\n\nSome Facts:\n\nThe above recursion generates a completely nonrandom sequence, therefore it is usually called a pseudo random sequence.\nUnder appropriate choices of \\(u_0\\) , \\(a\\) and \\(m\\) the generated (deterministic) sequence behaves like a sequence of independent random draws from a uniform distribution on \\([0, m]\\).\nThe cycle length of linear congruential generators will never exceed modulus \\(m\\), but can maximized with the three following conditions (see Knuth (2002) for a proof):\n\nThe increment \\(c\\) is relatively prime to \\(m\\),\n\\(a - 1\\) is a multiple of every prime dividing \\(m\\),\n\\(a - 1\\) is a multiple of \\(4\\) when \\(m\\) is a multiple of \\(4\\).\n\n\n\n\n\nThe modulo operator: \\(\\mathrm{mod}\\)\n\n# Modulo computation using the modulo operator '%%'\n5 %% 4\n9 %% 4\n\n4 %% 5\n\n# own modulo-function:\nmy_mod <- function(x,m){\n  t1 <- floor(x/m)\n  return(x-t1*m)\n}\n\n\n\nBad choice of parameters for the linear congruential random number generator:\n\nm <- 64    # modulus\na <- 33    # multiplier\nc <- 12    # increment\ns <- 57    # seed\nn <- 1000  # length of run (including seed)\nr_vec    <- numeric(n) # initialize vector\nr_vec[1] <- s # set seed\nfor (i in 1:(n-1)){\n r_vec[i+1] <- (a * r_vec[i] + c) %% m\n}\n# scale between [0,1]:\nbad_runif_vec <- r_vec/m\n\n# BUT! Very short cycle-length (here: period=16)\nr_vec[ 1:16]\n\n [1] 57 37 17 61 41 21  1 45 25  5 49 29  9 53 33 13\n\nr_vec[17:32]\n\n [1] 57 37 17 61 41 21  1 45 25  5 49 29  9 53 33 13\n\n\n\n\nExample: Average heads ratios for \\(n\\) simulated tosses of a fair coin with \\(n=1,2,\\dots\\). By the (strong or weak) law of large numbers this average should converge stochastically to \\(0.5\\) as \\(n\\) becomes large.\n\n# using the above bad RNG:\nbar_x_bad  <- cumsum(bad_runif_vec > 0.5)/(1:n)\n# using R's high-quality RNG:\nset.seed(223)\nbar_x_good <- cumsum(runif(n)  > 0.5 )/(1:n)\n# plotting the results:\nplot(bar_x_bad, type=\"l\", ylim=c(0.46,0.54), \n     xlab=\"\", ylab=\"\", main=\"Good vs. Bad RNG\")\nlines(bar_x_good, col=\"darkblue\")\n\n\n\n\n\n\n\n\n\nSee also:\n\nIBM’s RANDU is a famous example of an miss-specified linear congruential RNG."
  },
  {
    "objectID": "Ch1_Stochastic_Simulation.html#generation-of-discrete-random-variables",
    "href": "Ch1_Stochastic_Simulation.html#generation-of-discrete-random-variables",
    "title": "2  Random Variable Generation",
    "section": "2.2 Generation of Discrete Random Variables",
    "text": "2.2 Generation of Discrete Random Variables\nAssume that you have a realization \\(u\\) from a uniform distribution on \\([0, 1]\\) available.\nAssume the discrete variable \\(X\\) of interest takes on the values \\(\\{x_1, \\dots , x_k \\}\\) with \\[p_i = \\mathbb{P}(X = x_i ), \\quad i = 1,\\dots , k\\quad\\text{and}\\quad \\sum_{i=1}^kp_i = 1.\\]\nIdea:\n\nSubdivide \\([0, 1]\\) into \\(k\\) intervals with \\[I_i = (F_{i-1}, F_i],\\quad\\text{where}\\quad F_i = p_1 + \\dots p_i\\quad\\text{and}\\quad F_0 = 0.\\]\nDefine the new discrete realizations \\[x=\\left\\{\n\\begin{array}{l}\n       x_1\\quad\\text{if}\\quad u\\in I_1\\\\\n       \\quad \\vdots \\\\\n       x_k\\quad\\text{if}\\quad u\\in I_k\n       \\end{array}\\right.\\]\n\n\nLemma\n\nLet \\(u\\) be a realization from \\(U[0, 1]\\) and if \\(u\\in I_i\\), set \\(x = x_i\\).\nThen \\(x\\) is an observation from the discrete distribution of \\(X\\).\n\n\nProof: Done in the lecture.\n\n\n\n\nExample: Bernoulli Distribution\n\\[X\\sim\\mathrm{Bernoulli}(p)\\quad\\text{if}\\quad\\mathbb{P}(X=1)=p\\quad\\text{and}\\quad\\mathbb{P}(X=0)=1-p.\\]\nIf \\(U\\leq p\\) define \\(X=1\\) otherwise \\(X=0\\). Then \\(X\\sim\\mathrm{Bernoulli}(p)\\).\n\n\nExample: Binomial Distribution\n\\[X\\sim\\mathrm{Binomial}(n,p)\\quad\\text{if}\\quad\\mathbb{P}(X=i)=\\binom{n}{i}p^i(1-p)^{n-1}\\quad i=1,\\dots,n.\\]\nNote: If \\(X_i\\sim\\mathrm{Bernoulli}(p)\\) i.i.d., then \\(X=\\sum_{i=1}^nX_i \\sim\\mathrm{Binomial}(n,p)\\).\nTherefore if \\(U_1,\\dots,U_n\\sim U[0,1]\\), then\n\\[X=\\sum_{i=1}^n 1_{(U_i\\leq p)}\\sim\\mathrm{Binomial}(n,p),\\] where \\(1_{(.)}\\) is the indicator function with \\(1_{(\\mathtt{TRUE})}=1\\) and zero else."
  },
  {
    "objectID": "Ch1_Stochastic_Simulation.html#generation-of-continuous-random-variables",
    "href": "Ch1_Stochastic_Simulation.html#generation-of-continuous-random-variables",
    "title": "2  Random Variable Generation",
    "section": "2.3 Generation of Continuous Random Variables",
    "text": "2.3 Generation of Continuous Random Variables\n\n2.3.1 The Inverse Method\nA very general method to generate continuous random variables is the so-called Inverse Method which builds upon the following important Lemma.\n\nLemma (Probability Integral Transform):\n\nIf \\(X\\) is a continuous random variable with distribution function \\(F(.)\\) and inverse \\(F^{-1}(.)\\), then \\[U=F(X)\\sim U[0, 1].\\] Therefore, if \\[X=F^{-1}(U),\\quad\\text{then}\\quad X\\sim F.\\]\n\n\nProof: Done in the lecture.\n\n\nExample: Exponential Distribution\nSince \\(F(x)= 1 - \\exp(-\\lambda x)\\), we have \\(F^{-1}(u) = - \\frac{log(1-u)}{\\lambda}\\).\nNote that \\(1-U\\) has the same distribution as \\(U\\), if \\(U\\sim U[0,1]\\).\nTherefore \\(-\\frac{\\log(u)}{\\lambda}\\) leads to a value from \\(\\mathrm{Exp}(\\lambda)\\).\n\n\nPROs & CONs:\n\nThe Inverse Method is a good & general way to think about things.\n\nThough, in practice, we often use other methods, since the inverse of many cdfs cannot be derived explicitly.\nFor instance: * Even the cdf \\(\\Phi(.)\\) (and therefore also its inverse \\(\\Phi^{-1}(.)\\)) of the normal density is not available in explicit terms. * For discontinuous RVs we need efficient algorithms for computing the generalized inverse of the cdf \\(F(.)\\).\n\n\n\n\n\n2.3.2 Transformation Methods\n\n\nIdea: Construct algorithms from theoretical links between distributions.\nPro: These methods can be advantageous if a distribution \\(f\\) is linked (in a relatively simple way) to another distribution that is easy to simulate.\nCon: Generally, these methods are rather case-specific, and difficult to generalize.\n\n\nExample: Building on Exponential RVs We already learned to generate an exponential RV starting from a uniform. In the following we generate RVs starting from an exponential distribution:\nIf the \\(X_i\\)s (and \\(X_j\\)s) are i.i.d. \\(\\mathrm{Exp}(1)\\) RVs, then\n\\[Y\\sim \\chi^2_{2\\nu}\\quad\\text{if}       \\quad Y= 2     \\sum_{i=1}^\\nu X_i,\\quad\\nu=1,2,\\dots \\] \\[Y\\sim \\Gamma(\\alpha,\\beta)\\quad\\text{if}\\quad Y= \\beta \\sum_{i=1}^\\alpha X_i,\\quad \\alpha=1,2,\\dots \\] \\[Y\\sim \\mathrm{Beta}(a,b)\\quad\\text{if}  \\quad Y= \\frac{\\sum_{i=1}^a X_i}{\\sum_{j=1}^{a+b} X_j},\\quad a,b=1,2,\\dots \\]\nSome Limitations:\n\nThere are more efficient algorithms to generate Gamma and Beta RVs.\nWe cannot use exponential RVs to generate Gamma RVs with a non-integer shape parameter \\(\\alpha\\). * This implies that we cannot generate a \\(\\chi^2_{1}\\) RV, which would, in turn, get us a \\(N(0,1)\\) RV. (Reminder: \\(\\chi^2_{1}\\) is identical to \\(\\Gamma(1/2, 2)\\).)\nFor that we look at the Box-Muller Theorem (1958) and the derived algorithm.\n\n\n\n\n\nExample: Normal Variable Generation\nThe well-known Box-Muller algorithm for generating (standard) normal RV is based on the following theorem:\n\nTheorem (Box and Muller, 1958)\n\nIf \\(U_1\\) and \\(U_2\\) are i.i.d. \\(U[0,1]\\), then \\[X_1 =\\sqrt{-2 \\log(U_1)}\\, \\cos(2\\pi U_2)\\quad\\text{and}\\quad X_2=\\sqrt{-2\\log(U_1)}\\,\\sin(2\\pi U_2)\\] are i.i.d. \\(N(0,1)\\).\n\n\nIdea & Proof: Done in the lecture.\n\n\nImplementation of the Box-Muller algorithm:\n\n# Implementation:\nBM_Algo <- function(){\n  # 1. Step: Generate U_1, U_2 iid U[0,1]\n  U <- runif(2)\n  # 2. Step: Transformation\n  X1 <- sqrt(-2 * log(U[1])) * cos(2 * pi * U[2])\n  X2 <- sqrt(-2 * log(U[1])) * sin(2 * pi * U[2])\n  return(c(X1, X2))\n}\n\n# Generation of Stand. Normal RVs through the Box-Muller Algo:\nset.seed(123)\nX_vec <- NULL\nfor(i in 1:500){\n  X_vec <- c(X_vec, BM_Algo())\n}\n\n# Descriptive Plots\npar(mfrow=c(1,2))\nhist(X_vec, freq = FALSE)\ncurve(dnorm, add = TRUE, col=\"blue\", lwd=1.3)\nqqnorm(X_vec)\n\n\n\n\n\n\n\n# Testing for Normality using the Shapiro-Wilk Test (H0: Normality)\nshapiro.test(X_vec)\n\n\n    Shapiro-Wilk normality test\n\ndata:  X_vec\nW = 0.99893, p-value = 0.8323\n\n\n\n\n\n\n\n\n\n2.3.3 Accept-Reject Methods\nFor many distributions it is difficult (or impossible) to apply the Inverse or Transformation Methods, since the cdf \\(F(.)\\) is somehow unusable. For instance, surprisingly often there is no explicit form of \\(F(.)\\) available or its inverse does not exists.\nAccept-Reject Methods methods can provide a solution here, since they only require the knowledge of the functional form of the density \\(f\\) of interest up to a multiplicative constant. No deep analytic study of \\(f\\) is necessary.\n\n\nGeneral Idea and theoretical justification through the Fundamental Theorem of Simulation: Done in the lecture.\n\n\nThe case of pdfs with compact support:\nThe key-idea is easily explained using a bounded pdf \\(f\\) with compact support.\nNotions:\n\nBounded means that there exists a value \\(m\\) with \\(0<m<\\infty\\) s.t. \\(f(x)\\in[0,m]\\) for all \\(x\\).\nNote that only degenerated pdfs are not bounded.\nAn interval \\([a,b]\\) is called “compact” if it is closed and the boundaries are finite.\nFor instance, the Gaussian has not a compact support, since \\(\\mathrm{supp}(\\phi)=]-\\infty,\\infty[\\).\n\nFor instance, let’s say we want to simulate random numbers \\(X\\sim f\\) with \\[\nf(x)=\\frac{3}{4}\\left(1-\\left(x-1\\right)^2\\right)\\,1_{(|x-1|\\leq 1)},\n\\] where the (compact) support of \\(f\\) is \\([a,b]=[-1,1]\\) and its range is \\([0,m]=[0,3/4]\\), i.e., \\(f\\) is bounded from above by \\(3/4\\).\n\nThe idea is then to simulate the random pair \\((Y,U)\\sim\\mathrm{Unif}([a,b]\\times[0,m])\\) by simulating\n \\[Y\\sim\\mathrm{Unif}[a,b]\\quad\\text{and}\\quad U|Y=y \\sim \\mathrm{Unif}[0,m], \\] but to accept the pair \\((Y,U)\\) only if \\(U\\leq f(Y)\\) and to reject all others.\nThis results in the correct distribution of the accepted value of \\(Y\\), call it \\(X\\), because \\[\n\\mathbb{P}(X\\leq x)=\\mathbb{P}(Y\\leq x|U\\leq f(Y))\n=\\frac{\\int_a^{\\color{red}x} \\int_0^{f(y)}\\,1\\,du\\,dy}{\\int_a^{\\color{red}b}\\int_0^{f(y)}\\,1\\,du\\,dy}\n=\\frac{\\int_a^x f(y)\\,dy}{\\int_a^b f(y)\\,dy}\n=\\int_a^x f(y)dy,\n\\]\nwhere we used that \\(f(y)=\\int_{0}^{f(y)}du\\).\nThe Accept-Reject Algorithm (Simple Version):\n# Accept-Reject Algorithm:\nY <- runif(n, min = a, max = b) \nU <- runif(n, min = 0, max = m) \n# A-R Step:\naccept <- U <= f(Y)\nX      <- Y[accept]\nIn the following you see a graphical illustration of this procedure:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe good thing is that we only need to evaluate the pdf \\(f(.)\\); nothing more.\n\n\nGeneralization: pdfs with non-compact support.\nThe larger set does not necessarily need to be a surrounding closed box as used above. In fact, it can be any “larger set”, enclosing the pdf \\(f\\), as long as simulating uniformly over this larger set is feasible. This generalization allows for cases where the support of \\(f\\) is unbounded.\nLet the larger set denote by \\[\n\\mathscr{L}=\\{(y,u):\\, 0<u<m(y)\\},\n\\] where:\n\nsimulation of a uniform on \\(\\mathscr{L}\\) is feasible and\n\n\\(m(x)\\geq f(x)\\) for all \\(x\\).\n\n\n\nFrom the feasibility-requirement it follows that \\(m(.)\\) is necessarily integrable, i.e., that \\[\\int_{\\mathcal{X}}m(x)dx=M,\\] where \\(M\\) exists and is finite (and positive), since otherwise, \\(\\mathscr{L}\\) would not have finite mass and a uniform distribution would not exists on \\(\\mathscr{L}\\).\n\n\nIntegrability of \\(m(.)\\) is crucial here, since it allows us to relate \\(m(.)\\) with a corresponding (auxiliary) pdf \\(g(.)\\) as following: \\[m(x)=M\\,g(x),\\quad\\text{where}\\quad\\int_{\\mathcal{X}}m(x)\\,dx=\\int_{\\mathcal{X}}M\\,g(x)\\,dx=M.\\]\nTerminology:\n\nThe pdf \\(g(.)\\) is called the instrumental density. (Choose \\(g(.)\\) as a pdf from which it is easy to simulate!)\nThe pdf \\(f(.)\\) is called the target density.\n\n\n\nIn order to simulate the pair \\((Y,U)\\sim\\mathrm{Unif}(\\mathscr{L})\\) we can now simulate \\[Y\\sim g\\quad\\text{and}\\quad U|Y={\\color{red}y}\\sim\\mathrm{Unif}[0,M\\,g({\\color{red}y})],\\] but accept the pair \\((Y,U)\\) only if \\(U\\leq f(Y)\\) and to reject all others.\nThis results in the correct distribution of the accepted value of \\(Y\\), call it \\(X\\), because \\[\n\\mathbb{P}(X\\in A)=\\mathbb{P}(Y\\in A|U\\leq f(Y))\n=\\frac{\\int_{\\color{red}A}\\int_0^{f(y)}\\,\\frac{1}{M}\\,du\\,dy}{\\int_\\mathcal{X}\\int_0^{f(y)}\\,\\frac{1}{M}\\,du\\,dy}\n=\\frac{\\int_A f(y)\\,dy}{\\int_\\mathcal{X} f(y)\\,dy}\n=\\int_A f(y)dy,\n\\] for every set \\(A\\),  where we again used that \\(f(y)=\\int_{0}^{f(y)}du\\).\nNote that the above derivation implies that we only need to know the pdf \\(f(.)\\) up to an unkown multiplicative constant \\(c>0\\). I.e., it is enough to know \\(f(x)=c\\,\\tilde{f}_{\\textrm{true}}(x)\\), often written as \\(f(x)\\propto \\tilde{f}_{\\textrm{true}}(x)\\), since the unknown constant \\(c\\) cancels out in the above quotient anyways. This is not so much of importance for us, but useful in Bayesian Statistics.\n\n\nAll this leads to a more general version of the Fundamental Theorem of Simulation:\n\nFundamental Theorem of Simulation (General Version):\n\nLet \\(X\\sim f\\) and let \\(g(.)\\) be a pdf s.t. \\(f(x)\\leq M\\,g(x)\\) for some \\(M\\) with \\(1\\leq M<\\infty\\) and all \\(x\\). Then to simulate \\(X\\sim f\\) it is sufficient to generate \\[Y\\sim g\\quad\\text{and}\\quad U|Y=y\\sim\\mathrm{Unif}[0,M\\,g(y)]\\] if one accepts the pair \\((Y,U)\\) only if \\(U\\leq f(Y)\\) and rejects all others.\n\n\n\n\nThe Accept-Reject Algorithm (General Version):\n# Accept-Reject Algorithm:\nY   <- generate n random numbers from g(.)\n\n# Specify function m():\nm <- function(y){YOUR CODE}\n\nU   <- numeric(n)\nfor(i in 1:n){\n  U[i] <- runif(n=1, min = 0, max = m(Y[i])) \n}\n\n# A-R Step:\naccept <- U <= f(Y)\nX      <- Y[accept]\n\n\nExample\nLet the target “density” be \\[f(x)\\propto \\exp(-x^2/2)\\,(\\sin(6x)^2 + 3\\cos(x)^2\\,\\sin(4x)^2 + 1)\\] with upper bound (or, rather, dominating density) the standard normal density \\[g(x)=\\exp(-x^2/2)/\\sqrt{2\\pi},\\] which is obviously straightforward to generate.\nIn this example we can set \\(m(x)=M\\,g(x)\\) with \\(M=1\\), since we can simply scale the target “density” \\(f\\) such that \\(f(x)\\leq g(x)\\) for all \\(x\\). Specifically, we set \\(f(x)=0.075 \\cdot \\exp(-x^2/2)\\,(\\sin(6x)^2 + 3\\cos(x)^2\\,\\sin(4x)^2 + 1)\\).\nIn the following you see the graphical illustration of this example:\n\n\n\n\n\n\n\n\n\n\n\n\nEfficiency of the Accept-Reject algorithm:\nStatements with respect to the efficiency of the Accept-Reject algorithm can be made if \\(f\\) and \\(g\\) are normalized such that they are both pdfs. Then:\n\nThe constant \\(M\\) is necessarily larger than \\(1\\).\nThe probability of acceptance is \\(1/M\\). (See Exercises.)\n\\(M\\) is interpreted as the efficiency of the Accept-Reject algorithm. (The closer \\(M\\) is to \\(1\\) the better.)\n\\(M\\) is a function of how closely \\(g\\) can imitate \\(f\\).\n\nNote that, for such normalized \\(f\\) and \\(g\\) the inequality \\(f(x)\\leq M\\,g(x)\\) with \\(1\\leq M<\\infty\\) for all \\(x\\) is equivalent to saying that the quotient \\(f/g\\) is bounded, i.e., that \\[\n0\\leq \\frac{f(x)}{g(x)}\\leq M <\\infty\\quad\\text{for all}\\quad x.\n\\] That is, it is necessary for \\(g\\) to have, e.g., thicker tails than \\(f\\). This makes it, for instance, impossible to simulate a Cauchy distribution \\(f\\) using a normal distribution \\(g\\). The reverse, however, works quite well. \n\n\nExample: Normals from Double Exponentials\nConsider generating a \\(N(0,1)\\) by the Accept-Reject algorithm using a double-exponential distribution \\(\\mathcal{L}(\\alpha)\\), also called Laplace distribution, with density \\(g(x|b)=(1/(2b))\\exp(-\\,|x|/b)\\).  It is then straightforward to show that \\[\n\\frac{f(x)}{g(x|b)}\n%=\\frac{\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}x^2\\right)}{\\frac{1}{2b}\\exp\\left(-\\frac{|x|}{b}\\right)}\n%=\\sqrt{\\frac{2}{\\pi}}\\,b\\,\\exp\\left(-\\frac{1}{2}x^2+\\frac{|x|}{b}\\right)\n\\leq\\sqrt{\\frac{2}{\\pi}}\\,b\\,\\exp\\left(\\frac{1}{2\\,b^2}\\right)\n\\] and that the minimum of the bound (in \\(b\\)) is attained for \\(b=1\\).\nThis leads to the following optimal (i.e. most efficient) specification of the double-exponential distribution as instrumental pdf: \\[\n\\frac{f(x)}{g(x|1)}\n\\leq M=\\sqrt{\\frac{2}{\\pi}}\\,\\exp\\left(\\frac{1}{2}\\right).\n\\]\nThe probability of acceptance is then \\(\\sqrt{\\pi/(2e)}=0.76\\). I.e., to produce one normal random variable, this Accept-Reject algorithm requires on the average \\(1/0.76\\approx 1.3\\) uniform variables. This is to be compared with the Box-Muller algorithm for which the ratio between produced normals and required uniforms is 1."
  },
  {
    "objectID": "Ch1_Stochastic_Simulation.html#classical-monte-carlo-integration",
    "href": "Ch1_Stochastic_Simulation.html#classical-monte-carlo-integration",
    "title": "2  Random Variable Generation",
    "section": "3.1 Classical Monte Carlo Integration",
    "text": "3.1 Classical Monte Carlo Integration\nThe generic problem here is the evaluation of integrals. (Be aware: Integrals are everywhere in statistics!). For instance, \\[\n\\mathbb{E}_f\\left(h(X)\\right)=\\mathbb{E}\\left(h(X)\\right)=\\int_\\mathcal{X}h(x)\\,f(x)\\,dx.\n\\]\nConvergence:\nGiven our previous developments, it is natural to propose using a realization \\(x_1,\\dots,x_m\\) from a (pseudo random) i.i.d. sample \\(X_1,\\dots,X_m\\) with each \\(X_j\\) distributed as \\(X\\sim f\\) to approximate the above integral by the empirical mean \\[\n\\bar{h}_m=\\frac{1}{m}\\sum_{j=1}^m h(x_j).\n\\] By the Strong Law of Large Numbers we know that the empirical mean \\(\\bar{h}_m\\) converges almost surely (a.s.) to the desired limit \\(\\mathbb{E}\\left(h(X)\\right)\\) as \\(m\\to\\infty\\). (The only prerequisits are that \\(f\\) has finite first moments, i.e., \\(\\mathbb{E}\\left(h(X)\\right)<\\infty\\), and that \\(\\bar{h}_m\\) is constructed from an i.i.d. sample \\(X_1,\\dots,X_m\\).)\nAs we can use the computer to produce realizations from the i.i.d. sample \\(X_1,\\dots,X_m\\), we can in principle choose an arbitrary large sample size \\(m\\) such that \\(\\bar{h}_m\\) can (in principle) be arbitrarily close to the desired limit \\(\\mathbb{E}\\left(h(X)\\right)\\).\nThough, …\n\n… which sample size \\(m\\) is large enough?\nOr “equivalently”: How fast converges \\(\\bar{h}_m\\) to the desired limit \\(\\mathbb{E}\\left(h(X)\\right)\\)?\n\n\n\nSpeed of Convergence:\nOK, we know now that \\(\\bar{h}_m\\) reaches its limit (here in the “almost surely” sense) as \\(m\\to\\infty\\) under some rather loose conditions on the random sample \\(X_1,\\dots,X_m\\).\nIf we are willing to additionally assume that \\(f\\) has finite second moments, i.e., \\(\\mathbb{E}(h(X)^2)<\\infty\\), we can additionally say something about how fast \\(\\bar{h}_m\\) converges (a.s.) to \\(\\mathbb{E}(h(X))\\).\nThe speed of convergence of the stochastic sequence \\(\\{\\bar{h}_m\\}\\) (i.e., now we think of \\(\\bar{h}_m\\) as the {RV} \\(\\bar{h}_m=\\frac{1}{m}\\sum_{j=1}^m h({\\color{red}{X_{j}}})\\)) to its limit \\(\\mathbb{E}(h(X))\\) can be assessed by answering the question how fast the standard deviation (which is a function of \\(m\\)) of the stochastic sequence converges to zero as \\(m\\to\\infty\\).\n\nThe variance of \\(\\bar{h}_m\\) is given by \\[\n\\mathbb{V}_f\\left(\\bar{h}_m\\right)=\n\\mathbb{V}\\left(\\frac{1}{m}\\sum_{j=1}^m h(X_j)\\right)=\n\\frac{1}{m}\\mathbb{V}\\left(h(X)\\right)\n\\]\nNote that assuming finite second moments \\(\\mathbb{E}(h(X)^2)<\\infty\\) is equivalent to assuming finite variance \\(\\mathbb{V}\\left(h(X)\\right)<\\infty\\). Consequently, we can set \\(\\mathtt{const}=\\sqrt{\\mathbb{V}\\left(h(X)\\right)}\\) with \\(0<\\mathtt{const}<\\infty\\) such that \\[\n\\sqrt{\\mathbb{V}\\left(\\bar{h}_m\\right)}=m^{-1/2}\\mathtt{const}\\propto m^{-1/2}.\n\\]\n\nI.e., the speed of convergence (or rate) of the stochastic sequence \\(\\{\\bar{h}_m\\}\\) is proportional to the deterministic sequence \\(\\{m^{-1/2}\\}\\).\n\n\nRemark: Even if we would not know the value of \\(\\mathtt{const}=\\sqrt{\\mathbb{V}\\left(h(X)\\right)}\\), we know now that the improvement from \\(m=10\\) to \\(m=100\\) will be much higher than from \\(m=110\\) to \\(m=200\\). In practice, a typical choice is \\(m=10000\\); for moderate standard deviations this choice will guarantee a very good approximation.\n\n\nLimit Distribution:\nOf course, we can estimate the variance of the estimator \\(\\mathbb{V}\\left(\\bar{h}_m\\right)\\) by its empirical version \\[\nv_m=\\frac{1}{m}\\left(\\frac{1}{m}\\sum_{j=1}^m\\left(h(x_j)-\\bar{h}_m\\right)^2\\right),\n\\] where again by the Strong Law of Large Numbers (SLLN) \\[\n\\left(\\frac{1}{m}\\sum_{j=1}^m\\left(h(x_j)-\\bar{h}_m\\right)^2\\right)\\to_{\\text{a.s.}}\\mathbb{V}\\left(h(X)\\right).\n\\]  By the Central Limit Theorem (CLT) we have \\[\n\\sqrt{m}\\left(\\frac{\\bar{h}_m - \\mathbb{E}\\left(h(X)\\right)}{\\sqrt{\\mathbb{V}\\left(h(X)\\right)}}\\right)\\to_d Z,\n\\] where \\(Z\\sim N(0,1)\\). Note that the the above sequence \\(\\{\\sqrt{m}\\}\\) just hinders the convergence of the sequence \\(\\bar{h}_m - \\mathbb{E}\\left(h(X)\\right)\\to_{a.s.}0\\) such that the quotient converges to a “stable” distribution.\nThe above result can now be used for the construction of (asymptotically valid) convergence tests and confidence intervals with respect to \\(\\bar{h}_m\\), since for large \\(m\\) \\[\n\\bar{h}_m\\,\\overset{d}{\\approx} N\\left(\\mathbb{E}\\left(h(X)\\right),\\frac{\\mathbb{V}\\left(h(X)\\right)}{m}\\right).\n\\]\nAnd as we can use the computer to generate realizations of the i.i.d. sample \\(X_1,\\dots,X_m\\) from a generic \\(X\\sim f\\), we can easily approximate the mean \\(\\mathbb{E}\\left(h(X)\\right)\\) and the variance \\(\\mathbb{V}\\left(h(X)\\right)\\) with arbitrary accuracy as \\(m\\to\\infty\\); by the SLLN (or the WLLN).\n\n\nExample: A first Monte Carlo Integration\nLet’s say we want to integrate the function \\(h(x)=\\left(\\cos(50\\,x)+\\sin(20\\,x)\\right)^2\\). Although this function could be integrated analytically it is a good first test case. The left plot below shows the graph of the function \\(h(.)\\).\nTo approximate the integral \\[\n\\int_\\mathcal{X}h(x)dx\\quad\\text{with}\\quad\\mathcal{X}=[0,1]\n\\] we can use that \\[\n\\int_\\mathcal{X}h(x)dx=\\int_\\mathcal{[0,1]}1\\cdot h(x)dx =\\mathbb{E}_{f_\\text{Unif[0,1]}}(h(X)).\n\\]\nThus, we generate a realization \\((u_1,\\dots,u_n)\\) from the i.i.d. random sample \\(U_1,\\dots,U_n\\sim[0,1]\\) and approximate \\[\n\\int_\\mathcal{X}h(x)dx\\approx \\bar{h}_n=\\frac{1}{n}\\sum_{i=1}^n h(u_i).\n\\]\nIn order to assess how good this approximation is, we need to consider the stochastic propoerties of the RV \\[\n\\frac{1}{n}\\sum_{i=1}^n h(U_i).\n\\] This is done using the above (review of) results on the limit distribution of the sample mean which allows us to construct an approximative \\(95\\%\\) confidence interval, since for large \\(n\\) \\[\n\\left[\\bar{h}_n - 1.96\\frac{\\mathtt{std.error}_n}{\\sqrt{n}}, \\bar{h}_n + 1.96\\frac{\\mathtt{std.error}_n}{\\sqrt{n}}\\right]\\approx\n\\left[\\bar{h}_n - 1.96  \\sqrt{\\frac{\\mathbb{V}(h(U_i))}{n}}, \\bar{h}_n + 1.96  \\sqrt{\\frac{\\mathbb{V}(h(U_i))}{n}}\\right],\n\\] where \\(\\mathtt{std.error}_n^2=n^{-1}\\sum_{i=1}^n(h(u_i)-\\bar{h}_n)^2\\).\nThe right plot below shows one realization of the stochastic sequence \\(\\{\\bar{h}_1,\\dots,\\bar{h}_n\\}\\) with \\(n=10000\\), where the realized value of \\(\\bar{h}_n\\) is \\(0.966\\). This compares favorably with the with the exact value of \\(0.965\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemarks:\n\nThe approach followed in the above example can be successfully utilized in many cases, even though it is often possible to achieve greater efficiency through numerical methods (e.g., Riemann Sum, Trapezoidal Rule, Simpson’s Rule, etc.) in dimensions 1 or 2.\nThe approach is particularly useful for approximating integrals over higher dimensional sets.\n\n\n\nExample: Approximation of Normal Distribution Tables\nA possible way to construct normal distribution tables is to use MC simulations.\nGenerate a realization \\((x_1,\\dots,x_n)\\) from an i.i.d. standard normal random sample, e.g., using the Box-Muller algorithm.\nThe approximation of the standard normal cdf \\[\n\\Phi(t)=\\int_{-\\infty}^t\\frac{1}{\\sqrt{2\\pi}}e^{-y^2/2}dy\n\\] by the Monte Carlo method is thus \\[\n\\hat{\\Phi}_n(t)=\\frac{1}{n}\\sum_{i=1}^n 1_{(x_i\\leq t)}.\n\\] The corresponding RV \\(\\hat{\\Phi}_n(t)=\\frac{1}{n}\\sum_{i=1}^n1_{(X_i\\leq t)}\\) has (exact) variance \\[\n\\mathbb{V}(\\hat{\\Phi}_n(t))=\\frac{\\Phi(t)(1-\\Phi(t))}{n},\n\\] since the single RVs \\(1_{(X_i\\leq t)}\\) are independent Bernoulli with success probability \\(\\Phi(t)\\).\nFor values of \\(t\\) around \\(t=0\\), the variance is thus approximately \\(1/4n\\).\nTo achieve a precision of four decimals by means of a \\(99.9\\%\\) confidence interval, the approximation requires on average \\(n\\approx 10^8\\) simulations.\nThe table below gives the evolution of this approximation for several values of \\(t\\) and shows a very accurate evaluation for \\(n=10^8\\).\n\n\n\\[\n\\begin{array}{cccccccccc}\n\\hline\nn   &t=0.0  &t=0.67 &t=0.84 &t=1.28 &t=1.65 &t=2.32 &t=2.58 &t=3.09 &t=3.72 \\\\\n\\hline\n10^2 &0.485  &0.74   &0.77   &0.9    &0.945  &0.985  &0.995  &1      &1      \\\\\n10^3 &0.4925 &0.7455 &0.801  &0.902  &0.9425 &0.9885 &0.9955 &0.9985 &1      \\\\\n10^4 &0.4962 &0.7425 &0.7941 &0.9    &0.9498 &0.9896 &0.995  &0.999  &0.9999 \\\\\n10^5 &0.4995 &0.7489 &0.7993 &0.9003 &0.9498 &0.9898 &0.995  &0.9989 &0.9999 \\\\\n10^6 &0.5001 &0.7497 &0.8    &0.9002 &0.9502 &0.99   &0.995  &0.999  &0.9999 \\\\\n10^7 &0.5002 &0.7499 &0.8    &0.9001 &0.9501 &0.99   &0.995  &0.999  &0.9999 \\\\\n10^8 &0.5    &0.75   &0.8    &0.9    &0.95   &0.99   &0.995  &0.999  &0.9999 \\\\\n\\end{array}\n\\]\n\n\nRemarks:\n\nTo achieve a precision of two decimals by means of a \\(99.9\\%\\) confidence interval, already \\(n=10^4\\) leads to satisfactory results.\nNote that greater accuracy is achieved in the tails and that more efficient simulation methods could be used (e.g., Importance Sampling)."
  },
  {
    "objectID": "Ch1_Stochastic_Simulation.html#importance-sampling",
    "href": "Ch1_Stochastic_Simulation.html#importance-sampling",
    "title": "2  Random Variable Generation",
    "section": "3.2 Importance Sampling",
    "text": "3.2 Importance Sampling\nImportance sampling aims to reduce the variance of the Monte Carlo integral estimate therefore it’s refereed to as a variance reduction technique. This variance reduction is achieved by weighting functions, so-called importance functions.\nAs in the case of Monte Carlo integration the focus lies on evaluating the integral \\[\n\\mathbb{E}_f(h(X))=\\int_\\mathcal{X}h(x)f(x)\\,dx.\n\\]\n\nThough, it turns out that the above approach, i.e., sampling from \\(f\\) is often suboptimal.\nObserve that the value of the above integral can be represented by infinitely many alternative choices of the triplet \\((\\mathcal{X}, h, f)\\). Therefore, the search for an optimal estimator should encompass all these possible representations.\n\nLet’s illustrate this with a simple example.\nExample: Cauchy Tail Probability (from Ripley 1987)\nSuppose that the quantity of interest is the probability, say \\(p\\), that a Cauchy \\(\\mathrm{C}(0,1)\\) RV is larger than \\(2\\), i.e.: \\[\np=\\int_{2}^{+\\infty}\\frac{1}{\\pi(1+x^2)}\\,dx.\n\\]\n1. Naive Approach: If \\(p\\) is approximated through the empirical mean \\[\n\\hat{p}_{1}=\\frac{1}{m}\\sum_{j=1}^m1_{(X_j>2)}\n\\] of an i.i.d. sample \\(X_1,\\dots,X_m\\sim\\mathrm{C}(0,1)\\), then the variance of this estimator, a binomial RV scaled by \\(1/m\\), is \\[\n\\mathbb{V}(\\hat{p}_{1})=\\frac{1}{m^2}\\mathbb{V}\\left(\\sum_{j=1}^m1_{(X_j>2)}\\right)=\\frac{p(1-p)}{m},\n\\] which is equal to \\(0.1275/m\\), since (we already know that) \\(p=0.15\\).\n\n\n2. Accounting for Symmetry (i.e., using the ‘Adjusting Screws’ \\(\\mathcal{X}\\) and \\(h\\)): We can achieve a more efficient estimator (i.e., an estimator with lower variance for a given same sample size \\(n\\)) if we take into account the symmetric nature of \\(\\mathrm{C}(0,1)\\). Obviously, our target integral can be equivalently written as \\[\np=\\frac{1}{2}\\left(\\int_{-\\infty}^{-2}\\frac{1}{\\pi(1+x^2)}\\,dx + \\int_{2}^{+\\infty}\\frac{1}{\\pi(1+x^2)}\\,dx \\right).\n\\] This representation has the attractive feature that we can use a much higher fraction of the simulated data by using the following new empirical mean: \\[\n\\hat{p}_{2}=\n\\frac{1}{2}\\left(\\frac{1}{m}\\sum_{j=1}^m1_{(X_j<-2)}+ \\frac{1}{m}\\sum_{j=1}^m1_{(X_j>2)}\\right)\\;=\\;\n\\frac{1}{2m}\\sum_{j=1}^m1_{(|X_i|>2)}.\n\\] The variance of this new estimator, \\[\n\\mathbb{V}(\\hat{p}_{2})=\\frac{1}{4m^2}\\mathbb{V}\\left(\\sum_{j=1}^m1_{(|X_i|>2)}\\right)=\\frac{2p(1-2p)}{4m},\n\\] is equal to \\(0.0525/m\\), i.e., lower than in the naive approach.\n\n\n3. Using all ‘Adjusting Screws’ \\(\\mathcal{X}\\), \\(h\\), and \\(f\\): The (relative) inefficiency of the above approaches is due to the generation of RVs outside the domain of interest, \\([2,+\\infty)\\), which are in some sense irrelevant for the approximation of \\(p\\). This motivates the following reformulation of \\(p\\):\nBy symmetry of \\(f\\): \\[\n\\frac{1}{2}=\\int_{0}^2\\frac{1}{\\pi(1+x^2)}dx + \\underbrace{\\int_{2}^{+\\infty}\\frac{1}{\\pi(1+x^2)}dx}_{=p}\n\\] \\[\n\\Leftrightarrow \\; p=\\frac{1}{2}-\\int_{0}^2\\frac{1}{\\pi(1+x^2)}dx.\n\\] Furthermore, we can re-arrange the last integral a bit such that \\[\n\\int_{0}^2\\;\\left(\\frac{1}{2}\\cdot 2\\right)\\;\\frac{1}{\\pi(1+x^2)}\\,dx =\n\\int_{0}^2\\;\\underbrace{\\frac{1}{2}}_{f_{\\mathrm{Unif}[0,2]}}\\;\\underbrace{\\frac{2}{\\pi(1+x^2)}}_{=h(x)}\\,dx =\n\\mathbb{E}(h(U)),\\quad\\text{where}\\quad U\\sim\\mathrm{Unif}[0,2].\n\\]\nTherefore a new alternative method for evaluating \\(p\\) is: \\[\n\\hat{p}_{3}=\\frac{1}{2} - \\frac{1}{m}\\sum_{j=1}^m h(U_j),\\quad\\text{where}\\quad U_j\\sim\\mathrm{Unif}[0,2].\n\\] Using integration by parts, it can be shown that \\(\\mathbb{V}(\\hat p_3)=0.0285/m\\). (Compare this to the former results: \\(\\mathbb{V}(\\hat{p}_{2})=0.0525/m\\) and \\(\\mathbb{V}(\\hat{p}_{1})=0.1275/m\\).)\n\n\nA More General Point of View:\nThe idea of importance sampling is related to weighted and stratified sampling ideas. As illustrated by the above example, when estimating \\[\n\\theta=\\mathbb{E}_f(h(X))=\\int h(x)f(x)dx.\n\\]\nSome outcomes of \\(X\\sim f\\) may be more important than others in determining \\(\\theta\\) and we wish to select such values more frequently.\nFor instance, if \\(\\theta\\) denotes the probability of the occurrence of a very rare event, then the only way to estimate \\(\\theta\\) at all accurately may be to produce the rare events more frequently.\nTo achieve this, we can simulate a model which gives pdf \\(g\\) to \\(X\\) instead of the correct pdf \\(f\\), where both pdfs need to be known. This can be easily done, since \\[\n\\theta=\\mathbb{E}_f(h(X))=\\int h(x)\\left(\\frac{g(x)}{g(x)}\\right)\\;f(x)dx=\n\\int \\underbrace{\\left(h(x)\\frac{f(x)}{g(x)}\\right)}_{=\\psi(x)}\\;g(x)dx=\n\\int \\psi(x)\\;g(x)dx=\n\\mathbb{E}_g(\\psi(X)).\n\\]\nThis leads to the following unbiased estimator for \\(\\theta\\) based on sampling from \\(g\\): \\[\n\\hat{\\theta}_g=\\frac{1}{n}\\sum_{i=1}^n\\psi(X_i)\\quad\\text{with}\\quad X_i\\sim g,\n\\] which is a weighted mean of the \\(h(X_i)\\) with weights inversely proportional to the “selection factor” \\(\\frac{g(X_i)}{f(X_i)}\\). \nFor the variance of the estimator \\(\\hat{\\theta}_g\\) we have \\[\n\\mathbb{V}(\\hat{\\theta}_g)=\\frac{1}{n}\\mathbb{V}(\\psi(X_i))=\n\\frac{1}{n}\\int\\left(\\psi(x)-\\theta\\right)^2g(x)dx=\n\\frac{1}{n}\\int\\left(\\frac{h(x)\\,f(x)}{g(x)}-\\theta\\right)^2g(x)dx,\n\\] which, depending on the choice of \\(g(.)\\), can be much smaller (or larger) than the variance of the naive estimator from the classical Monte Carlo Integration using the ordinary empricial mean. \n\n\n\n\nMinimum Variance Theorem\n\nThe importance function \\(g(.)\\) which minimizes the variance \\(\\mathbb{V}(\\psi(X_i))\\), and therefore the variance \\(\\mathbb{V}(\\hat{\\theta}_g)\\), is given by \\[\ng^\\ast(x)=\\frac{|h(x)|f(x)}{\\int |h(z)|f(z)dz}.\n\\]\n\n\nProof: Done in the lecture.\n\n\nThough, this result is rather formal (in the sense of “impractical”), since, e.g., if \\(h(x)>0\\) then \\(g^\\ast\\) requires us to know \\(\\int h(z)f(z)dz\\), which is just the integral of interest!\nRemarks:\nThe above minimum variance result is still useful:\n\nIt tells us that a good choice of \\(g(x)\\) shall mimic the shape of \\(|h(x)|f(x)\\), since the optimal \\(g^\\ast(x)\\propto |h(x)|f(x)\\).\nFurthermore, \\(g(x)\\) should be chosen such that it has a thicker tail than \\(f(x)\\), since the variance \\(\\mathbb{V}(\\hat{\\theta}_g)\\) crucially depends on the quotient \\(f(x)/g(x)\\) which would “explode” for \\(g(x)\\approx 0\\).\n\n\n\nLet’s apply our new insights to the above example on the Cauchy tail probability \\(p\\).\nExample: Cauchy Tail Probability (cont.)\nAbove we had:\n\n\\(f(x)=\\frac{1}{\\pi(1+x^2)}\\), the pdf of \\(\\mathrm{C}(0,1)\\) and\n\\(h(x)=1_{(x>2)}\\), i.e., here \\(|h(x)|=h(x)\\).\n\nTherefore \\[\np=\\mathbb{E}_f(h(X))=\\int h(x)f(x)dx=\\int_{2}^{\\infty}f(x)dx=\\int_{2}^{\\infty}\\underbrace{\\frac{f(x)}{g(x)}}_{=\\psi(x)}\\;g(x)dx=\\mathbb{E}_g(\\psi(X)),\n\\] where the \\(h\\) function is absorbed by the formulation of the definite integral.\nA possibly good (and simple) choice of \\(g\\) is, e.g., \\(g(x)=2/(x^2)\\), since this function:\n\n“closely” matches \\(h(x)f(x)\\) and\n\\(g\\) has thicker tails than \\(f\\).\n\n\n\n\n\n\n\n\n\n\n\n\nCaution: It is not straight forward to directly sample from \\(g\\), therefore we need some further steps:\n\n\nThe choice of \\(g\\) leads to \\[\np=\\mathbb{E}_g(\\psi(X))=\n\\int_{2}^{+\\infty}\\left(\\frac{x^2}{2\\,\\pi(1+x^2)}\\right)\\,\\frac{2}{x^2}\\,dx=\n\\int_{2}^{+\\infty}\\left(\\frac{1}{\\pi(1+x^{-2})}\\right)\\,x^{-2}\\,dx.\n\\]\n\n\nNow we can apply some additional (rather case-specific) re-arrangements:\nIntegration by substitution (substituting \\(u=x^{-1}\\)) yields: \\[\np=\\int_{0}^{1/2}\\frac{1}{\\pi(1+u^2)}du.\n\\] Again, we can re-arrange the last integral a bit such that \\[\np=\\int_{0}^{1/2}\\underbrace{2}_{f_{\\mathrm{Unif}[0,1/2]}}\\;\\underbrace{\\frac{1}{2\\,\\pi(1+u^2)}}_{=h(u)}\\,du=\\mathbb{E}(h(U)),\\quad\\text{where}\\quad U\\sim\\mathrm{Unif}[0,1/2].\n\\] Therefore, we have a final fourth version of the estimator of \\(p\\): \\[\n\\hat{p}_4=\\sum_{j=1}^m h(U_j),\\quad\\text{where}\\quad U\\sim\\mathrm{Unif}[0,1/2]\n\\] and \\(h(u)=1/(2\\pi(1+u^2))\\).\nThe variance of \\(\\hat{p}_4\\) is \\((\\mathbb{E}(h(U)^2)-\\mathbb{E}(h(U))^2)/m\\) and an integration by parts shows that \\(\\mathbb{V}(\\hat{p}_4)=0.95\\cdot 10^{-4}/m\\). Compare this to the former results: \\(\\mathbb{V}(\\hat p_3)=0.0285/m\\), \\(\\mathbb{V}(\\hat{p}_{2})=0.0525/m\\) and \\(\\mathbb{V}(\\hat{p}_{1})=0.1275/m\\). The variance of \\(\\hat{p}_4\\) is by a factor of \\(10^{-3}\\) lower than the variance of the original \\(\\hat{p}_1\\)."
  },
  {
    "objectID": "Ch_Bootstrap.html",
    "href": "Ch_Bootstrap.html",
    "title": "3  An Introduction to the Bootstrap",
    "section": "",
    "text": "Some literature:"
  },
  {
    "objectID": "Ch_Bootstrap.html#x_1-x_2-x_3-x_4-x_5-x_6-x_7-x_8",
    "href": "Ch_Bootstrap.html#x_1-x_2-x_3-x_4-x_5-x_6-x_7-x_8",
    "title": "3  An Introduction to the Bootstrap",
    "section": "Example 3.1 (Example (empirical distribution function)) \\(x_1\\) | \\(x_2\\) | \\(x_3\\) | \\(x_4\\) | \\(x_5\\) | \\(x_6\\) | \\(x_7\\) | \\(x_8\\)",
    "text": "Example 3.1 (Example (empirical distribution function)) \\(x_1\\) | \\(x_2\\) | \\(x_3\\) | \\(x_4\\) | \\(x_5\\) | \\(x_6\\) | \\(x_7\\) | \\(x_8\\)\n5,20 | 4,80 | 5,40 | 4,60 | 6,10 | 5,40 | 5,80 | 5,50\nCorresponding empirical distribution function:\n\nsample     <- c(5.20, 4.80, 5.40, 4.60, 6.10, 5.40, 5.80, 5.50)\n\nmyecdf_fun <- ecdf(sample)\n\nplot(myecdf_fun, main=\"\")"
  },
  {
    "objectID": "Ch_Bootstrap.html#the-bootstrap-basic-idea",
    "href": "Ch_Bootstrap.html#the-bootstrap-basic-idea",
    "title": "3  An Introduction to the Bootstrap",
    "section": "3.2 The bootstrap: Basic idea",
    "text": "3.2 The bootstrap: Basic idea\nThe bootstrap is an important tool of modern statistical analysis. It establishes a general framework for simulation-based statistical inference. In simple situations the uncertainty of an estimate may be gauged by analytical calculations leading, for example, to the construction of confidence intervals based on an assumed probability model for the available data. The bootstrap replaces complicated and often inaccurate approximations to biases, variances and other measures of uncertainty by computer simulations.\nThe idea of the bootstrap:\n\nThe random sample \\(X_1,\\dots,X_n\\) is generated by drawing observations independently and with replacement from the underlying population with distribution function \\(F\\).\n\nThat is, for each interval \\([a,b]\\) the probability of drawing an observation in \\([a,b]\\) is given by \\(P(X\\in [a,b])=F(b)-F(a)\\).\n\n\\(n\\) large: The empirical distribution of the sample values is “close” to the distribution of \\(X\\) in the underlying population.\n\nThat is, the relative frequency \\(F_n(b)-F_n(a)\\) of observations in \\([a,b]\\) converges to \\(P(X\\in [a,b])=F(b)-F(a)\\) as \\(n\\rightarrow\\infty\\).\n\nThe idea of the bootstrap consists in mimicking the data generating process:\n\nRandom sampling from the true population is replaced by random sampling from the observed data. This is justified by the insight that the empirical distribution of the observed data is “similar” to the true distribution; i.e. \\(F_n\\rightarrow F\\) for \\(n\\rightarrow\\infty\\).\n\n\n\n3.2.1 Estimating a population mean\nSetup:\n\nPopulation Model: Continuous random variable \\(X\\) with unknown mean \\(\\mu\\)\nData: i.i.d. sample \\(X_1,\\dots,X_n\\) from \\(X\\)\nProblem: What is the distribution of \\(\\bar{X} -\\mu\\)?\n\nNow assume that \\(n=8\\) and that the observed sample is\n\n\n\n\\(i\\)\n\\(X_i\\)\n\n\n\n\n1\n-0.6\n\n\n2\n1.0\n\n\n3\n1.4\n\n\n4\n-0.8\n\n\n5\n1.6\n\n\n6\n1.9\n\n\n7\n-0.1\n\n\n8\n0.7\n\n\n\n\nobservedSample <- c(-0.6, 1.0, 1.4, -0.8, 1.6, 1.9, -0.1, 0.7)\n\nSo the sample mean is\n\n\\(\\bar X =\\) mean(observedSample) \\(=\\) 0.6375\n\n\nBootstrap:\nThe observed sample \\({\\cal S}_n=\\{X_1,\\dots,X_n\\}\\) is taken as underlying empirical “population” in order to generate “Bootstrap data” \\(X_1^*,\\dots,X_n^*\\).\n\ni.i.d. samples \\(X_1^*,\\dots,X_n^*\\) are generated by drawing observations independently and with replacement from \\({\\cal S}_n=\\{X_1,\\dots,X_n\\}\\).\n\n\n## generating a bootstrap sample\nbootSample <- sample(x       = observedSample, \n                     size    = length(observedSample), \n                     replace = TRUE)\n\n\nThe distribution of \\(\\bar X -\\mu\\) is approximated by the conditional distribution of \\(\\bar X^* -\\bar X\\) given the original sample \\({\\cal S}_n\\) \\[\n\\underbrace{P\\left(\\bar{X}-\\mu<\\delta\\right)}_{\\text{unknown}}\\approx\n\\underbrace{P\\left(\\bar{X}^*-\\bar{X}<\\delta|\\mathcal{S}_n\\right)}_{\\text{approximable}}\n\\]\n\nFor the given data with \\(n=8\\) observations, there are \\(n^n=8^8=16,777,216\\) possible bootstrap samples which are all equally probable.\nThe conditional distribution function of \\(\\bar{X}^*-\\bar{X}\\) given \\(\\mathcal{S}_n\\) \\[\nP\\left(\\bar{X}^*-\\bar{X}<\\delta|\\mathcal{S}_n\\right)\n\\] can be approximated using Monte-Carlo simulations.\nFor example, \\(m=5\\) simulation runs may lead to the following results:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimul.\n\\(X_1^*\\)\n\\(X_2^*\\)\n\\(X_3^*\\)\n\\(X_4^*\\)\n\\(X_5^*\\)\n\\(X_6^*\\)\n\\(X_7^*\\)\n\\(X_8^*\\)\n\\(\\bar X^*-\\bar{X}\\)\n\n\n\n\n1\n1.9\n-0.8\n1.9\n-0.6\n1.4\n-0.1\n-0.8\n1.0\n-0.15\n\n\n2\n0.7\n-0.8\n-0.8\n1.0\n1.6\n1.0\n-0.1\n-0.8\n-0.4125\n\n\n3\n-0.1\n1.9\n0.7\n1.0\n-0.1\n1.6\n1.0\n-0.6\n0.0375\n\n\n4\n1.4\n1.0\n1.4\n-0.1\n1.9\n-0.8\n1.9\n1.0\n0.325\n\n\n5\n1.0\n0.7\n-0.1\n0.7\n1.4\n-0.8\n1.0\n1.6\n0.05\n\n\n\nOf course, \\(m=5\\) simulations will not be enough. But using \\(m=1000\\) or \\(m=2000\\) then \\[\nP\\left(\\bar X^*-\\bar X\\leq \\delta |{\\cal S}_n\\right) \\approx \\frac{\\sum_{k=1}^m\nI( \\bar X^*_k-\\bar X\\leq \\delta)}{m}\n\\] will provide a fairly accurate approximation.\n\nn                <- length(observedSample)\nXbar             <- mean(observedSample)\nm                <- 2000\nbootRealizations <- numeric(m)\n\nfor(l in seq_len(m)){\n bootSample          <- sample(x       = observedSample, \n                               size    = n, \n                               replace = TRUE)\n bootXbar            <- mean(bootSample)\n bootRealizations[l] <- bootXbar - Xbar\n}\n\nplot(ecdf(bootRealizations), main=\"\")"
  },
  {
    "objectID": "Ch1_Random_Variable_Generation.html",
    "href": "Ch1_Random_Variable_Generation.html",
    "title": "2  Random Variable Generation",
    "section": "",
    "text": "Main:\n\nMonte Carlo Statistical Methods, Robert, C., and Casella, G., Ch. 2\n\nFurther:\n\nNon-Uniform Random Variate Generation, Devroye, L.\nNonparametric Density Estimation: The L1 View, Devroye, L., Ch. 8\nMonte Carlo and Quasi-Monte Carlo Sampling, Lemieux, C., Ch. 2 and 3"
  },
  {
    "objectID": "Ch1_Random_Variable_Generation.html#uniform-simulation",
    "href": "Ch1_Random_Variable_Generation.html#uniform-simulation",
    "title": "2  Random Variable Generation",
    "section": "2.1 Uniform Simulation",
    "text": "2.1 Uniform Simulation\nGeneral procedure:\n\nUsually, a random integer with values uniformly in \\([0,m]\\) with a large integer \\(m\\) is generated.\nTo achieve a random number in \\([0, 1]\\), we divide this number by \\(m\\).\nFrom this (pseudo) uniform random numbers we can generate random numbers of almost any other distribution.\n\nThere are many different Random Number Generators (RNGs), we consider the most simple class of RNGs:\n\nLinear Congruential Generators\n\nHere the \\(i\\)th random integer \\(u_i\\) is generated by \\[u_i=(a u_{i-1}+c) \\,\\mathrm{mod}\\, m,\\]\nwhere \\(u_0\\) is chosen fixed and called seed. Further “\\(b\\,\\mathrm{mod}\\,c\\)” denotes the remainder of the division of \\(b\\) by \\(c\\), and:\n\n\\(m\\), with \\(0<m\\), is called the “modulus”,\n\\(a\\), with \\(0<a<m\\), is called the “multiplier”,\n\\(c\\), with \\(0\\leq c<m\\), is called the “increment”.\n\n\n\n\n\nSome Facts:\n\nThe above recursion generates a completely nonrandom sequence, therefore it is usually called a pseudo random sequence.\nUnder appropriate choices of \\(u_0\\) , \\(a\\) and \\(m\\) the generated (deterministic) sequence behaves like a sequence of independent random draws from a uniform distribution on \\([0, m]\\).\nThe cycle length of linear congruential generators will never exceed modulus \\(m\\), but can maximized with the three following conditions (see Knuth (2002) for a proof):\n\nThe increment \\(c\\) is relatively prime to \\(m\\),\n\\(a - 1\\) is a multiple of every prime dividing \\(m\\),\n\\(a - 1\\) is a multiple of \\(4\\) when \\(m\\) is a multiple of \\(4\\).\n\n\n\n\n\nThe modulo operator: \\(\\mathrm{mod}\\)\n\n# Modulo computation using the modulo operator '%%'\n5 %% 4\n9 %% 4\n\n4 %% 5\n\n# own modulo-function:\nmy_mod <- function(x,m){\n  t1 <- floor(x/m)\n  return(x-t1*m)\n}\n\n\n\nBad choice of parameters for the linear congruential random number generator:\n\nm <- 64    # modulus\na <- 33    # multiplier\nc <- 12    # increment\ns <- 57    # seed\nn <- 1000  # length of run (including seed)\nr_vec    <- numeric(n) # initialize vector\nr_vec[1] <- s # set seed\nfor (i in 1:(n-1)){\n r_vec[i+1] <- (a * r_vec[i] + c) %% m\n}\n# scale between [0,1]:\nbad_runif_vec <- r_vec/m\n\n# BUT! Very short cycle-length (here: period=16)\nr_vec[ 1:16]\n\n [1] 57 37 17 61 41 21  1 45 25  5 49 29  9 53 33 13\n\nr_vec[17:32]\n\n [1] 57 37 17 61 41 21  1 45 25  5 49 29  9 53 33 13\n\n\n\n\nExample: Average heads ratios for \\(n\\) simulated tosses of a fair coin with \\(n=1,2,\\dots\\). By the (strong or weak) law of large numbers this average should converge stochastically to \\(0.5\\) as \\(n\\) becomes large.\n\n# using the above bad RNG:\nbar_x_bad  <- cumsum(bad_runif_vec > 0.5)/(1:n)\n# using R's high-quality RNG:\nset.seed(223)\nbar_x_good <- cumsum(runif(n)  > 0.5 )/(1:n)\n# plotting the results:\nplot(bar_x_bad, type=\"l\", ylim=c(0.46,0.54), \n     xlab=\"\", ylab=\"\", main=\"Good vs. Bad RNG\")\nlines(bar_x_good, col=\"darkblue\")\n\n\n\n\n\n\n\n\n\nSee also:\n\nIBM’s RANDU is a famous example of an miss-specified linear congruential RNG."
  },
  {
    "objectID": "Ch1_Random_Variable_Generation.html#generation-of-discrete-random-variables",
    "href": "Ch1_Random_Variable_Generation.html#generation-of-discrete-random-variables",
    "title": "2  Random Variable Generation",
    "section": "2.2 Generation of Discrete Random Variables",
    "text": "2.2 Generation of Discrete Random Variables\nAssume that you have a realization \\(u\\) from a uniform distribution on \\([0, 1]\\) available.\nAssume the discrete variable \\(X\\) of interest takes on the values \\(\\{x_1, \\dots , x_k \\}\\) with \\[p_i = \\mathbb{P}(X = x_i ), \\quad i = 1,\\dots , k\\quad\\text{and}\\quad \\sum_{i=1}^kp_i = 1.\\]\nIdea:\n\nSubdivide \\([0, 1]\\) into \\(k\\) intervals with \\[I_i = (F_{i-1}, F_i],\\quad\\text{where}\\quad F_i = p_1 + \\dots p_i\\quad\\text{and}\\quad F_0 = 0.\\]\nDefine the new discrete realizations \\[x=\\left\\{\n\\begin{array}{l}\n       x_1\\quad\\text{if}\\quad u\\in I_1\\\\\n       \\quad \\vdots \\\\\n       x_k\\quad\\text{if}\\quad u\\in I_k\n       \\end{array}\\right.\\]\n\n\nLemma\n\nLet \\(u\\) be a realization from \\(U[0, 1]\\) and if \\(u\\in I_i\\), set \\(x = x_i\\).\nThen \\(x\\) is an observation from the discrete distribution of \\(X\\).\n\n\nProof: Done in the lecture.\n\n\n\n\nExample: Bernoulli Distribution\n\\[X\\sim\\mathrm{Bernoulli}(p)\\quad\\text{if}\\quad\\mathbb{P}(X=1)=p\\quad\\text{and}\\quad\\mathbb{P}(X=0)=1-p.\\]\nIf \\(U\\leq p\\) define \\(X=1\\) otherwise \\(X=0\\). Then \\(X\\sim\\mathrm{Bernoulli}(p)\\).\n\n\nExample: Binomial Distribution\n\\[X\\sim\\mathrm{Binomial}(n,p)\\quad\\text{if}\\quad\\mathbb{P}(X=i)=\\binom{n}{i}p^i(1-p)^{n-1}\\quad i=1,\\dots,n.\\]\nNote: If \\(X_i\\sim\\mathrm{Bernoulli}(p)\\) i.i.d., then \\(X=\\sum_{i=1}^nX_i \\sim\\mathrm{Binomial}(n,p)\\).\nTherefore if \\(U_1,\\dots,U_n\\sim U[0,1]\\), then\n\\[X=\\sum_{i=1}^n 1_{(U_i\\leq p)}\\sim\\mathrm{Binomial}(n,p),\\] where \\(1_{(.)}\\) is the indicator function with \\(1_{(\\mathtt{TRUE})}=1\\) and zero else."
  },
  {
    "objectID": "Ch1_Random_Variable_Generation.html#generation-of-continuous-random-variables",
    "href": "Ch1_Random_Variable_Generation.html#generation-of-continuous-random-variables",
    "title": "2  Random Variable Generation",
    "section": "2.3 Generation of Continuous Random Variables",
    "text": "2.3 Generation of Continuous Random Variables\n\n2.3.1 The Inverse Method\nA very general method to generate continuous random variables is the so-called Inverse Method which builds upon the following important Lemma.\n\nLemma (Probability Integral Transform):\n\nIf \\(X\\) is a continuous random variable with distribution function \\(F(.)\\) and inverse \\(F^{-1}(.)\\), then \\[U=F(X)\\sim U[0, 1].\\] Therefore, if \\[X=F^{-1}(U),\\quad\\text{then}\\quad X\\sim F.\\]\n\n\nProof: Done in the lecture.\n\n\nExample: Exponential Distribution\nSince \\(F(x)= 1 - \\exp(-\\lambda x)\\), we have \\(F^{-1}(u) = - \\frac{log(1-u)}{\\lambda}\\).\nNote that \\(1-U\\) has the same distribution as \\(U\\), if \\(U\\sim U[0,1]\\).\nTherefore \\(-\\frac{\\log(u)}{\\lambda}\\) leads to a value from \\(\\mathrm{Exp}(\\lambda)\\).\n\n\nPROs & CONs:\n\nThe Inverse Method is a good & general way to think about things.\n\nThough, in practice, we often use other methods, since the inverse of many cdfs cannot be derived explicitly.\nFor instance: * Even the cdf \\(\\Phi(.)\\) (and therefore also its inverse \\(\\Phi^{-1}(.)\\)) of the normal density is not available in explicit terms. * For discontinuous RVs we need efficient algorithms for computing the generalized inverse of the cdf \\(F(.)\\).\n\n\n\n\n\n2.3.2 Transformation Methods\n\n\nIdea: Construct algorithms from theoretical links between distributions.\nPro: These methods can be advantageous if a distribution \\(f\\) is linked (in a relatively simple way) to another distribution that is easy to simulate.\nCon: Generally, these methods are rather case-specific, and difficult to generalize.\n\n\nExample: Building on Exponential RVs We already learned to generate an exponential RV starting from a uniform. In the following we generate RVs starting from an exponential distribution:\nIf the \\(X_i\\)s (and \\(X_j\\)s) are i.i.d. \\(\\mathrm{Exp}(1)\\) RVs, then\n\\[Y\\sim \\chi^2_{2\\nu}\\quad\\text{if}       \\quad Y= 2     \\sum_{i=1}^\\nu X_i,\\quad\\nu=1,2,\\dots \\] \\[Y\\sim \\Gamma(\\alpha,\\beta)\\quad\\text{if}\\quad Y= \\beta \\sum_{i=1}^\\alpha X_i,\\quad \\alpha=1,2,\\dots \\] \\[Y\\sim \\mathrm{Beta}(a,b)\\quad\\text{if}  \\quad Y= \\frac{\\sum_{i=1}^a X_i}{\\sum_{j=1}^{a+b} X_j},\\quad a,b=1,2,\\dots \\]\nSome Limitations:\n\nThere are more efficient algorithms to generate Gamma and Beta RVs.\nWe cannot use exponential RVs to generate Gamma RVs with a non-integer shape parameter \\(\\alpha\\). * This implies that we cannot generate a \\(\\chi^2_{1}\\) RV, which would, in turn, get us a \\(N(0,1)\\) RV. (Reminder: \\(\\chi^2_{1}\\) is identical to \\(\\Gamma(1/2, 2)\\).)\nFor that we look at the Box-Muller Theorem (1958) and the derived algorithm.\n\n\n\n\n\nExample: Normal Variable Generation\nThe well-known Box-Muller algorithm for generating (standard) normal RV is based on the following theorem:\n\nTheorem (Box and Muller, 1958)\n\nIf \\(U_1\\) and \\(U_2\\) are i.i.d. \\(U[0,1]\\), then \\[X_1 =\\sqrt{-2 \\log(U_1)}\\, \\cos(2\\pi U_2)\\quad\\text{and}\\quad X_2=\\sqrt{-2\\log(U_1)}\\,\\sin(2\\pi U_2)\\] are i.i.d. \\(N(0,1)\\).\n\n\nIdea & Proof: Done in the lecture.\n\n\nImplementation of the Box-Muller algorithm:\n\n# Implementation:\nBM_Algo <- function(){\n  # 1. Step: Generate U_1, U_2 iid U[0,1]\n  U <- runif(2)\n  # 2. Step: Transformation\n  X1 <- sqrt(-2 * log(U[1])) * cos(2 * pi * U[2])\n  X2 <- sqrt(-2 * log(U[1])) * sin(2 * pi * U[2])\n  return(c(X1, X2))\n}\n\n# Generation of Stand. Normal RVs through the Box-Muller Algo:\nset.seed(123)\nX_vec <- NULL\nfor(i in 1:500){\n  X_vec <- c(X_vec, BM_Algo())\n}\n\n# Descriptive Plots\npar(mfrow=c(1,2))\nhist(X_vec, freq = FALSE)\ncurve(dnorm, add = TRUE, col=\"blue\", lwd=1.3)\nqqnorm(X_vec)\n\n\n\n\n\n\n\n# Testing for Normality using the Shapiro-Wilk Test (H0: Normality)\nshapiro.test(X_vec)\n\n\n    Shapiro-Wilk normality test\n\ndata:  X_vec\nW = 0.99893, p-value = 0.8323\n\n\n\n\n\n\n\n\n\n2.3.3 Accept-Reject Methods\nFor many distributions it is difficult (or impossible) to apply the Inverse or Transformation Methods, since the cdf \\(F(.)\\) is somehow unusable. For instance, surprisingly often there is no explicit form of \\(F(.)\\) available or its inverse does not exists.\nAccept-Reject Methods methods can provide a solution here, since they only require the knowledge of the functional form of the density \\(f\\) of interest up to a multiplicative constant. No deep analytic study of \\(f\\) is necessary.\n\n\nGeneral Idea and theoretical justification through the Fundamental Theorem of Simulation: Done in the lecture.\n\n\nThe case of pdfs with compact support:\nThe key-idea is easily explained using a bounded pdf \\(f\\) with compact support.\nNotions:\n\nBounded means that there exists a value \\(m\\) with \\(0<m<\\infty\\) s.t. \\(f(x)\\in[0,m]\\) for all \\(x\\).\nNote that only degenerated pdfs are not bounded.\nAn interval \\([a,b]\\) is called “compact” if it is closed and the boundaries are finite.\nFor instance, the Gaussian has not a compact support, since \\(\\mathrm{supp}(\\phi)=]-\\infty,\\infty[\\).\n\nFor instance, let’s say we want to simulate random numbers \\(X\\sim f\\) with \\[\nf(x)=\\frac{3}{4}\\left(1-\\left(x-1\\right)^2\\right)\\,1_{(|x-1|\\leq 1)},\n\\] where the (compact) support of \\(f\\) is \\([a,b]=[-1,1]\\) and its range is \\([0,m]=[0,3/4]\\), i.e., \\(f\\) is bounded from above by \\(3/4\\).\n\nThe idea is then to simulate the random pair \\((Y,U)\\sim\\mathrm{Unif}([a,b]\\times[0,m])\\) by simulating\n \\[Y\\sim\\mathrm{Unif}[a,b]\\quad\\text{and}\\quad U|Y=y \\sim \\mathrm{Unif}[0,m], \\] but to accept the pair \\((Y,U)\\) only if \\(U\\leq f(Y)\\) and to reject all others.\nThis results in the correct distribution of the accepted value of \\(Y\\), call it \\(X\\), because \\[\n\\mathbb{P}(X\\leq x)=\\mathbb{P}(Y\\leq x|U\\leq f(Y))\n=\\frac{\\int_a^{\\color{red}x} \\int_0^{f(y)}\\,1\\,du\\,dy}{\\int_a^{\\color{red}b}\\int_0^{f(y)}\\,1\\,du\\,dy}\n=\\frac{\\int_a^x f(y)\\,dy}{\\int_a^b f(y)\\,dy}\n=\\int_a^x f(y)dy,\n\\]\nwhere we used that \\(f(y)=\\int_{0}^{f(y)}du\\).\nThe Accept-Reject Algorithm (Simple Version):\n# Accept-Reject Algorithm:\nY <- runif(n, min = a, max = b) \nU <- runif(n, min = 0, max = m) \n# A-R Step:\naccept <- U <= f(Y)\nX      <- Y[accept]\nIn the following you see a graphical illustration of this procedure:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe good thing is that we only need to evaluate the pdf \\(f(.)\\); nothing more.\n\n\nGeneralization: pdfs with non-compact support.\nThe larger set does not necessarily need to be a surrounding closed box as used above. In fact, it can be any “larger set”, enclosing the pdf \\(f\\), as long as simulating uniformly over this larger set is feasible. This generalization allows for cases where the support of \\(f\\) is unbounded.\nLet the larger set denote by \\[\n\\mathscr{L}=\\{(y,u):\\, 0<u<m(y)\\},\n\\] where:\n\nsimulation of a uniform on \\(\\mathscr{L}\\) is feasible and\n\n\\(m(x)\\geq f(x)\\) for all \\(x\\).\n\n\n\nFrom the feasibility-requirement it follows that \\(m(.)\\) is necessarily integrable, i.e., that \\[\\int_{\\mathcal{X}}m(x)dx=M,\\] where \\(M\\) exists and is finite (and positive), since otherwise, \\(\\mathscr{L}\\) would not have finite mass and a uniform distribution would not exists on \\(\\mathscr{L}\\).\n\n\nIntegrability of \\(m(.)\\) is crucial here, since it allows us to relate \\(m(.)\\) with a corresponding (auxiliary) pdf \\(g(.)\\) as following: \\[m(x)=M\\,g(x),\\quad\\text{where}\\quad\\int_{\\mathcal{X}}m(x)\\,dx=\\int_{\\mathcal{X}}M\\,g(x)\\,dx=M.\\]\nTerminology:\n\nThe pdf \\(g(.)\\) is called the instrumental density. (Choose \\(g(.)\\) as a pdf from which it is easy to simulate!)\nThe pdf \\(f(.)\\) is called the target density.\n\n\n\nIn order to simulate the pair \\((Y,U)\\sim\\mathrm{Unif}(\\mathscr{L})\\) we can now simulate \\[Y\\sim g\\quad\\text{and}\\quad U|Y={\\color{red}y}\\sim\\mathrm{Unif}[0,M\\,g({\\color{red}y})],\\] but accept the pair \\((Y,U)\\) only if \\(U\\leq f(Y)\\) and to reject all others.\nThis results in the correct distribution of the accepted value of \\(Y\\), call it \\(X\\), because \\[\n\\mathbb{P}(X\\in A)=\\mathbb{P}(Y\\in A|U\\leq f(Y))\n=\\frac{\\int_{\\color{red}A}\\int_0^{f(y)}\\,\\frac{1}{M}\\,du\\,dy}{\\int_\\mathcal{X}\\int_0^{f(y)}\\,\\frac{1}{M}\\,du\\,dy}\n=\\frac{\\int_A f(y)\\,dy}{\\int_\\mathcal{X} f(y)\\,dy}\n=\\int_A f(y)dy,\n\\] for every set \\(A\\),  where we again used that \\(f(y)=\\int_{0}^{f(y)}du\\).\nNote that the above derivation implies that we only need to know the pdf \\(f(.)\\) up to an unkown multiplicative constant \\(c>0\\). I.e., it is enough to know \\(f(x)=c\\,\\tilde{f}_{\\textrm{true}}(x)\\), often written as \\(f(x)\\propto \\tilde{f}_{\\textrm{true}}(x)\\), since the unknown constant \\(c\\) cancels out in the above quotient anyways. This is not so much of importance for us, but useful in Bayesian Statistics.\n\n\nAll this leads to a more general version of the Fundamental Theorem of Simulation:\n\nFundamental Theorem of Simulation (General Version):\n\nLet \\(X\\sim f\\) and let \\(g(.)\\) be a pdf s.t. \\(f(x)\\leq M\\,g(x)\\) for some \\(M\\) with \\(1\\leq M<\\infty\\) and all \\(x\\). Then to simulate \\(X\\sim f\\) it is sufficient to generate \\[Y\\sim g\\quad\\text{and}\\quad U|Y=y\\sim\\mathrm{Unif}[0,M\\,g(y)]\\] if one accepts the pair \\((Y,U)\\) only if \\(U\\leq f(Y)\\) and rejects all others.\n\n\n\n\nThe Accept-Reject Algorithm (General Version):\n# Accept-Reject Algorithm:\nY   <- generate n random numbers from g(.)\n\n# Specify function m():\nm <- function(y){YOUR CODE}\n\nU   <- numeric(n)\nfor(i in 1:n){\n  U[i] <- runif(n=1, min = 0, max = m(Y[i])) \n}\n\n# A-R Step:\naccept <- U <= f(Y)\nX      <- Y[accept]\n\n\nExample\nLet the target “density” be \\[f(x)\\propto \\exp(-x^2/2)\\,(\\sin(6x)^2 + 3\\cos(x)^2\\,\\sin(4x)^2 + 1)\\] with upper bound (or, rather, dominating density) the standard normal density \\[g(x)=\\exp(-x^2/2)/\\sqrt{2\\pi},\\] which is obviously straightforward to generate.\nIn this example we can set \\(m(x)=M\\,g(x)\\) with \\(M=1\\), since we can simply scale the target “density” \\(f\\) such that \\(f(x)\\leq g(x)\\) for all \\(x\\). Specifically, we set \\(f(x)=0.075 \\cdot \\exp(-x^2/2)\\,(\\sin(6x)^2 + 3\\cos(x)^2\\,\\sin(4x)^2 + 1)\\).\nIn the following you see the graphical illustration of this example:\n\n\n\n\n\n\n\n\n\n\n\n\nEfficiency of the Accept-Reject algorithm:\nStatements with respect to the efficiency of the Accept-Reject algorithm can be made if \\(f\\) and \\(g\\) are normalized such that they are both pdfs. Then:\n\nThe constant \\(M\\) is necessarily larger than \\(1\\).\nThe probability of acceptance is \\(1/M\\). (See Exercises.)\n\\(M\\) is interpreted as the efficiency of the Accept-Reject algorithm. (The closer \\(M\\) is to \\(1\\) the better.)\n\\(M\\) is a function of how closely \\(g\\) can imitate \\(f\\).\n\nNote that, for such normalized \\(f\\) and \\(g\\) the inequality \\(f(x)\\leq M\\,g(x)\\) with \\(1\\leq M<\\infty\\) for all \\(x\\) is equivalent to saying that the quotient \\(f/g\\) is bounded, i.e., that \\[\n0\\leq \\frac{f(x)}{g(x)}\\leq M <\\infty\\quad\\text{for all}\\quad x.\n\\] That is, it is necessary for \\(g\\) to have, e.g., thicker tails than \\(f\\). This makes it, for instance, impossible to simulate a Cauchy distribution \\(f\\) using a normal distribution \\(g\\). The reverse, however, works quite well. \n\n\nExample: Normals from Double Exponentials\nConsider generating a \\(N(0,1)\\) by the Accept-Reject algorithm using a double-exponential distribution \\(\\mathcal{L}(\\alpha)\\), also called Laplace distribution, with density \\(g(x|b)=(1/(2b))\\exp(-\\,|x|/b)\\).  It is then straightforward to show that \\[\n\\frac{f(x)}{g(x|b)}\n%=\\frac{\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}x^2\\right)}{\\frac{1}{2b}\\exp\\left(-\\frac{|x|}{b}\\right)}\n%=\\sqrt{\\frac{2}{\\pi}}\\,b\\,\\exp\\left(-\\frac{1}{2}x^2+\\frac{|x|}{b}\\right)\n\\leq\\sqrt{\\frac{2}{\\pi}}\\,b\\,\\exp\\left(\\frac{1}{2\\,b^2}\\right)\n\\] and that the minimum of the bound (in \\(b\\)) is attained for \\(b=1\\).\nThis leads to the following optimal (i.e. most efficient) specification of the double-exponential distribution as instrumental pdf: \\[\n\\frac{f(x)}{g(x|1)}\n\\leq M=\\sqrt{\\frac{2}{\\pi}}\\,\\exp\\left(\\frac{1}{2}\\right).\n\\]\nThe probability of acceptance is then \\(\\sqrt{\\pi/(2e)}=0.76\\). I.e., to produce one normal random variable, this Accept-Reject algorithm requires on the average \\(1/0.76\\approx 1.3\\) uniform variables. This is to be compared with the Box-Muller algorithm for which the ratio between produced normals and required uniforms is 1."
  },
  {
    "objectID": "Ch1_Random_Variable_Generation.html#classical-monte-carlo-integration",
    "href": "Ch1_Random_Variable_Generation.html#classical-monte-carlo-integration",
    "title": "2  Random Variable Generation",
    "section": "3.1 Classical Monte Carlo Integration",
    "text": "3.1 Classical Monte Carlo Integration\nThe generic problem here is the evaluation of integrals. (Be aware: Integrals are everywhere in statistics!). For instance, \\[\n\\mathbb{E}_f\\left(h(X)\\right)=\\mathbb{E}\\left(h(X)\\right)=\\int_\\mathcal{X}h(x)\\,f(x)\\,dx.\n\\]\nConvergence:\nGiven our previous developments, it is natural to propose using a realization \\(x_1,\\dots,x_m\\) from a (pseudo random) i.i.d. sample \\(X_1,\\dots,X_m\\) with each \\(X_j\\) distributed as \\(X\\sim f\\) to approximate the above integral by the empirical mean \\[\n\\bar{h}_m=\\frac{1}{m}\\sum_{j=1}^m h(x_j).\n\\] By the Strong Law of Large Numbers we know that the empirical mean \\(\\bar{h}_m\\) converges almost surely (a.s.) to the desired limit \\(\\mathbb{E}\\left(h(X)\\right)\\) as \\(m\\to\\infty\\). (The only prerequisits are that \\(f\\) has finite first moments, i.e., \\(\\mathbb{E}\\left(h(X)\\right)<\\infty\\), and that \\(\\bar{h}_m\\) is constructed from an i.i.d. sample \\(X_1,\\dots,X_m\\).)\nAs we can use the computer to produce realizations from the i.i.d. sample \\(X_1,\\dots,X_m\\), we can in principle choose an arbitrary large sample size \\(m\\) such that \\(\\bar{h}_m\\) can (in principle) be arbitrarily close to the desired limit \\(\\mathbb{E}\\left(h(X)\\right)\\).\nThough, …\n\n… which sample size \\(m\\) is large enough?\nOr “equivalently”: How fast converges \\(\\bar{h}_m\\) to the desired limit \\(\\mathbb{E}\\left(h(X)\\right)\\)?\n\n\n\nSpeed of Convergence:\nOK, we know now that \\(\\bar{h}_m\\) reaches its limit (here in the “almost surely” sense) as \\(m\\to\\infty\\) under some rather loose conditions on the random sample \\(X_1,\\dots,X_m\\).\nIf we are willing to additionally assume that \\(f\\) has finite second moments, i.e., \\(\\mathbb{E}(h(X)^2)<\\infty\\), we can additionally say something about how fast \\(\\bar{h}_m\\) converges (a.s.) to \\(\\mathbb{E}(h(X))\\).\nThe speed of convergence of the stochastic sequence \\(\\{\\bar{h}_m\\}\\) (i.e., now we think of \\(\\bar{h}_m\\) as the {RV} \\(\\bar{h}_m=\\frac{1}{m}\\sum_{j=1}^m h({\\color{red}{X_{j}}})\\)) to its limit \\(\\mathbb{E}(h(X))\\) can be assessed by answering the question how fast the standard deviation (which is a function of \\(m\\)) of the stochastic sequence converges to zero as \\(m\\to\\infty\\).\n\nThe variance of \\(\\bar{h}_m\\) is given by \\[\n\\mathbb{V}_f\\left(\\bar{h}_m\\right)=\n\\mathbb{V}\\left(\\frac{1}{m}\\sum_{j=1}^m h(X_j)\\right)=\n\\frac{1}{m}\\mathbb{V}\\left(h(X)\\right)\n\\]\nNote that assuming finite second moments \\(\\mathbb{E}(h(X)^2)<\\infty\\) is equivalent to assuming finite variance \\(\\mathbb{V}\\left(h(X)\\right)<\\infty\\). Consequently, we can set \\(\\mathtt{const}=\\sqrt{\\mathbb{V}\\left(h(X)\\right)}\\) with \\(0<\\mathtt{const}<\\infty\\) such that \\[\n\\sqrt{\\mathbb{V}\\left(\\bar{h}_m\\right)}=m^{-1/2}\\mathtt{const}\\propto m^{-1/2}.\n\\]\n\nI.e., the speed of convergence (or rate) of the stochastic sequence \\(\\{\\bar{h}_m\\}\\) is proportional to the deterministic sequence \\(\\{m^{-1/2}\\}\\).\n\n\nRemark: Even if we would not know the value of \\(\\mathtt{const}=\\sqrt{\\mathbb{V}\\left(h(X)\\right)}\\), we know now that the improvement from \\(m=10\\) to \\(m=100\\) will be much higher than from \\(m=110\\) to \\(m=200\\). In practice, a typical choice is \\(m=10000\\); for moderate standard deviations this choice will guarantee a very good approximation.\n\n\nLimit Distribution:\nOf course, we can estimate the variance of the estimator \\(\\mathbb{V}\\left(\\bar{h}_m\\right)\\) by its empirical version \\[\nv_m=\\frac{1}{m}\\left(\\frac{1}{m}\\sum_{j=1}^m\\left(h(x_j)-\\bar{h}_m\\right)^2\\right),\n\\] where again by the Strong Law of Large Numbers (SLLN) \\[\n\\left(\\frac{1}{m}\\sum_{j=1}^m\\left(h(x_j)-\\bar{h}_m\\right)^2\\right)\\to_{\\text{a.s.}}\\mathbb{V}\\left(h(X)\\right).\n\\]  By the Central Limit Theorem (CLT) we have \\[\n\\sqrt{m}\\left(\\frac{\\bar{h}_m - \\mathbb{E}\\left(h(X)\\right)}{\\sqrt{\\mathbb{V}\\left(h(X)\\right)}}\\right)\\to_d Z,\n\\] where \\(Z\\sim N(0,1)\\). Note that the the above sequence \\(\\{\\sqrt{m}\\}\\) just hinders the convergence of the sequence \\(\\bar{h}_m - \\mathbb{E}\\left(h(X)\\right)\\to_{a.s.}0\\) such that the quotient converges to a “stable” distribution.\nThe above result can now be used for the construction of (asymptotically valid) convergence tests and confidence intervals with respect to \\(\\bar{h}_m\\), since for large \\(m\\) \\[\n\\bar{h}_m\\,\\overset{d}{\\approx} N\\left(\\mathbb{E}\\left(h(X)\\right),\\frac{\\mathbb{V}\\left(h(X)\\right)}{m}\\right).\n\\]\nAnd as we can use the computer to generate realizations of the i.i.d. sample \\(X_1,\\dots,X_m\\) from a generic \\(X\\sim f\\), we can easily approximate the mean \\(\\mathbb{E}\\left(h(X)\\right)\\) and the variance \\(\\mathbb{V}\\left(h(X)\\right)\\) with arbitrary accuracy as \\(m\\to\\infty\\); by the SLLN (or the WLLN).\n\n\nExample: A first Monte Carlo Integration\nLet’s say we want to integrate the function \\(h(x)=\\left(\\cos(50\\,x)+\\sin(20\\,x)\\right)^2\\). Although this function could be integrated analytically it is a good first test case. The left plot below shows the graph of the function \\(h(.)\\).\nTo approximate the integral \\[\n\\int_\\mathcal{X}h(x)dx\\quad\\text{with}\\quad\\mathcal{X}=[0,1]\n\\] we can use that \\[\n\\int_\\mathcal{X}h(x)dx=\\int_\\mathcal{[0,1]}1\\cdot h(x)dx =\\mathbb{E}_{f_\\text{Unif[0,1]}}(h(X)).\n\\]\nThus, we generate a realization \\((u_1,\\dots,u_n)\\) from the i.i.d. random sample \\(U_1,\\dots,U_n\\sim[0,1]\\) and approximate \\[\n\\int_\\mathcal{X}h(x)dx\\approx \\bar{h}_n=\\frac{1}{n}\\sum_{i=1}^n h(u_i).\n\\]\nIn order to assess how good this approximation is, we need to consider the stochastic propoerties of the RV \\[\n\\frac{1}{n}\\sum_{i=1}^n h(U_i).\n\\] This is done using the above (review of) results on the limit distribution of the sample mean which allows us to construct an approximative \\(95\\%\\) confidence interval, since for large \\(n\\) \\[\n\\left[\\bar{h}_n - 1.96\\frac{\\mathtt{std.error}_n}{\\sqrt{n}}, \\bar{h}_n + 1.96\\frac{\\mathtt{std.error}_n}{\\sqrt{n}}\\right]\\approx\n\\left[\\bar{h}_n - 1.96  \\sqrt{\\frac{\\mathbb{V}(h(U_i))}{n}}, \\bar{h}_n + 1.96  \\sqrt{\\frac{\\mathbb{V}(h(U_i))}{n}}\\right],\n\\] where \\(\\mathtt{std.error}_n^2=n^{-1}\\sum_{i=1}^n(h(u_i)-\\bar{h}_n)^2\\).\nThe right plot below shows one realization of the stochastic sequence \\(\\{\\bar{h}_1,\\dots,\\bar{h}_n\\}\\) with \\(n=10000\\), where the realized value of \\(\\bar{h}_n\\) is \\(0.966\\). This compares favorably with the with the exact value of \\(0.965\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemarks:\n\nThe approach followed in the above example can be successfully utilized in many cases, even though it is often possible to achieve greater efficiency through numerical methods (e.g., Riemann Sum, Trapezoidal Rule, Simpson’s Rule, etc.) in dimensions 1 or 2.\nThe approach is particularly useful for approximating integrals over higher dimensional sets.\n\n\n\nExample: Approximation of Normal Distribution Tables\nA possible way to construct normal distribution tables is to use MC simulations.\nGenerate a realization \\((x_1,\\dots,x_n)\\) from an i.i.d. standard normal random sample, e.g., using the Box-Muller algorithm.\nThe approximation of the standard normal cdf \\[\n\\Phi(t)=\\int_{-\\infty}^t\\frac{1}{\\sqrt{2\\pi}}e^{-y^2/2}dy\n\\] by the Monte Carlo method is thus \\[\n\\hat{\\Phi}_n(t)=\\frac{1}{n}\\sum_{i=1}^n 1_{(x_i\\leq t)}.\n\\] The corresponding RV \\(\\hat{\\Phi}_n(t)=\\frac{1}{n}\\sum_{i=1}^n1_{(X_i\\leq t)}\\) has (exact) variance \\[\n\\mathbb{V}(\\hat{\\Phi}_n(t))=\\frac{\\Phi(t)(1-\\Phi(t))}{n},\n\\] since the single RVs \\(1_{(X_i\\leq t)}\\) are independent Bernoulli with success probability \\(\\Phi(t)\\).\nFor values of \\(t\\) around \\(t=0\\), the variance is thus approximately \\(1/4n\\).\nTo achieve a precision of four decimals by means of a \\(99.9\\%\\) confidence interval, the approximation requires on average \\(n\\approx 10^8\\) simulations.\nThe table below gives the evolution of this approximation for several values of \\(t\\) and shows a very accurate evaluation for \\(n=10^8\\).\n\n\n\\[\n\\begin{array}{cccccccccc}\n\\hline\nn   &t=0.0  &t=0.67 &t=0.84 &t=1.28 &t=1.65 &t=2.32 &t=2.58 &t=3.09 &t=3.72 \\\\\n\\hline\n10^2 &0.485  &0.74   &0.77   &0.9    &0.945  &0.985  &0.995  &1      &1      \\\\\n10^3 &0.4925 &0.7455 &0.801  &0.902  &0.9425 &0.9885 &0.9955 &0.9985 &1      \\\\\n10^4 &0.4962 &0.7425 &0.7941 &0.9    &0.9498 &0.9896 &0.995  &0.999  &0.9999 \\\\\n10^5 &0.4995 &0.7489 &0.7993 &0.9003 &0.9498 &0.9898 &0.995  &0.9989 &0.9999 \\\\\n10^6 &0.5001 &0.7497 &0.8    &0.9002 &0.9502 &0.99   &0.995  &0.999  &0.9999 \\\\\n10^7 &0.5002 &0.7499 &0.8    &0.9001 &0.9501 &0.99   &0.995  &0.999  &0.9999 \\\\\n10^8 &0.5    &0.75   &0.8    &0.9    &0.95   &0.99   &0.995  &0.999  &0.9999 \\\\\n\\end{array}\n\\]\n\n\nRemarks:\n\nTo achieve a precision of two decimals by means of a \\(99.9\\%\\) confidence interval, already \\(n=10^4\\) leads to satisfactory results.\nNote that greater accuracy is achieved in the tails and that more efficient simulation methods could be used (e.g., Importance Sampling)."
  },
  {
    "objectID": "Ch1_Random_Variable_Generation.html#importance-sampling",
    "href": "Ch1_Random_Variable_Generation.html#importance-sampling",
    "title": "2  Random Variable Generation",
    "section": "3.2 Importance Sampling",
    "text": "3.2 Importance Sampling\nImportance sampling aims to reduce the variance of the Monte Carlo integral estimate therefore it’s refereed to as a variance reduction technique. This variance reduction is achieved by weighting functions, so-called importance functions.\nAs in the case of Monte Carlo integration the focus lies on evaluating the integral \\[\n\\mathbb{E}_f(h(X))=\\int_\\mathcal{X}h(x)f(x)\\,dx.\n\\]\n\nThough, it turns out that the above approach, i.e., sampling from \\(f\\) is often suboptimal.\nObserve that the value of the above integral can be represented by infinitely many alternative choices of the triplet \\((\\mathcal{X}, h, f)\\). Therefore, the search for an optimal estimator should encompass all these possible representations.\n\nLet’s illustrate this with a simple example.\nExample: Cauchy Tail Probability (from Ripley 1987)\nSuppose that the quantity of interest is the probability, say \\(p\\), that a Cauchy \\(\\mathrm{C}(0,1)\\) RV is larger than \\(2\\), i.e.: \\[\np=\\int_{2}^{+\\infty}\\frac{1}{\\pi(1+x^2)}\\,dx.\n\\]\n1. Naive Approach: If \\(p\\) is approximated through the empirical mean \\[\n\\hat{p}_{1}=\\frac{1}{m}\\sum_{j=1}^m1_{(X_j>2)}\n\\] of an i.i.d. sample \\(X_1,\\dots,X_m\\sim\\mathrm{C}(0,1)\\), then the variance of this estimator, a binomial RV scaled by \\(1/m\\), is \\[\n\\mathbb{V}(\\hat{p}_{1})=\\frac{1}{m^2}\\mathbb{V}\\left(\\sum_{j=1}^m1_{(X_j>2)}\\right)=\\frac{p(1-p)}{m},\n\\] which is equal to \\(0.1275/m\\), since (we already know that) \\(p=0.15\\).\n\n\n2. Accounting for Symmetry (i.e., using the ‘Adjusting Screws’ \\(\\mathcal{X}\\) and \\(h\\)): We can achieve a more efficient estimator (i.e., an estimator with lower variance for a given same sample size \\(n\\)) if we take into account the symmetric nature of \\(\\mathrm{C}(0,1)\\). Obviously, our target integral can be equivalently written as \\[\np=\\frac{1}{2}\\left(\\int_{-\\infty}^{-2}\\frac{1}{\\pi(1+x^2)}\\,dx + \\int_{2}^{+\\infty}\\frac{1}{\\pi(1+x^2)}\\,dx \\right).\n\\] This representation has the attractive feature that we can use a much higher fraction of the simulated data by using the following new empirical mean: \\[\n\\hat{p}_{2}=\n\\frac{1}{2}\\left(\\frac{1}{m}\\sum_{j=1}^m1_{(X_j<-2)}+ \\frac{1}{m}\\sum_{j=1}^m1_{(X_j>2)}\\right)\\;=\\;\n\\frac{1}{2m}\\sum_{j=1}^m1_{(|X_i|>2)}.\n\\] The variance of this new estimator, \\[\n\\mathbb{V}(\\hat{p}_{2})=\\frac{1}{4m^2}\\mathbb{V}\\left(\\sum_{j=1}^m1_{(|X_i|>2)}\\right)=\\frac{2p(1-2p)}{4m},\n\\] is equal to \\(0.0525/m\\), i.e., lower than in the naive approach.\n\n\n3. Using all ‘Adjusting Screws’ \\(\\mathcal{X}\\), \\(h\\), and \\(f\\): The (relative) inefficiency of the above approaches is due to the generation of RVs outside the domain of interest, \\([2,+\\infty)\\), which are in some sense irrelevant for the approximation of \\(p\\). This motivates the following reformulation of \\(p\\):\nBy symmetry of \\(f\\): \\[\n\\frac{1}{2}=\\int_{0}^2\\frac{1}{\\pi(1+x^2)}dx + \\underbrace{\\int_{2}^{+\\infty}\\frac{1}{\\pi(1+x^2)}dx}_{=p}\n\\] \\[\n\\Leftrightarrow \\; p=\\frac{1}{2}-\\int_{0}^2\\frac{1}{\\pi(1+x^2)}dx.\n\\] Furthermore, we can re-arrange the last integral a bit such that \\[\n\\int_{0}^2\\;\\left(\\frac{1}{2}\\cdot 2\\right)\\;\\frac{1}{\\pi(1+x^2)}\\,dx =\n\\int_{0}^2\\;\\underbrace{\\frac{1}{2}}_{f_{\\mathrm{Unif}[0,2]}}\\;\\underbrace{\\frac{2}{\\pi(1+x^2)}}_{=h(x)}\\,dx =\n\\mathbb{E}(h(U)),\\quad\\text{where}\\quad U\\sim\\mathrm{Unif}[0,2].\n\\]\nTherefore a new alternative method for evaluating \\(p\\) is: \\[\n\\hat{p}_{3}=\\frac{1}{2} - \\frac{1}{m}\\sum_{j=1}^m h(U_j),\\quad\\text{where}\\quad U_j\\sim\\mathrm{Unif}[0,2].\n\\] Using integration by parts, it can be shown that \\(\\mathbb{V}(\\hat p_3)=0.0285/m\\). (Compare this to the former results: \\(\\mathbb{V}(\\hat{p}_{2})=0.0525/m\\) and \\(\\mathbb{V}(\\hat{p}_{1})=0.1275/m\\).)\n\n\nA More General Point of View:\nThe idea of importance sampling is related to weighted and stratified sampling ideas. As illustrated by the above example, when estimating \\[\n\\theta=\\mathbb{E}_f(h(X))=\\int h(x)f(x)dx.\n\\]\nSome outcomes of \\(X\\sim f\\) may be more important than others in determining \\(\\theta\\) and we wish to select such values more frequently.\nFor instance, if \\(\\theta\\) denotes the probability of the occurrence of a very rare event, then the only way to estimate \\(\\theta\\) at all accurately may be to produce the rare events more frequently.\nTo achieve this, we can simulate a model which gives pdf \\(g\\) to \\(X\\) instead of the correct pdf \\(f\\), where both pdfs need to be known. This can be easily done, since \\[\n\\theta=\\mathbb{E}_f(h(X))=\\int h(x)\\left(\\frac{g(x)}{g(x)}\\right)\\;f(x)dx=\n\\int \\underbrace{\\left(h(x)\\frac{f(x)}{g(x)}\\right)}_{=\\psi(x)}\\;g(x)dx=\n\\int \\psi(x)\\;g(x)dx=\n\\mathbb{E}_g(\\psi(X)).\n\\]\nThis leads to the following unbiased estimator for \\(\\theta\\) based on sampling from \\(g\\): \\[\n\\hat{\\theta}_g=\\frac{1}{n}\\sum_{i=1}^n\\psi(X_i)\\quad\\text{with}\\quad X_i\\sim g,\n\\] which is a weighted mean of the \\(h(X_i)\\) with weights inversely proportional to the “selection factor” \\(\\frac{g(X_i)}{f(X_i)}\\). \nFor the variance of the estimator \\(\\hat{\\theta}_g\\) we have \\[\n\\mathbb{V}(\\hat{\\theta}_g)=\\frac{1}{n}\\mathbb{V}(\\psi(X_i))=\n\\frac{1}{n}\\int\\left(\\psi(x)-\\theta\\right)^2g(x)dx=\n\\frac{1}{n}\\int\\left(\\frac{h(x)\\,f(x)}{g(x)}-\\theta\\right)^2g(x)dx,\n\\] which, depending on the choice of \\(g(.)\\), can be much smaller (or larger) than the variance of the naive estimator from the classical Monte Carlo Integration using the ordinary empricial mean. \n\n\n\n\nMinimum Variance Theorem\n\nThe importance function \\(g(.)\\) which minimizes the variance \\(\\mathbb{V}(\\psi(X_i))\\), and therefore the variance \\(\\mathbb{V}(\\hat{\\theta}_g)\\), is given by \\[\ng^\\ast(x)=\\frac{|h(x)|f(x)}{\\int |h(z)|f(z)dz}.\n\\]\n\n\nProof: Done in the lecture.\n\n\nThough, this result is rather formal (in the sense of “impractical”), since, e.g., if \\(h(x)>0\\) then \\(g^\\ast\\) requires us to know \\(\\int h(z)f(z)dz\\), which is just the integral of interest!\nRemarks:\nThe above minimum variance result is still useful:\n\nIt tells us that a good choice of \\(g(x)\\) shall mimic the shape of \\(|h(x)|f(x)\\), since the optimal \\(g^\\ast(x)\\propto |h(x)|f(x)\\).\nFurthermore, \\(g(x)\\) should be chosen such that it has a thicker tail than \\(f(x)\\), since the variance \\(\\mathbb{V}(\\hat{\\theta}_g)\\) crucially depends on the quotient \\(f(x)/g(x)\\) which would “explode” for \\(g(x)\\approx 0\\).\n\n\n\nLet’s apply our new insights to the above example on the Cauchy tail probability \\(p\\).\nExample: Cauchy Tail Probability (cont.)\nAbove we had:\n\n\\(f(x)=\\frac{1}{\\pi(1+x^2)}\\), the pdf of \\(\\mathrm{C}(0,1)\\) and\n\\(h(x)=1_{(x>2)}\\), i.e., here \\(|h(x)|=h(x)\\).\n\nTherefore \\[\np=\\mathbb{E}_f(h(X))=\\int h(x)f(x)dx=\\int_{2}^{\\infty}f(x)dx=\\int_{2}^{\\infty}\\underbrace{\\frac{f(x)}{g(x)}}_{=\\psi(x)}\\;g(x)dx=\\mathbb{E}_g(\\psi(X)),\n\\] where the \\(h\\) function is absorbed by the formulation of the definite integral.\nA possibly good (and simple) choice of \\(g\\) is, e.g., \\(g(x)=2/(x^2)\\), since this function:\n\n“closely” matches \\(h(x)f(x)\\) and\n\\(g\\) has thicker tails than \\(f\\).\n\n\n\n\n\n\n\n\n\n\n\n\nCaution: It is not straight forward to directly sample from \\(g\\), therefore we need some further steps:\n\n\nThe choice of \\(g\\) leads to \\[\np=\\mathbb{E}_g(\\psi(X))=\n\\int_{2}^{+\\infty}\\left(\\frac{x^2}{2\\,\\pi(1+x^2)}\\right)\\,\\frac{2}{x^2}\\,dx=\n\\int_{2}^{+\\infty}\\left(\\frac{1}{\\pi(1+x^{-2})}\\right)\\,x^{-2}\\,dx.\n\\]\n\n\nNow we can apply some additional (rather case-specific) re-arrangements:\nIntegration by substitution (substituting \\(u=x^{-1}\\)) yields: \\[\np=\\int_{0}^{1/2}\\frac{1}{\\pi(1+u^2)}du.\n\\] Again, we can re-arrange the last integral a bit such that \\[\np=\\int_{0}^{1/2}\\underbrace{2}_{f_{\\mathrm{Unif}[0,1/2]}}\\;\\underbrace{\\frac{1}{2\\,\\pi(1+u^2)}}_{=h(u)}\\,du=\\mathbb{E}(h(U)),\\quad\\text{where}\\quad U\\sim\\mathrm{Unif}[0,1/2].\n\\] Therefore, we have a final fourth version of the estimator of \\(p\\): \\[\n\\hat{p}_4=\\sum_{j=1}^m h(U_j),\\quad\\text{where}\\quad U\\sim\\mathrm{Unif}[0,1/2]\n\\] and \\(h(u)=1/(2\\pi(1+u^2))\\).\nThe variance of \\(\\hat{p}_4\\) is \\((\\mathbb{E}(h(U)^2)-\\mathbb{E}(h(U))^2)/m\\) and an integration by parts shows that \\(\\mathbb{V}(\\hat{p}_4)=0.95\\cdot 10^{-4}/m\\). Compare this to the former results: \\(\\mathbb{V}(\\hat p_3)=0.0285/m\\), \\(\\mathbb{V}(\\hat{p}_{2})=0.0525/m\\) and \\(\\mathbb{V}(\\hat{p}_{1})=0.1275/m\\). The variance of \\(\\hat{p}_4\\) is by a factor of \\(10^{-3}\\) lower than the variance of the original \\(\\hat{p}_1\\)."
  },
  {
    "objectID": "Ch_Bootstrap.html#the-empirical-distribution-function",
    "href": "Ch_Bootstrap.html#the-empirical-distribution-function",
    "title": "3  An Introduction to the Bootstrap",
    "section": "3.1 The empirical distribution function",
    "text": "3.1 The empirical distribution function\nThe distribution of a real-valued random variable \\(X\\) can be completely described by its distribution function \\[F(x)=P(X\\leq x)\\quad \\text{for all } x\\in\\mathbb{R}.\\]\nData: i.i.d. random sample \\(X_1,\\dots,X_n\\)\nFor given data, the sample analogue of \\(F\\) is the so-called empirical distribution function, which is an important tool of statistical inference.\nLet \\(I(\\cdot)\\) denote the indicator function, i.e., \\(I(x\\leq t)=1\\) if \\(x\\leq t\\), and \\(I(x\\leq t)=0\\) if \\(x>t.\\)\n\nDefinition 3.1 (Empirical distribution function) \\[\nF_n(x)=\\frac{1}{n} \\sum_{i=1}^n I(X_i\\leq x)\n\\] i.e \\(F_n(x)\\) is the proportion of observations with \\(X_i\\le x,\\) \\(i=1,\\dots,n.\\)\n\nProperties:\n\n\\(0\\le F_n(x)\\le 1\\)\n\\(F_n(x)=0\\), if \\(x<X_{(1)}\\), where \\(X_{(1)}\\leq X_{(2)}\\leq \\dots \\leq X_{(n)}\\) denotes the order-statistic; i.e. \\(X_{(1)}\\) is the smallest observation\n\\(F(x)=1\\), if \\(x\\ge X_{(n)}\\), where \\(X_{(n)}\\) is largest observation\n\\(F_n\\) monotonically increasing step function\nStructurally, \\(F_n\\) itself is a distribution function; it is equivalent to the distribution function of a discrete random variable \\(X^*\\) with possible values \\(X^*\\in\\{X_1,\\dots,X_n\\}\\) and with \\(P(X^*=X_i)=\\frac{1}{n}\\) for all \\(i=1,\\dots,n.\\)\n\n\nExample 3.1 (Empirical distribution function) \nSome data:\n\n\n\n\\(i\\)\n\\(X_i\\)\n\n\n\n\n1\n5.20\n\n\n2\n4.80\n\n\n3\n5.40\n\n\n4\n4.60\n\n\n5\n6.10\n\n\n6\n5.40\n\n\n7\n5.80\n\n\n8\n5.50\n\n\n\nCorresponding empirical distribution function using R:\n\nobservedSample <- c(5.20, 4.80, 5.40, 4.60, \n                    6.10, 5.40, 5.80, 5.50)\n\nmyecdf_fun     <- ecdf(observedSample)\n\nplot(myecdf_fun, main=\"\")\n\n\n\n\n\n\\(F_n(x)\\) depends on the observed sample and thus is random. We obtain\n\nFor every \\(x\\in\\mathbb{R}\\) \\[\nnF_n(x)\\sim B(n, p=F(x))\n\\] I.e., \\(nF_n(x)\\) has a binomial distribution with parameters \\(n\\) and \\(p=F(x)\\).\n\\(E(F_n(x))=F(x)\\)\n\\(Var(F_n(x))=\\frac{F(x)(1-F(x))}{n}\\)\n\n\nTheorem 3.1 (Theorem of Glivenko-Cantelli) \\[\nP\\left(\\lim_{n\\rightarrow\\infty} \\sup_{x\\in\\mathbb{R}} |F_n(x)-F(x)|=0\\right)=1\n\\]"
  }
]