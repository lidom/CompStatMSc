## Solutions {-}

#### Solutions of Exercise 1. {-} 

##### (a) Likelihood function {-}

The probability mass function of $X\sim\text{Bernoulli}(p)$ is 
$$
f(x)=p^{x}(1-p)^{1-x},\quad\text{with}\quad x\in\{0,1\}.
$$
Thus the likelihood function is
$$
\begin{align*}
\mathcal{L}(p|\mathbf{x})   & = \prod_{i=1}^n p^{x_i}(1-p)^{1-x_i}\\
\mathcal{\ell}(p|\mathbf{x}) & = \sum_{i=1}^n \ln\left(p^{x_i}(1-p)^{1-x_i}\right),
\end{align*}
$$
where $\mathbf{x}=(x_1,\dots,x_n)$ denotes the vector of observed data points. 


##### (b) Likelihood function for a Bernoulli mixture distribution {-}
The probability mass function of a Bernoulli mixture distribution is 
$$
\begin{align*}
f_G(x)
& =\sum_{g=1}^G f_g(x)\\[2ex]
& =\sum_{g=1}^G \pi_g\; p_g^{x}(1-p_g)^{1-x}\quad\text{with}\quad x\in\{0,1\}.
\end{align*}
$$
Thus the likelihood function is
$$
\begin{align*}
\mathcal{L}(\mathbf{p},\boldsymbol{\pi}|\mathbf{x})    & = \prod_{i=1}^n\left(\sum_{g=1}^G \pi_g\; p_g^{x_i}(1-p_g)^{1-x_i}\right)\\[2ex]
\ell(\mathbf{p},\boldsymbol{\pi}|\mathbf{x}) & = \sum_{i=1}^n\ln\left(\sum_{g=1}^G\pi_g\; p_g^{x_i}(1-p_g)^{1-x_i}\right)
\end{align*}
$$
where $\mathbf{p}=(p_1,\dots,p_G)$ and $\boldsymbol{\pi}=(\pi_1,\dots,\pi_G)$.

##### (c) Likelihood function with group indicator random variables {-}

$$
\begin{align*}
\tilde{\mathcal{L}}(\mathbf{p},\boldsymbol{\pi}|\mathbf{x}) 
& = \prod_{i=1}^n \prod_{g=1}^G\left(\pi_g p_g^{x_i}(1-p_g)^{1-x_i}\right)^{Z_{ig}}\\[2ex]
\tilde{\ell}(\mathbf{p},\boldsymbol{\pi}|\mathbf{x})    
& = \sum_{i=1}^n \sum_{g=1}^G Z_{ig}\left(\ln(\pi_g) + \ln\left(p_g^{x_i}(1-p_g)^{1-x_i}\right)\right)
\end{align*}
$$


##### (d) Posterior probability {-}

$$
\begin{align*}
\mathfrak{p}_{ig} = P(Z_{ig}=1 | X_i = x_i) 
&=\frac{ P(Z_{ig}=1) f(x_i|Z_{ig}=1)}{f_G(x_i)} \\[2ex]
&=\frac{ P(Z_{ig}=1) f_g(x_i)}{f_G(x_i)} \\[2ex]
&=\frac{\pi_g\; p_g^{x_i} (1-p_g)^{1-x_i}}{\sum_{g=1}^G \pi_g\; p_g^{x_i} (1-p_g)^{1-x_i}}
\end{align*}
$$


##### (e) Expectation of $\tilde\ell$ {-}


$$
\begin{align*}
\mathbb{E}_{\mathbf{p},\boldsymbol{\pi}}\left(\ell(\mathbf{p},\boldsymbol{\pi}|\mathbf{x})\right) 
& = \sum_{i=1}^n \sum_{g=1}^G \mathbb{E}_{\mathbf{p},\boldsymbol{\pi}}\left(Z_{ig}\right)\left(\ln(\pi_g) + \ln\left(p_g^{x_i}(1-p_g)^{1-x_i}\right)\right)\\[2ex]
& = \sum_{i=1}^n \sum_{g=1}^G \mathfrak{p}_{ig} \left(\ln(\pi_g) + \ln\left(p_g^{x_i}(1-p_g)^{1-x_i}\right)\right),
\end{align*}
$$
since 
$$
\begin{align*}
\mathbb{E}_{\mathbf{p},\boldsymbol{\pi}}\left(Z_{ig}\right) = P(Z_{ig}=1 | X_i = x_i) 
\end{align*}
$$


##### (f) Maximizing $\mathbb{E}_{\mathbf{p},\boldsymbol{\pi}}\left(\ell(\mathbf{p},\boldsymbol{\pi}|\mathbf{x})\right)$ with respect to $p_g$ {-}

$$
\begin{align*}
\frac{\partial}{\partial p_g}\mathbb{E}_{\mathbf{p},\boldsymbol{\pi}}\left(\ell(\mathbf{p},\boldsymbol{\pi}|\mathbf{x})\right) 
& = \frac{\partial}{\partial p_g}\sum_{i=1}^n \sum_{g=1}^G \mathfrak{p}_{ig} \left(\ln(\pi_g) + \ln\left(p_g^{x_i}(1-p_g)^{1-x_i}\right)\right)\\[2ex]
& = \frac{\partial}{\partial p_g}\sum_{i=1}^n \sum_{g=1}^G \mathfrak{p}_{ig} \left(\ln(\pi_g) + \left(x_i\ln(p_g) + (1-x_i)\ln(1-p_g)\right)\right)\\[2ex]
%& = \sum_{i=1}^n \mathfrak{p}_{ig} \frac{\partial}{\partial p_g} \left(x_i\ln(p_g) + (1-x_i)\ln(1-p_g)\right)\\[2ex]
& = \sum_{i=1}^n \mathfrak{p}_{ig} \left(\frac{x_i}{p_g} - \frac{(1-x_i)}{(1-p_g)}\right)\\[2ex]
\end{align*}
$$
First order condition
$$
\begin{align*}
\sum_{i=1}^n \mathfrak{p}_{ig} \left(\frac{x_i}{p_g} - \frac{(1-x_i)}{(1-p_g)}\right)&=0\\[2ex]
\sum_{i=1}^n \mathfrak{p}_{ig} \left(\frac{x_i(1-p_g)}{p_g(1-p_g)} - \frac{(1-x_i)p_g}{p_g(1-p_g)}\right)&=0\\[2ex]
\sum_{i=1}^n \mathfrak{p}_{ig} \left(x_i(1-p_g) - (1-x_i)p_g\right)&=0\\[2ex]
\sum_{i=1}^n \mathfrak{p}_{ig} \left(x_i - p_g \right)&=0\\[2ex]
p_g\sum_{i=1}^n \mathfrak{p}_{ig} &= \sum_{i=1}^n \mathfrak{p}_{ig}x_i \\[2ex]
p_g & = \frac{\left(\sum_{i=1}^n \mathfrak{p}_{ig}x_i \right)}{\sum_{i=1}^n \mathfrak{p}_{ig}}
\end{align*}
$$


##### (g) Maximize $\mathbb{E}_{\mathbf{p},\boldsymbol{\pi}}\left(\ell(\mathbf{p},\boldsymbol{\pi}|\mathbf{x})\right)$ with respect to $\pi_g$ {-}


$$
\begin{align*}
\mathbb{E}_{\mathbf{p},\boldsymbol{\pi}}\left(\ell(\mathbf{p},\boldsymbol{\pi}|\mathbf{x})\right) 
& = \sum_{i=1}^n \sum_{g=1}^G \mathfrak{p}_{ig} \left(\ln(\pi_g) + \ln\left(p_g^{x_i}(1-p_g)^{1-x_i}\right)\right)
\end{align*}
$$


We only need to focus on the $\pi_g$ terms since the other terms are no functions of $\pi_g$. However, we need to do maximization under the side constraint that $\sum_{g=1}^G\pi_g=1.$ So, we use Lagrange multipliers. 

$$
\begin{align*}
L(\boldsymbol{\pi},\lambda)=\sum_{i=1}^n \sum_{g=1}^G \mathfrak{p}_{ig} \ln(\pi_g) - \lambda \left(\sum_{g=1}^G\pi_g-1\right) 
\end{align*}
$$
First order condition with respect to $\pi_g$:
$$
\begin{align*}
\frac{\partial}{\partial \pi_g} L(\boldsymbol{\pi},\lambda)&=0\\[2ex]
\sum_{i=1}^n \mathfrak{p}_{ig}\frac{1}{\pi_g}  - \lambda  &=0 \\[2ex]
\sum_{i=1}^n \mathfrak{p}_{ig}   &=\lambda \pi_g\\[2ex]
\pi_g & = \frac{\sum_{i=1}^n \mathfrak{p}_{ig}}{\lambda}  \\[2ex]
\end{align*}
$$
Plugging $\pi_g = \frac{\sum_{i=1}^n \mathfrak{p}_{ig}}{\lambda}$ into $L(\boldsymbol{\pi},\lambda)$:
$$
\begin{align*}
L(\lambda)&=\sum_{i=1}^n \sum_{g=1}^G \mathfrak{p}_{ig} \ln\left(\frac{\sum_{i=1}^n \mathfrak{p}_{ig}}{\lambda}\right) - \lambda \left(\sum_{g=1}^G\frac{\sum_{i=1}^n \mathfrak{p}_{ig}}{\lambda}-1\right) \\[2ex]
&=\sum_{i=1}^n \sum_{g=1}^G \mathfrak{p}_{ig} \left(\ln\left(\sum_{i=1}^n \mathfrak{p}_{ig}\right) - \ln\left(\lambda\right)\right) -  \left(\sum_{g=1}^G\sum_{i=1}^n \mathfrak{p}_{ig}-1\right) \\[2ex]
\end{align*}
$$
First order condition with respect to $\lambda$:
$$
\begin{align*}
\frac{\partial}{\partial \lambda} L(\lambda)&=0\\[2ex]
\frac{1}{\lambda}\sum_{i=1}^n \sum_{g=1}^G \mathfrak{p}_{ig} & = 0\\[2ex]
\lambda &= \sum_{i=1}^n \sum_{g=1}^G \mathfrak{p}_{ig} \\[2ex]
\end{align*}
$$
So, we have that 
$$
\begin{align*}
\pi_g & = \frac{\sum_{i=1}^n \mathfrak{p}_{ig}}{\sum_{i=1}^n \sum_{g=1}^G \mathfrak{p}_{ig}}  \\[2ex]
\end{align*}
$$


##### (h) Sketch of the EM-Algorithm {-}

1. Initial guesses for $p_g^{(0)}$ and $\pi_g^{(0)}$,  $g=1,\dots,G$.

2. For $r=1,2,\dots$
    * Expectation-Step: 
    $$
    \begin{align*}
    \mathfrak{p}_{ig}^{(r-1)} 
    &=\frac{\pi_g^{(r-1)}\; \left(p_g^{(r-1)}\right)^{x_i} \left(1-p_g^{(r-1)}\right)^{1-x_i}}{\sum_{g=1}^G \pi_g^{(r-1)}\; \left(p_g^{(r-1)}\right)^{x_i} \left(1-p_g^{(r-1)}\right)^{1-x_i}}
    \end{align*}
    $$
    * Maximization-Step: 
    $$
    \begin{align*}
    p_g^{(r)} & = \frac{\left(\sum_{i=1}^n \mathfrak{p}_{ig}^{(r-1)}x_i \right)}{\sum_{i=1}^n \mathfrak{p}_{ig}^{(r-1)}}
    \end{align*}
    $$
    $$
    \begin{align*}
    \pi_g^{(r)} & = \frac{\sum_{i=1}^n \mathfrak{p}_{ig}^{(r-1)}}{\sum_{i=1}^n \sum_{g=1}^G \mathfrak{p}_{ig}^{(r-1)}}  \\[2ex]
    \end{align*}
    $$

3. Check convergence (no relevant change of the maximized log-likelihood function). 