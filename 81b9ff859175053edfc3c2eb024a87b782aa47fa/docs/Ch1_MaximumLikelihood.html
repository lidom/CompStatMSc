<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Computational Statistics (M.Sc.) - 1&nbsp; Maximum Likelihood</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Ch2_EMAlgorithmus.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./" class="sidebar-logo-link">
      <img src="./images/Uni_Bonn_Logo.jpeg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Computational Statistics (M.Sc.)</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Organization of the Course</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch1_MaximumLikelihood.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch2_EMAlgorithmus.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">EM Algorithm &amp; Cluster Analysis</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#likelihood-principle" id="toc-likelihood-principle" class="nav-link active" data-scroll-target="#likelihood-principle"><span class="toc-section-number">1.1</span>  Likelihood Principle</a>
  <ul class="collapse">
  <li><a href="#properties-of-maximum-likelihood-estimators" id="toc-properties-of-maximum-likelihood-estimators" class="nav-link" data-scroll-target="#properties-of-maximum-likelihood-estimators">Properties of Maximum Likelihood Estimators</a></li>
  <li><a href="#example-coin-flipping-bernoulli-trial" id="toc-example-coin-flipping-bernoulli-trial" class="nav-link" data-scroll-target="#example-coin-flipping-bernoulli-trial">Example: Coin Flipping (Bernoulli Trial)</a></li>
  </ul></li>
  <li><a href="#numeric-optimization" id="toc-numeric-optimization" class="nav-link" data-scroll-target="#numeric-optimization"><span class="toc-section-number">1.2</span>  Numeric Optimization</a>
  <ul class="collapse">
  <li><a href="#newton-raphson-optimization" id="toc-newton-raphson-optimization" class="nav-link" data-scroll-target="#newton-raphson-optimization"><span class="toc-section-number">1.2.1</span>  Newton-Raphson Optimization</a></li>
  <li><a href="#sec-ConvNR" id="toc-sec-ConvNR" class="nav-link" data-scroll-target="#sec-ConvNR"><span class="toc-section-number">1.2.2</span>  Convergence of the Newton-Raphson Algorithm</a></li>
  <li><a href="#newton-raphson-algorithm-coin-flipping-example" id="toc-newton-raphson-algorithm-coin-flipping-example" class="nav-link" data-scroll-target="#newton-raphson-algorithm-coin-flipping-example"><span class="toc-section-number">1.2.3</span>  Newton-Raphson Algorithm: Coin-Flipping Example</a></li>
  </ul></li>
  <li><a href="#sec-LinRegNorm" id="toc-sec-LinRegNorm" class="nav-link" data-scroll-target="#sec-LinRegNorm"><span class="toc-section-number">1.3</span>  Linear Regression under Normality</a>
  <ul class="collapse">
  <li><a href="#sec-varMLE" id="toc-sec-varMLE" class="nav-link" data-scroll-target="#sec-varMLE"><span class="toc-section-number">1.3.1</span>  Variance of ML-Estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML}\)</span></a></li>
  </ul></li>
  <li><a href="#sec-MLAsymp" id="toc-sec-MLAsymp" class="nav-link" data-scroll-target="#sec-MLAsymp"><span class="toc-section-number">1.4</span>  Asymptotic Theory of Maximum-Likelihood Estimators</a></li>
  <li><a href="#equivariance-property-of-the-ml-estimator" id="toc-equivariance-property-of-the-ml-estimator" class="nav-link" data-scroll-target="#equivariance-property-of-the-ml-estimator"><span class="toc-section-number">1.5</span>  Equivariance Property of the ML-Estimator</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<!-- For updating: Elements of Statistical Learning and All of Statistics -->
<section id="likelihood-principle" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="likelihood-principle"><span class="header-section-number">1.1</span> Likelihood Principle</h2>
<p>The basic idea behind maximum likelihood estimation is very simple: Assume that the data is generated by some distribution with a certain (finite) set of unknown distribution parameters (e.g.&nbsp;the normal distribution with unknown mean and variance). Then find the distribution parameters for which it is most likely that the distribution has generated the data we actually observed.</p>
<p>In (classical) maximum likelihood estimation we must be rather specific about the process that generated the data. This is a trade off – by imposing a fair amount of structure on the data, we get in return a very desirable estimator. The question remains, however, whether we have made the right decision about the specific distribution/density function.</p>
<section id="properties-of-maximum-likelihood-estimators" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="properties-of-maximum-likelihood-estimators">Properties of Maximum Likelihood Estimators</h3>
<p>Why do we like maximum likelihood as an estimation method? The answer is that: A maximum likelihood estimator <span class="math inline">\(\hat\theta_n\)</span> of some parameter <span class="math inline">\(\theta_0\in\mathbb{R}\)</span> is</p>
<ul>
<li><strong>Consistent:</strong> <span class="math inline">\(\hat\theta_n\rightarrow_p\theta_0\)</span> as <span class="math inline">\(n\to\infty\)</span></li>
<li><strong>Asymptotically normal:</strong> <span class="math inline">\(\sqrt{n}(\hat\theta_n-\theta_0) \stackrel{a}{\sim} \mathcal{N}(0, \sigma^2)\)</span></li>
<li><strong>Asymptotically efficient:</strong> This means that no consistent estimator has lower asymptotic mean squared error than the maximum likelihood estimator.</li>
</ul>
<p>Likewise for multivariate parameter <span class="math inline">\(\theta_0\in\mathbb{R}^p.\)</span></p>
<p>Thus, maximum likelihood estimators can be very appealing, provided that the assumption on the general distribution family is correct.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
ML-estimation requires to fix the family of distributions <span class="math inline">\(f(\cdot|\theta)\)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Classic ML-estimation requires us to fix the general family of density/probability mass functions <span class="math inline">\(f\)</span> of the random variables in the (i.i.d.) random sample <span class="math inline">\(X_1,\dots,X_n\)</span> such that <span class="math inline">\(X_i\sim f\)</span>, <span class="math inline">\(i=1,\dots,n,\)</span> where <span class="math inline">\(f\)</span> is known up to an unknown parameter <span class="math inline">\(\theta,\)</span> where <span class="math inline">\(\theta\in\mathbb{R}^K\)</span> is allowed to be a <em>finite</em> (<span class="math inline">\(1\leq K&lt;\infty\)</span>) dimensional vector.</p>
<p>Examples:</p>
<ul>
<li><span class="math inline">\(f\)</span> being the probability mass function of the Bernoulli distribution <span class="math inline">\(\mathcal{Bern}(\theta)\)</span> with <span class="math display">\[
f(x_i|\theta)=
\left\{
\begin{array}{ll}
\theta,&amp;\text{if } x_i=1\\
1-\theta, &amp; \text{if } x_i=0
\end{array}
\right.
\]</span> and <strong>unknown</strong> parameter <span class="math inline">\(0\leq \theta\leq 1.\)</span></li>
<li><span class="math inline">\(f\)</span> is the normal density <span class="math display">\[
f(x_i|\theta)=\frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{1}{2}\left(\frac{x_i-\mu}{\sigma}\right)\right)
\]</span> with <strong>unknown</strong> parameter vector <span class="math inline">\(\theta=(\mu,\sigma^2)^T.\)</span></li>
</ul>
<p>This requirement (fixing the family of density functions) can be overly restrictive. In many applications we typically do not know the family of <span class="math inline">\(f.\)</span> To address this issue, the <strong>quasi maximum likelihood theory</strong> generalizes classic maximum likelihood estimation to cases where <span class="math inline">\(f\)</span> is misspecified (see <span class="citation" data-cites="White1982">White (<a href="#ref-White1982" role="doc-biblioref">1982</a>)</span>).</p>
</div>
</div>
</section>
<section id="example-coin-flipping-bernoulli-trial" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="example-coin-flipping-bernoulli-trial">Example: Coin Flipping (Bernoulli Trial)</h3>
<p>To introduce the main idea of maximum likelihood estimation, we use the simple example of a coin flipping experiment, where a <strong>possibly unfair</strong> <span class="math inline">\(\text{Coin}\)</span> can take the value <span class="math inline">\(H\)</span> (Head) or <span class="math inline">\(T\)</span> (Tail), <span class="math display">\[
\text{Coin}\in\{H,T\}.
\]</span> Such coin-flips can be modeled using Bernoulli random variables <span class="math display">\[
X\sim\mathcal{Bern}(\theta_0)
\]</span> where <span class="math display">\[
X=\left\{
    \begin{matrix}
    1 &amp; \text{if } \text{Coin}=H\\[2ex]
    0 &amp; \text{if } \text{Coin}=T
    \end{matrix}
    \right.
\]</span> The probability mass function of the Bernoulli distribution <span class="math inline">\(\mathcal{Bern}(\theta_0)\)</span> with <strong>unknown</strong> probability of success parameter <span class="math inline">\(0&lt;\theta_0&lt;1,\)</span> is given by <span class="math display">\[
f(x|\theta_0)=
\left\{
  \begin{array}{ll}
  \theta_0,&amp;\text{if } x=1\\
  1-\theta_0, &amp; \text{if } x=0
  \end{array}
\right.
\]</span> I.e. <span class="math display">\[
\theta_0 = f(1|\theta_0) = P(X=1) = P(\text{Coin}=H),
\]</span> which implies that the probability that we get a tail <span class="math inline">\(T\)</span> is <span class="math display">\[
1-\theta_0 = f(0|\theta_0) = P(X=0) = P(\text{Coin}=T).
\]</span></p>
<p>Our goal is to <strong>estimate the unknown</strong> <span class="math inline">\(\theta_0\)</span> using a random (i.i.d.) sample of size <span class="math inline">\(n\)</span> <span class="math display">\[
\{X_1,\dots,X_n\}
\]</span> with <span class="math display">\[
X_i=\left\{
    \begin{matrix}
    1 &amp; \text{if } \text{Coin}=H\text{ in $i$th coin flip}\\[2ex]
    0 &amp; \text{if } \text{Coin}=T\text{ in $i$th coin flip}
    \end{matrix}
    \right.
\]</span> such that <span class="math display">\[
X_i\sim\mathcal{Bern}(\theta_0),\quad i=1,\dots,n.
\]</span> <!-- where $\mathcal{Bern}(\theta)$ denotes the Bernoulli distribution with unknown probability of success parameter $\theta.$  --></p>
<p>A <strong>given observed realization</strong> of the random sample <span class="math display">\[
\{X_{1,obs},X_{2,obs},\dots,X_{n,obs}\}=\{0,1,\dots,0\}
\]</span> consists of <span class="math inline">\(0\leq N_{H,obs}\leq n\)</span> <span class="math display">\[
N_{H,obs}=\sum_{i=1}^n X_{i,obs}
\]</span> many heads and of <span class="math display">\[
0\leq n-N_{H,obs} \leq n
\]</span> many tails.</p>
<section id="the-log-likelihood-function" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-log-likelihood-function">The (Log-)Likelihood Function</h4>
<p>How do we combine the information from the <span class="math inline">\(n\)</span> observations <span class="math display">\[
\{X_{1,obs},\dots,X_{n,obs}\}
\]</span> to estimate the unknown <span class="math inline">\(\theta_0\)</span>?</p>
<p>If the observations are realizations of an i.i.d. sample, then the joint probability of observing <span class="math inline">\(h\)</span> heads <span class="math inline">\(H\)</span> and <span class="math inline">\(n-h\)</span> tails <span class="math inline">\(T\)</span> in <span class="math inline">\(n\)</span> coin flips is: <span class="math display">\[
\begin{align*}
\mathcal{L}_n(\theta)
&amp;=\prod_{i=1}^nf(X_{i,obs}|\theta)\\[2ex]
%&amp;=\left(P(X=1)\right)^{N_{H,obs}}\left(P(X=0)\right)^{n-N_{H,obs}}\\[2ex]
%&amp;= \theta^{N_{H,obs}}(1-\theta)^{n-N_{H,obs}}  \\[2ex]
&amp;= \prod_{i=1}^n \theta^{X_{i,obs}}(1-\theta)^{1-X_{i,obs}}.
\end{align*}
\]</span></p>
<p>The function <span class="math inline">\(\mathcal{L}_n(\theta)\)</span> is called the <strong>likelihood function</strong>.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-LikelihoodFunction" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1.1 (Likelihood Function) </strong></span>More generally, when the observations <span class="math inline">\(\{X_{1,obs},\dots,X_{n,obs}\}\)</span> are a realization of an i.i.d. sample <span class="math inline">\(\{X_1,\dots,X_n\}\)</span> with <span class="math inline">\(X_i\sim f\)</span> for all <span class="math inline">\(i=1,\dots,n\)</span>, we have that <span class="math display">\[
\mathcal{L}_n(\theta)=\prod_{i=1}^n f(X_{i,obs}|\theta),
\]</span> where <span class="math inline">\(f(X_{i,obs} | \theta)\)</span> is the density function of the random variable <span class="math inline">\(X_i\)</span> evaluated at the realization <span class="math inline">\(X_{i,obs},\)</span> and where <span class="math inline">\(\theta\)</span> denotes the unknown finite dimensional parameter vector of the density function. (A definition for dependent data (e.g.&nbsp;time series) is also possible.)</p>
</div>
</div>
</div>
</section>
<section id="estimation-idea" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="estimation-idea">Estimation Idea</h4>
<p>We estimate the unknown parameter <span class="math inline">\(\theta_0\)</span> by maximizing the likelihood of the observed data <span class="math inline">\(\{X_{1,obs},\dots,X_{n,obs}\}\)</span> over the range of possible parameter values. The value <span class="math inline">\(\hat\theta\)</span> at which the likelihood function <span class="math inline">\(\mathcal{L}_n(\cdot)\)</span> is maximized is called the <strong>maximum likelihood (ML) estimator</strong></p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-MLEstimator" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1.2 (Maximum Likelihood (ML) Estimator) </strong></span><span class="math display">\[
\begin{align*}
\hat{\theta}_{ML}
&amp;=\arg\max_{\theta\in\Theta} \mathcal{L}_n(\theta)\\[2ex]
&amp;=\arg\max_{\theta\in\Theta} \prod_{i=1}^n f(X_{i,obs}|\theta),
\end{align*}
\]</span> where <span class="math inline">\(\Theta\)</span> denotes the <strong>parameter space</strong>.</p>
</div>
</div>
</div>
<p>In our coin flip example this means to estimate the unknown <span class="math inline">\(\theta_0\)</span> by the value <span class="math inline">\(\hat\theta\)</span> at which the likelihood of the observed data <span class="math inline">\(\{X_{1,obs},\dots,X_{n,obs}\}\)</span> is maximal, <span class="math display">\[
\hat\theta_{ML} = \arg\max_{\theta\in[0,1]} \prod_{i=1}^n \theta^{X_{i,obs}}(1-\theta)^{1-X_{i,obs}}.
\]</span></p>
<p>Usually it’s easier to work with sums rather than products—also for doing the asymptotics in <a href="#sec-MLAsymp"><span>Section&nbsp;1.4</span></a>. So we apply a monotonic transformation by taking the logarithm of the likelihood which leads to the <strong>log-likelihood function</strong>: <span class="math display">\[
\begin{align*}
\ell_n(\theta)
&amp;=\ln\mathcal{L}_n(\theta)\\[2ex]
&amp;=\ln\prod_{i=1}^n f(X_{i,obs}|\theta)\\[2ex]
&amp;=\sum_{i=1}^n \ln f(X_{i,obs}|\theta).
\end{align*}
\]</span> Since this is only a monotonic transformation, we have that <span class="math display">\[
\begin{align*}
\hat\theta_{ML}
&amp;=\arg\max_{\theta\in\Theta} \mathcal{L}_n(\theta)\\[2ex]
&amp;=\arg\max_{\theta\in\Theta} \ell_n(\theta).
\end{align*}
\]</span> <!-- but $\ell_n(\theta)$ gives a more simple structure simplifying the maximization problem.  --></p>
<p>In our coin flipping example, taking the natural logarithm (<span class="math inline">\(\ln\)</span>) yields, <span class="math display">\[
\begin{align*}
\mathcal{L}_n(\theta) &amp;= \prod_{i=1}^n \theta^{X_{i,obs}}(1-\theta)^{1-X_{i,obs}} \\[2ex]
\Rightarrow\quad \ell_n(\theta)
&amp;=\ln\mathcal{L}_n(\theta)\\[2ex]
&amp;=\sum_{i=1}^n\left( X_{i,obs} \ln(\theta) + (1-X_{i,obs})\ln(1-\theta)\right).
\end{align*}
\]</span></p>
<p>The coin flip example is actually so simple that we can maximize <span class="math inline">\(\ell_n(\theta)\)</span> analytically. Computing the first derivative yields <span class="math display">\[
\begin{align*}
\ell'_n(\theta)&amp;=\sum_{i=1}^n \left(X_{i,obs}\dfrac{1}{\theta} - (1-X_{i,obs})\dfrac{1}{1-\theta}\right)\\[2ex]
&amp;=\dfrac{N_{H,obs}}{\theta} - \dfrac{n-N_{H,obs}}{1-\theta}
\end{align*}
\]</span> Setting the first derivative to zero determines the maximum likelihood estimator (MLE): <span id="eq-MLECoinFlipp"><span class="math display">\[
\begin{array}{rrcl}
&amp;\ell_n'(\hat\theta_{ML})&amp;\overset{!}{=}&amp;0\\[2ex]
\Leftrightarrow&amp;\dfrac{N_{H,obs}}{\hat\theta_{ML}} &amp;=&amp; \dfrac{n-N_{H,obs}}{1-\hat\theta_{ML}} \\[2ex]
\Leftrightarrow&amp;N_{H,obs}-N_{H,obs}\hat\theta_{ML}  &amp;=&amp; n\hat\theta_{ML}-N_{H,obs}\hat\theta_{ML}\\[2ex]
\Leftrightarrow&amp;\hat\theta_{ML}&amp;=&amp;\dfrac{N_{H,obs}}{n}
\end{array}
\tag{1.1}\]</span></span></p>
<p>Usually, however, the log-likelihood function is <strong>way more complicated</strong> and one needs to apply <strong>numeric optimization</strong> algorithms to find the MLE, <span class="math inline">\(\hat\theta_{ML}.\)</span></p>
</section>
</section>
</section>
<section id="numeric-optimization" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="numeric-optimization"><span class="header-section-number">1.2</span> Numeric Optimization</h2>
<p>Usually we are not so fortunate as to have an analytical solution for the MLE, and must rely on the computer to find the maximizing arguments of the log-likelihood function. Various methods exist for finding the maximum (or minimum) of a function.</p>
<!-- [numerically with the help of the computer](https://jaimemosg.github.io/EstimationTools/index.html) -->
<p><strong>General idea:</strong></p>
<ol type="1">
<li>Start at some value, <span class="math inline">\(\theta_{(0)},\)</span> in the parameter space <span class="math inline">\(\Theta.\)</span></li>
<li>Search across the parameter space <span class="math inline">\(\Theta\)</span> using a step-wise procedure until a updated parameter value <span class="math inline">\(\ell'(\theta_{(m)})\)</span> is found that yield a derivative of the log likelihood that is effectively zero (i.e.&nbsp;smaller than some convergence/stopping criterion), <span class="math inline">\(\ell'(\theta_{(m)})\approx 0.\)</span></li>
</ol>
<section id="newton-raphson-optimization" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="newton-raphson-optimization"><span class="header-section-number">1.2.1</span> Newton-Raphson Optimization</h3>
<p>One of the most-used methods for optimization is the Newton-Raphson method (or a variant of it). The Newton-Raphson method relies on Taylor-series approximations of the log-likelihood function.</p>
<p>In the following, we consider the univariate case <span class="math inline">\(\theta\in\mathbb{R}.\)</span> However, the multivariate case <span class="math inline">\(\theta\in\mathbb{R}^K\)</span> is treated likewise, but requires substituting first derivatives by gradients, second derivatives by the Hessian, etc.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<!-- * By strange convention Newton usually shares credit for this algorithm when
it is applied to root-finding, but not when it is used for optimization. However, root-finding can be used for finding the root of the first-derivative function and thus can be used for optimization.  -->
<p>Minimization and maximization are essentially the same problems since minimizing a function <span class="math inline">\(f(x)\)</span> with respect to <span class="math inline">\(x\)</span> is equivalent to maximizing <span class="math inline">\(-f(x)\)</span> with respect to <span class="math inline">\(x.\)</span></p>
</div>
</div>
<p>Let <span class="math inline">\(f\)</span> be a two times differentiable function to be optimized (here maximized). The <strong>first- and second-order Taylor-series approximations</strong> of <span class="math inline">\(f\)</span> around the point <span class="math inline">\(\theta\)</span> are: <span class="math display">\[
\begin{align*}
\text{First-order:}\quad &amp;f(\theta+h)\approx \overbrace{f(\theta)+f'(\theta)h}^{\text{Taylor Polynomial of order 1}} \\
\text{Second-order:}\quad&amp; f(\theta+h)\approx \underbrace{f(\theta)+f'(\theta)h + \frac{1}{2} f''(\theta)h^2}_{\text{Taylor Polynomial of order 2}},
\end{align*}
\]</span> Locally, i.e.&nbsp;for <span class="math inline">\(h\approx 0,\)</span> (e.g.&nbsp;<span class="math inline">\(h=\pm 0.04\)</span>) the Taylor polynomials are very good approximations of <span class="math inline">\(f(\theta + h);\)</span> see <a href="#fig-taylorApprox">Figure&nbsp;<span>1.1</span></a>.</p>
<div class="cell" data-hash="Ch1_MaximumLikelihood_cache/html/fig-taylorApprox_a0c2f0ea084585095207b1b19468dd01">
<div class="cell-output-display">
<div id="fig-taylorApprox" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Ch1_MaximumLikelihood_files/figure-html/fig-taylorApprox-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1.1: First- and second-order Taylor approximations of a function <span class="math inline">\(f\)</span> around <span class="math inline">\(\theta=1.\)</span></figcaption><p></p>
</figure>
</div>
</div>
</div>
<!-- ::: {.callout-important}
The first-order and the second-order Taylor polynomial can both be used to approximate $f.$

The second-order Taylor polynomial can be used to apprixmate $f'.$
::: -->
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="thm-TaylorThm" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1.1 (Taylor’s Theorem) </strong></span><br> Today, there are many different versions of Taylor’s theorem. We consider the following two:</p>
<p><strong>1. <a href="https://en.wikipedia.org/wiki/Giuseppe_Peano">Peano</a> form of the remainder term:</strong><br> Let <span class="math inline">\(f:\mathbb{R}\to\mathbb{R}\)</span> be <span class="math inline">\(k\)</span> times differentiable at <span class="math inline">\(x\in\mathbb{R}\)</span> and let <span class="math inline">\(h\in\mathbb{R}.\)</span> Then there exists a function <span class="math inline">\(P_{k,x}:\mathbb{R}\to\mathbb{R}\)</span> such that <span class="math display">\[
\begin{align*}
f(x+h) &amp;=
f(x)
+ \sum_{\ell=1}^k \frac{f^{(\ell)}(x)}{\ell!}(h)^\ell
+ P_{k,x}(h)\;(h)^k
\end{align*}
\]</span> with <span class="math display">\[
P_{k,x}(h)\to 0\quad\text{as}\quad h\to 0,
\]</span> where <span class="math inline">\(f^{(\ell)}(x)\)</span> denotes the <span class="math inline">\(\ell\)</span>th derivative of <span class="math inline">\(f\)</span> at <span class="math inline">\(x.\)</span></p>
<p><strong>2. <a href="https://en.wikipedia.org/wiki/Joseph-Louis_Lagrange">Lagrange</a> or Mean-value form of the remainder term:</strong><br> Let <span class="math inline">\(f:\mathbb{R}\to\mathbb{R}\)</span> be <span class="math inline">\(k+1\)</span> times differentiable on the open interval between <span class="math inline">\(x\)</span> and <span class="math inline">\(x+h,\)</span> with <span class="math inline">\(h\in\mathbb{R},\)</span> and let <span class="math inline">\(f^{(k)}\)</span> be continuous on the closed interval between <span class="math inline">\(x\)</span> and <span class="math inline">\(x+h,\)</span>. Then <span class="math display">\[
\begin{align*}
f(x+h) &amp;=
f(x)
+ \sum_{\ell=1}^k \frac{f^{(\ell)}(x)}{\ell!}(h)^\ell
+ M_{k,x}(h)
\end{align*}
\]</span> with <span class="math display">\[
M_{k,x}(h)=\frac{f^{(k+1)}(\xi)}{(k+1)!}(h)^{k+1}
\]</span> for some real number <span class="math inline">\(\xi\)</span> between <span class="math inline">\(x\)</span> and <span class="math inline">\(x+h.\)</span> (This form of Taylor’s theorem is based on the mean-value <a href="#thm-MVT">Theorem&nbsp;<span>1.2</span></a>.)</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Qualitative version using the small-<span class="math inline">\(o\)</span> notation:
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{align*}
f(x + h) &amp; =
f(x)
+ \sum_{\ell=1}^k \frac{f^{(\ell)}(x)}{\ell!}(h)^\ell
+ o\big(|h|^k\big),
\end{align*}
\]</span> where <span class="math inline">\(o\big(|h|^k\big)\)</span> denotes the family of real-valued functions, <span class="math inline">\(g(h)\)</span> say, that are of a <strong>strictly smaller <span class="math inline">\(o\)</span>rder of magnitude</strong> than the function <span class="math inline">\(|h|^k\)</span> as <span class="math inline">\(h\to 0;\)</span> i.e.<br>
<span class="math display">\[
o\big(|h|^k\big)=\left\{g(h)\to 0\;\text{ as }\; h\to 0:\frac{|g(h)|}{|h|^k}\to 0\quad\text{as}\quad h\to 0\right\}.
\]</span></p>
<p><strong>1. Note: Peano form of the remainder term:</strong><br> <span class="math inline">\(P_{k,x}(h)\;(h)^k=o\big(|h|^k\big)\)</span> since <span class="math display">\[
\frac{|P_{k,x}(h)\;(h)^k|}{|h|^k}
%=\frac{|P_k(x+h)|\cdot |h|^k|}{|h|^k}
=|P_{k,x}(h)|\to 0\quad\text{as}\quad h\to 0.
\]</span></p>
<p><strong>2. Note: Mean-value form of the remainder term:</strong><br> <span class="math inline">\(M_{k,x}(h)=o\big(|h|^k\big)\)</span> since <span class="math display">\[
\frac{|M_{k,x}(h)|}{|h|^k}=
\left|\frac{f^{(k+1)}(\xi)}{(k+1)!}\right|\cdot|h|\to 0\quad\text{as}\quad h\to 0.
\]</span></p>
</div>
</div>
</div>
</div>
</div>
<section id="optimization-idea" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="optimization-idea">Optimization Idea</h4>
<p>Let <span class="math inline">\(\ell_n\)</span> be a log-likelihood function with continuous first, <span class="math inline">\(\ell_n',\)</span> and second, <span class="math inline">\(\ell_n'',\)</span> derivative.</p>
<p>To optimize the log-likelihood function <span class="math inline">\(\ell_n,\)</span> we try to find the root of <span class="math inline">\(\ell_n',\)</span> i.e.&nbsp;the value of <span class="math inline">\(\theta\in\Theta\)</span> such that <span class="math display">\[
\ell_n'(\theta)=0.
\]</span> That is, we try to find the value of <span class="math inline">\(\theta\)</span> that fulfills the <strong>first order condition</strong> of the optimization problem. We do so using a step-wise optimization approach, where each step has a smallish size <span class="math inline">\(h.\)</span></p>
<p><strong>Initialization:</strong> Let <span class="math inline">\(\theta_{(0)}\in\Theta\)</span> be our first guess of the root of <span class="math inline">\(\ell'_n.\)</span></p>
<p><strong><span class="math inline">\(h\)</span>-Steps:</strong> Typically, our guess is not perfect and thus <span class="math inline">\(\ell_n'(\theta_{(0)})\neq 0.\)</span> Therefore, we want to move from <span class="math inline">\(\theta_{(0)}\)</span> to a new root-candidate <span class="math inline">\(\theta_{(1)}\)</span> by doing an <span class="math inline">\(h\)</span>-step update <span class="math display">\[
\theta_{(1)} = \theta_{(0)} + h.
\]</span></p>
<!-- 1. We select some starting value $\theta_0.$ 
2. Optimize the second-order Taylor polynomial of $f$ around $\theta_0$ with respect to $h.$ 
3. In each of the following steps, we optimize new second-order Taylor polynomials of $f$ at those values $\theta,$ for which the previous second-order Taylor polynomial was maximal.  -->
<!-- **Implementation-Idea:** The second-order Taylor-series approximation gives -->
<p>The first-order Taylor-series approximation of <span class="math inline">\(\ell_n'\)</span> around our first guess <span class="math inline">\(\theta_{(0)}\)</span> gives <span class="math display">\[
\begin{align*}
\ell_n'(\theta_{(0)} + h) &amp; \approx \ell_n'(\theta_{(0)}) + \ell_n''(\theta_{(0)})h
\end{align*}
\]</span> Thus, to find the <span class="math inline">\(h\)</span>-step that brings us closer to the root of <span class="math inline">\(\ell_n',\)</span> we can (approximatively) use the <span class="math inline">\(h\)</span>-step that brings us to the root of its first-order approximation, i.e. <span class="math display">\[
\begin{align*}
\ell_n'(\theta_{(0)}) + \ell_n''(\theta_{(0)})h = 0\\[2ex]
\Rightarrow h = -\frac{\ell_n'(\theta_{(0)})}{\ell_n''(\theta_{(0)})}.
\end{align*}
\]</span> Based on this <span class="math inline">\(h\)</span>-step, the new root-candidate is <span class="math display">\[
\theta_{(1)} = \theta_{(0)} - \frac{\ell_n'(\theta_{(0)})}{\ell_n''(\theta_{(0)})}.
\]</span> Likewise, the <span class="math inline">\(m\)</span>th root-candidate is <span class="math display">\[
\theta_{(m)} = \theta_{(m-1)} - \frac{\ell_n'(\theta_{(m-1)})}{\ell_n''(\theta_{(m-1)})};
\]</span> see also <a href="#fig-NR">Figure&nbsp;<span>1.2</span></a>.</p>
<div class="cell" data-hash="Ch1_MaximumLikelihood_cache/html/fig-NR_3e37eb79dd90aa55545172f4be78103a">
<div class="cell-output-display">
<div id="fig-NR" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Ch1_MaximumLikelihood_files/figure-html/fig-NR-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1.2: The <span class="math inline">\(m\)</span>th update step in the Newton-Raphson root-finding algorithm.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-ConvNR" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="sec-ConvNR"><span class="header-section-number">1.2.2</span> Convergence of the Newton-Raphson Algorithm</h3>
<p>Let <span class="math inline">\(\theta_{root}\)</span> denote the root of <span class="math inline">\(\ell_n';\)</span> i.e.&nbsp; <span class="math display">\[
\ell_n'(\theta_{root})=0.
\]</span> We aim to find <span class="math inline">\(\theta_{root}\)</span> using the Newton-Raphson algorithm and call our best approximation of <span class="math inline">\(\theta_{root}\)</span> the maximum likelihood estimate; i.e.&nbsp;<span class="math inline">\(\hat{\theta}_{ML}\approx\theta_{root}.\)</span></p>
<p>Let <span class="math display">\[
e_{(0)}=\theta_{root}-\theta_{(0)}
\]</span> denote the start value error and let <span class="math display">\[
I=[\theta_{root}-|e_{(0)}|, \theta_{root}+|e_{(0)}|]
\]</span> denote the start value error neighborhood around <span class="math inline">\(\theta_{root}.\)</span></p>
<p>One can shown that if <span class="math inline">\(\ell_n'\)</span> is “well behaved” over <span class="math inline">\(I;\)</span> i.e.&nbsp;</p>
<ul>
<li>if <span class="math inline">\(\ell_n''(\theta)\neq 0\)</span> for all <span class="math inline">\(\theta\in I\)</span> and</li>
<li>if <span class="math inline">\(\ell_n'''(\theta)\)</span> is finite and continuous for all <span class="math inline">\(\theta\in I,\)</span></li>
</ul>
<p>and if our first guess <span class="math inline">\(\theta_{(0)}\)</span> is “close enough;” i.e.&nbsp;</p>
<ul>
<li>if <span class="math inline">\(M|e_{(0)}|&lt;1,\)</span> where <span class="math display">\[
M=\frac{1}{2}\left(\sup_{\theta\in I}|\ell_n'''(\theta)|\right)\left(\sup_{\theta\in I}\frac{1}{|\ell_n''(\theta)|}\right)\geq 0,
\]</span></li>
</ul>
<p>then <span class="math inline">\(\theta_{(m)}\)</span> will converge to <span class="math inline">\(\theta_{root}\)</span> as <span class="math inline">\(m\to\infty.\)</span></p>
<div class="callout-warning callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Unfortunately, we typically don’t know if <span class="math inline">\(\ell_n'\)</span> is “well behaved” and we usually don’t know whether our first guess is “close enough”. So, typically we cannot guarantee convergence of the Newton-Raphson algorithm. 😭 <!-- Exercise: Let this be proofen: https://en.wikipedia.org/wiki/Newton%27s_method --></p>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>For problems that are globally concave, the starting value <span class="math inline">\(\theta_0\)</span> doesn’t matter. For more complex problems, however, the Newton-Raphson algorithm can get stuck into a local maximum. In such cases, it is usually a good idea to <strong>try multiple starting values</strong>.</p></li>
<li><p>In actual practice, implementation of the Newton-Raphson algorithm can be tricky. We may have <span class="math inline">\(\ell_n''(\theta_{(m)})=0,\)</span> in which case the function looks locally like a straight line, with no solution to the Taylor series approximation <span class="math display">\[
\begin{align*}
\ell_n'(\theta_{(m)} + h) &amp; \approx \ell_n'(\theta_{(m)}) + \ell_n''(\theta_{(m)})h.
\end{align*}
\]</span> In this case a simple strategy is to move a small step in the direction which decreases the function value, based only on <span class="math inline">\(\ell_n'(\theta_m).\)</span></p></li>
<li><p>In other cases where <span class="math inline">\(\theta_{(m)}\)</span> is too far from the true maximizer <span class="math inline">\(\theta\)</span>, the Taylor approximation may be so inaccurate that <span class="math inline">\(\ell_n(\theta_{(m+1)})\)</span> is actually <em>smaller</em> than <span class="math inline">\(\ell_n(\theta_{(m)}).\)</span> When this happens one may replace <span class="math inline">\(\theta_{(m+1)}\)</span> with <span class="math inline">\((\theta_{(m+1)}+\theta_{(m)})/2\)</span> (or some other value between <span class="math inline">\(\theta_{(m)}\)</span> and <span class="math inline">\(\theta_{(m+1)}\)</span>) in the hope that a smaller step will produce better results.</p></li>
</ul>
</div>
</div>
<p><strong>Stopping Criterion:</strong> Since we are expecting that <span class="math inline">\(\ell_n'(\theta_{(m)})\to 0,\)</span> as <span class="math inline">\(m\to\infty,\)</span> a good stopping condition for the Newton-Raphson algorithm is <span class="math display">\[
|\ell_n'(\theta_{(m)})|\leq \varepsilon
\]</span> for some (small) tolerance <span class="math inline">\(\varepsilon&gt;0.\)</span></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Pseudo-Code: Newton-Raphson Algorithm
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{array}{ll}
\texttt{\textbf{select }} \theta_{(0)}\in\Theta\;\;\text{ and}&amp;\varepsilon&gt;0 \\[2ex]
\texttt{\textbf{let }} m=0         &amp;  \\
\texttt{\textbf{while }}  | \ell_n'(\theta_{(m)}) | &gt;\varepsilon &amp; \texttt{\textbf{do}}\\
&amp;\left[
                                    \begin{array}{l}\texttt{\textbf{let }} m = m+1 \\
                                    \texttt{\textbf{let }} \theta_{(m)} = \theta_{(m-1)} - \frac{\ell_n'(\theta_{(m-1)})}{\ell_n''(\theta_{(m-1)})} \\
                                    \end{array} \right.\\
\texttt{\textbf{let }}\hat\theta_{ML}=\theta_{(m)} &amp; \\
\texttt{\textbf{return }} \hat\theta_{ML} &amp;  \\
\end{array}
\]</span></p>
</div>
</div>
</section>
<section id="newton-raphson-algorithm-coin-flipping-example" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="newton-raphson-algorithm-coin-flipping-example"><span class="header-section-number">1.2.3</span> Newton-Raphson Algorithm: Coin-Flipping Example</h3>
<p>Let’s return to our earlier coin flipping example.</p>
<p>If we observe, for instance, only one head <span class="math inline">\(N_{H,obs}=1\)</span> for a sample size of <span class="math inline">\(n=5,\)</span> we already know from <a href="#eq-MLECoinFlipp">Equation&nbsp;<span>1.1</span></a> that <span class="math display">\[
\hat\theta_{ML}=\frac{N_{H,obs}}{n}=\frac{1}{5}=0.2,
\]</span> but let us, nevertheless, apply the Newton-Raphson algorithm.</p>
<p>The first and second derivatives of <span class="math display">\[
\ell_n(\theta)=\sum_{i=1}^n\big(X_{i,obs} \ln(\theta) + (1-X_{i,obs})\ln(1-\theta)\big)
\]</span> are <span class="math display">\[
\begin{align*}
\ell_n'(\theta)&amp;=\dfrac{N_{H,obs}}{\theta} - \dfrac{n-N_{H,obs}}{1-\theta} \\[2ex]
\ell_n''(\theta) &amp;= -\dfrac{N_{H,obs}}{\theta^2} + \dfrac{n}{(1-\theta)^2}(-1)-\dfrac{N_{H,obs}}{(1-\theta)^2}(-1)\\[2ex]
&amp;= -\dfrac{N_{H,obs}}{\theta^2} - \dfrac{n-N_{H,obs}}{(1-\theta)^2}.
\end{align*}
\]</span></p>
<p>We consider a sample size of <span class="math inline">\(n=5\)</span> with the following observed outcome:</p>
<ul>
<li>One Head: <span class="math inline">\(\quad N_{H,obs}=1\)</span></li>
<li>Four Tails: <span class="math inline">\(\quad n-N_{H,obs}=4\)</span></li>
</ul>
<p>Setting <span class="math inline">\(\varepsilon=10^{-10}\)</span> as our stopping criterion and <span class="math inline">\(\theta_{(0)}=0.4\)</span> as our starting value allows us to run the Newton-Raphson algorithm which gives us the results shown in <a href="#tbl-NR">Table&nbsp;<span>1.1</span></a>. The numeric optimization solution is <span class="math inline">\(\hat\theta_{ML} = 0.2\)</span> which equals the analytic solution.</p>
<div id="tbl-NR" class="anchored">
<table class="table">
<caption>Table&nbsp;1.1: Result of applying the Newton Raphson optimization algorithm to our coin flipping example for given data with <span class="math inline">\(N_{H,obs}=1,\)</span> sample size <span class="math inline">\(n=5,\)</span> starting value <span class="math inline">\(\theta_{(0)}=0.4,\)</span> and convergence criterion <span class="math inline">\(\varepsilon=10^{-10}.\)</span></caption>
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 25%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(m\)</span></th>
<th><span class="math inline">\(\hat\theta_{(m)}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(-\ell_n'(\hat\theta_{(m)})/\ell_n''(\hat\theta_{(m)})\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\ell_n'(\hat\theta_{(m)})\gtrless \varepsilon\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(0.40\)</span></td>
<td style="text-align: center;"><span class="math inline">\(-2.4\cdot 10^{-1}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{red}-4.2 &gt; \varepsilon}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(0.16\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phantom{-}3.3\cdot 10^{-2}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{red}\phantom{-}1.5 &gt; \varepsilon}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(2\)</span></td>
<td><span class="math inline">\(0.19\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phantom{-}6.6\cdot 10^{-3}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{red}\phantom{-}2.2\cdot 10^{-1} &gt; \varepsilon}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(3\)</span></td>
<td><span class="math inline">\(0.19\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phantom{-}1.7\cdot 10^{-4}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{red}\phantom{-}5.4\cdot 10^{-3} &gt; \varepsilon}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(4\)</span></td>
<td><span class="math inline">\(0.19\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phantom{-}1.1\cdot 10^{-7}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{red}\phantom{-}3.5\cdot 10^{-6} &gt; \varepsilon}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(5\)</span></td>
<td><span class="math inline">\(0.20\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phantom{-}4.8\cdot 10^{-14}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{darkgreen}\phantom{-}1.5\cdot 10^{-12} &lt; \varepsilon}\)</span></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="sec-LinRegNorm" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="sec-LinRegNorm"><span class="header-section-number">1.3</span> Linear Regression under Normality</h2>
<p>Now let’s return to the linear regression model <span id="eq-LinMod"><span class="math display">\[
Y_i=X_i'\beta_0 + \varepsilon_i,\quad  i=1,\dots,n,
\tag{1.2}\]</span></span> where <span class="math inline">\(Y_i\in\mathbb{R}\)</span> denotes the response (or “dependent”) variable, <span class="math display">\[
\beta_0\in\mathbb{R}^p
\]</span> denotes the vector of unknown slope parameters, and <span class="math display">\[
X_i:=(\underbrace{X_{i1}}_{=1},X_{i2},\ldots,X_{ip})'\in\mathbb{R}^p
\]</span> denotes the vector of predictor variables, where the (i.i.d.) random sample<br>
<span class="math display">\[
(Y_1,X_1), (Y_2,X_2), \dots, (Y_n,X_n)
\]</span> follows a <strong>random design with homoskedastic errors</strong> (see <a href="#def-RandomDesign">Definition&nbsp;<span>1.3</span></a>).</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-RandomDesign" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1.3 (Random Design (Regression Analysis)) </strong></span><br></p>
<p>A <strong>random desgin</strong> in regression analysis is given by the following setup:</p>
<p>Let <span class="math display">\[
(Y_1,X_1), (Y_2,X_2), \dots, (Y_n,X_n)
\]</span> or equivalently <span class="math display">\[
(X_1,\varepsilon_1), (X_2,\varepsilon_2), \dots, (X_n,\varepsilon_n)
\]</span> denote a (i.i.d.) random sample with <span class="math inline">\(\mathbb{E}(\varepsilon_i|X_i)=0\)</span>, <span class="math inline">\(i=1,\dots,n,\)</span> and with either</p>
<ul>
<li><strong>homoskedastic</strong> errors: <span class="math inline">\(0&lt;\mathbb{E}(\varepsilon_i^2|X_i)=\sigma^2_0&lt;\infty\)</span></li>
</ul>
<p>or</p>
<ul>
<li><strong>heteroskedastic</strong> errors: <span class="math inline">\(0&lt;\mathbb{E}(\varepsilon_i^2|X_i)=\sigma^2_0(X_i)&lt;\infty\)</span>, for a strictly positive and finite variance function <span class="math inline">\(\sigma^2_0(\cdot).\)</span></li>
</ul>
</div>
</div>
</div>
<p>For the following, it is convenient to write <a href="#eq-LinMod">Equation&nbsp;<span>1.2</span></a> using matrix notation <span class="math display">\[
\begin{eqnarray*}
  \underset{(n\times 1)}{Y}&amp;=&amp;\underset{(n\times K)}{X}\underset{(K\times 1)}{\beta_0} + \underset{(n\times 1)}{\varepsilon},
\end{eqnarray*}
\]</span> where <span class="math display">\[
\begin{equation*}
Y=\left(\begin{matrix}Y_1\\ \vdots\\Y_n\end{matrix}\right),\quad X=\left(\begin{matrix}X_{11}&amp;\dots&amp;X_{1K}\\\vdots&amp;\ddots&amp;\vdots\\ X_{n1}&amp;\dots&amp;X_{nK}\\\end{matrix}\right),\quad\text{and}\quad \varepsilon=\left(\begin{matrix}\varepsilon_1\\ \vdots\\ \varepsilon_n\end{matrix}\right).
\end{equation*}
\]</span></p>
<p>Under <strong>normally distributed</strong> (and homoskedastic) error terms, <span class="math inline">\(\varepsilon_i,\)</span> we have that <span id="eq-OLSnormAss"><span class="math display">\[
\begin{align}
\underset{(n\times 1)}{\varepsilon} &amp;\sim \mathcal{N}_n\left(0, \sigma_0^2I_n\right)\\[2ex]
\Rightarrow\quad
\underset{(n\times 1)}{Y|X} &amp;\sim \mathcal{N}_n\left(X\beta_0, \sigma^2_0I_n\right)
\end{align}
\tag{1.3}\]</span></span></p>
<!-- We could also choose another distributional assumption for $\varepsilon,$ but the classical ML estimation theory requires us to assumed the correct error distribution. Luckily, the quasi maximum likelihood theory of @White1982 shows that false distributional assumptions are typically not problematic. -->
<!-- ::: {.callout-note}
The requirement to make a (correct) distributional assumption is much more restrictive than requirements for analyzing the OLS estimator under standard large sample inference. However, taking into account specific distributional assumptions allows us to consider also more complicated non-linear regression models such as, for instance, logistic regression. 
:::pe -->
<!-- \begin{itemize} -->
<!-- \item The $\varepsilon$'s are jointly normally distributed. -->
<!-- \item The $\varepsilon$'s are independent of one another. -->
<!-- \item The $\varepsilon$'s are identically distributed, i.e. homoskedastic. -->
<!-- \end{itemize} -->
<p>Under <a href="#eq-OLSnormAss">Equation&nbsp;<span>1.3</span></a>, we have <span class="math display">\[
f(Y_i|X_i;\beta_0',\sigma_0^2)=
\frac{1}{(2\pi\sigma^2)^{1/2}}\exp\left(-\frac{(Y_i-X_i'\beta_0)^2}{2\sigma_0^2}\right),
\]</span> where <span class="math display">\[
\theta_0=(\beta_0',\sigma_0^2)'\in\mathbb{R}^K\times\mathbb{R}_{&gt;0}
\]</span> denotes the unknown parameter vector.</p>
<p>This allows us to setup the likelihood function, <span class="math display">\[
\begin{align*}
\mathcal{L}_n(\beta',\sigma^2)
&amp; =\prod_{i=1}^n f(Y_i|X_i;\beta',\sigma^2)\\[2ex]
&amp; =\prod_{i=1}^n \frac{1}{(2\pi\sigma^2)^{1/2}}\exp\left(-\frac{(Y_i-X_i'\beta)^2}{2\sigma^2}\right)\\[2ex]
&amp; =\frac{1}{(2\pi\sigma^2)^{1/2}}\exp\left(-\frac{\sum_{i=1}^n (Y_i-X_i'\beta)^2}{2\sigma^2}\right)\\[2ex]
%&amp; =\dfrac{1}{(2\pi \sigma^2)^{n/2}} \exp\left(-\frac{\varepsilon'\varepsilon}{2\sigma^2}\right)\\[2ex]
&amp; =(2\pi)^{-n/2} \cdot (\sigma^2)^{-n/2}\cdot  \exp\left(-\frac{(Y-X\beta)'(Y-X\beta)}{2\sigma^2}\right),\\[2ex]
\end{align*}
\]</span> <!-- The multivariate density for $\varepsilon=(\varepsilon_1,\dots,\varepsilon_n)'$ is then
$$
\begin{equation*}
f(\varepsilon)=\dfrac{1}{(2\pi \sigma^2)^{n/2}} \exp\left(-\frac{\varepsilon'\varepsilon}{2\sigma^2}\right).
\end{equation*}
$$ --> <!-- Noting that $\varepsilon=Y-X\beta$, we get the  --> and the log-likelihood function, <span class="math display">\[
\begin{align*}
\ell_n(\beta',\sigma^2)&amp; =-\dfrac{n}{2} \ln(2\pi) - \dfrac{n}{2}\ln(\sigma^2) - \dfrac{1}{2 \sigma^2}(Y-X\beta)'(Y-X\beta).
\end{align*}
\]</span> <!-- with $K+1$ unknown parameters: 

* $\beta=(\beta_1,\dots,\beta_K)'\in\mathbb{R}^K$ and 
* $\sigma^2\in\mathbb{R}_{>0}.$ --></p>
<p>Taking first derivatives gives <span class="math display">\[
\begin{align*}
\underset{(K\times 1)}{\dfrac{\partial \ell_n}{\partial \beta}(\beta',\sigma^2)}    
&amp;= - \dfrac{1}{\sigma^2}(-X'Y + X'X\beta)\\[2ex]
\underset{(1\times 1)}{\dfrac{\partial \ell_n}{\partial \sigma^2}(\beta',\sigma^2)}
%&amp;= -\dfrac{n}{2\sigma^2}+ \dfrac{1}{2\sigma^4}(Y-X\beta)'(Y-X\beta)
&amp;=-\frac{n}{2 \sigma^{2}}+\left[\frac{1}{2}(Y-X\beta)'(Y-X\beta)\right]\frac{1}{\left(\sigma^{2}\right)^{2}}\\
%&amp;=\frac{1}{2 \sigma^{2}}\left[\frac{1}{\sigma^{2}} (Y-X\beta)'(Y-X\beta)-n\right]
\end{align*}
\]</span> Putting the above derivative functions into one column vector yields the <span class="math inline">\(((K+1)\times 1)\)</span>-dimensional gradient called <strong>score function</strong> in ML-theory: <span id="eq-LinRegScoreFun"><span class="math display">\[
\left(\begin{matrix}
\dfrac{\partial \ell_n}{\partial \beta}(\beta',\sigma^2)\\
\dfrac{\partial \ell_n}{\partial \sigma^2}(\beta',\sigma^2)
\end{matrix}\right)
\tag{1.4}\]</span></span></p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-ScoreFunction" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1.4 (Score Function) </strong></span>More generally, let <span class="math inline">\(\ell_n(\theta)\)</span> denote the log-likelihood function evaluated at a <span class="math inline">\(p\)</span>-dimensional parameter vector <span class="math inline">\(\theta=(\theta_1,\dots,\theta_p)'.\)</span></p>
<p>Then the gradient vector <span class="math display">\[\nabla\ell_n(\theta')=\left(\begin{matrix}
  \dfrac{\partial \ell_n}{\partial \theta_1}(\theta')\\ \vdots\\
  \dfrac{\partial \ell_n}{\partial \theta_p}(\theta')
  \end{matrix}
  \right)
\]</span> is called the <strong>score-function</strong>.</p>
<p>The score function is <strong>random</strong>, since it depends on the random sample.</p>
<p>At the <strong>true parameter</strong> vector <span class="math inline">\(\theta_0\in\mathbb{R}^p,\)</span> the score function satisfies <span class="math display">\[
\mathbb{E}\left(\dfrac{\partial \ell_n}{\partial \theta_j}(\theta_0')\right)=0
\]</span> for all <span class="math inline">\(j=1,\dots,p.\)</span> We show this below in <a href="#sec-MLAsymp"><span>Section&nbsp;1.4</span></a>.</p>
</div>
</div>
</div>
<p>Setting the score function in <a href="#eq-LinRegScoreFun">Equation&nbsp;<span>1.4</span></a> equal to zero yields a system of <span class="math inline">\(K+1\)</span> equations with <span class="math inline">\(K+1\)</span> unknowns, and we can solve for the maximum likelihood estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML}:\)</span></p>
<p>Solving for <span class="math inline">\(\hat\beta_{ML}:\)</span> <span class="math display">\[
\begin{align*}
&amp; \dfrac{\partial \ell_n}{\partial \beta}(\hat\beta_{ML}',\hat\sigma^2_{ML}) \overset{!}{=}0\\[2ex]
\Leftrightarrow\quad&amp; - \dfrac{1}{\hat\sigma^2_{ML}}(-X'Y + X'X\hat\beta_{ML})  \overset{!}{=}0\\[2ex]
\Rightarrow\quad &amp; \hat\beta_{ML}=(X'X)^{-1}X'Y\\[2ex]
\end{align*}
\]</span> Solving for <span class="math inline">\(s^2_{ML}:\)</span> <span class="math display">\[
\begin{align*}
&amp; \dfrac{\partial \ell_n}{\partial \sigma^2}(\hat\beta_{ML}',\hat\sigma^2_{ML}) \overset{!}{=}0\\[2ex]
\Leftrightarrow\quad&amp;-\frac{n}{2 s_{ML}^2}+\left[\frac{1}{2}(Y-X\hat\beta_{ML})'(Y-X\hat\beta_{ML})\right]\frac{1}{\left(s_{ML}^2\right)^{2}}  \overset{!}{=}0\ \\[2ex]
\Rightarrow\quad  &amp;
s_{ML}^2 =\dfrac{1}{n}(Y-X\hat\beta_{ML})'(Y-X\hat\beta_{ML})\\[2ex]
&amp;\phantom{s_{ML}^2}=\dfrac{1}{n}\sum_i^n \hat\varepsilon_i^2,
\end{align*}
\]</span> where <span class="math inline">\(\hat\varepsilon_i = Y_i - X_i'\hat{\beta}_{ML}.\)</span></p>
<p>Thus, <span class="math inline">\(\hat\beta_{ML}\)</span> equals the OLS estimator <span class="math inline">\(\hat\beta.\)</span></p>
<p>Since the ML estimator <span class="math inline">\(\hat\beta_{ML}\)</span> is here equivalent to the OLS estimator we can use the classic inference machinery (<span class="math inline">\(t\)</span>-test, <span class="math inline">\(F\)</span>-test, confidence intervals) developed for the classic OLS estimator (see your econometrics class).</p>
<p>However, the ML estimator <span class="math inline">\(s_{ML}^2\)</span> for <span class="math inline">\(\sigma^2\)</span> differs from the unbiased variance estimator <span class="math inline">\(s_{UB}^2=\frac{1}{n-K}\hat{\varepsilon}_i^2.\)</span></p>
<section id="sec-varMLE" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="sec-varMLE"><span class="header-section-number">1.3.1</span> Variance of ML-Estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML}\)</span></h3>
<p>To compute the asymptotic variance of the ML-estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML},\)</span> we need</p>
<ul>
<li>compute all partial second derivatives of <span class="math inline">\(\ell_n\)</span> and then</li>
<li>take the expectation of these partial second derivatives and multiply it by <span class="math inline">\(-1/n\)</span>,</li>
</ul>
<p>which gives us the <strong>Fisher Information</strong>.</p>
<p>Let’s do this preliminary work in the following:</p>
<ol type="1">
<li><p>Partial second derivatives with respect to <span class="math inline">\(\beta:\)</span> <span class="math display">\[
\begin{align*}
\underset{(K\times 1)}{\dfrac{\partial \ell_n}{\partial \beta}(\beta',\sigma^2)}    
&amp;= - \dfrac{1}{\sigma^2}(-X'Y + X'X\beta)\\[2ex]
\Rightarrow\quad
\underset{(K\times K)}{\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta}(\beta',\sigma^2)}
&amp;= - \dfrac{1}{\sigma^2}(X'X)
\end{align*}
\]</span> <span class="math display">\[
\begin{align*}
\Rightarrow\quad
&amp;-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta}(\beta',\sigma^2)\right)\\[2ex]
&amp;=  -\frac{1}{n}\cdot \left(-\dfrac{1}{\sigma^2} \mathbb{E}(X'X)\right)\\[2ex]
&amp;=  -\frac{1}{n}\cdot \left(-\dfrac{n}{\sigma^2} \Sigma_{X'X}\right)\\[2ex]
&amp;=  \dfrac{1}{\sigma^2} \Sigma_{X'X},
\end{align*}
\]</span> where<br>
<span class="math display">\[
\mathbb{E}\left(X'X\right)
=\mathbb{E}\left(\sum_{i=1}^nX_iX_i'\right)
=n\underbrace{\mathbb{E}\left(X_iX_i'\right)}_{=:\Sigma_{X'X}} = n\Sigma_{X'X}.
\]</span></p></li>
<li><p>Second derivative with respect to <span class="math inline">\(\sigma^2:\)</span> <span class="math display">\[
\begin{align*}
\underset{(1\times 1)}{\dfrac{\partial \ell_n}{\partial \sigma^2}(\beta',\sigma^2)}
&amp;=-\frac{n}{2 \sigma^{2}}+\frac{1}{2}\frac{(Y-X\beta)'(Y-X\beta)}{\left(\sigma^{2}\right)^{2}}\\[2ex]
\Rightarrow\quad\underset{(1\times 1)}{\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta',\sigma^2)}
&amp;=\frac{n}{2 \left(\sigma^{2}\right)^2}-\dfrac{(Y-X\beta)'(Y-X\beta)}{\left(\sigma^{2}\right)^{3}} \\[2ex]
&amp;=\frac{n}{2\sigma^{4}}-\frac{\sum_{i=1}^n\varepsilon_i^2}{\sigma^{6}} \\[2ex]
\end{align*}
\]</span> <span class="math display">\[
\begin{align*}
\Rightarrow\quad
&amp;-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta',\sigma^2)\right)\\[2ex]
&amp;=-\frac{1}{n}\cdot \left(\frac{n}{2\sigma^{4}}-\frac{\mathbb{E}\left(\sum_{i=1}^n\varepsilon_i^2\right)}{\sigma^{6}} \right)\\[2ex]
&amp;=-\frac{1}{n}\cdot \left(\frac{n}{2\sigma^{4}}-\frac{n\sigma^2}{\sigma^{6}}\right)\\[2ex]
&amp;=\left(-\frac{1}{2\sigma^{4}}+\frac{1}{\sigma^{4}}\right)\\[2ex]
&amp;=\frac{1}{2\sigma^{4}}\\[2ex]
\end{align*}
\]</span></p></li>
<li><p>First derivative with respect to <span class="math inline">\(\beta,\)</span> second derivative with respect to <span class="math inline">\(\sigma^2:\)</span> <span class="math display">\[
\begin{align*}
\underset{(K\times 1)}{\dfrac{\partial \ell_n}{\partial \beta}(\beta',\sigma^2)}    
&amp;= - \dfrac{1}{\sigma^2}(-X'Y + X'X\beta)\\[2ex]
&amp;= \dfrac{1}{\sigma^2}(X')(Y - X\beta)\\[2ex]
&amp;= \dfrac{1}{\sigma^2}X'\varepsilon\\[2ex]
\end{align*}
\]</span></p></li>
</ol>
<p><span class="math display">\[
\begin{align*}
\Rightarrow\quad
\underset{(K\times 1)}{\dfrac{\partial^2 \ell_n}{\partial \beta \partial \sigma^2}(\beta',\sigma^2)}
=   \left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta',\sigma^2)\right)'
%&amp;= -\frac{X'(Y-X\beta)}{\sigma^4}\\[2ex]
&amp; = \frac{X'\varepsilon}{\sigma^4}\\
\end{align*}
\]</span> <span class="math display">\[
\begin{align*}
\Rightarrow\quad
&amp;-\frac{1}{n}\cdot  \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \sigma^2}(\beta',\sigma^2)\right)\\[2ex]
&amp;=-\frac{1}{n}\cdot\left(\mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta',\sigma^2)\right)\right)'\\[2ex]
&amp;=-\frac{1}{n}\cdot\frac{\mathbb{E}(X'\varepsilon)}{\sigma^4}\\[2ex]
&amp;=-\frac{1}{n}\cdot\frac{\mathbb{E}(\mathbb{E}(X'\varepsilon|X))}{\sigma^4}\\[2ex]
&amp;=-\frac{1}{n}\cdot\frac{\mathbb{E}(X'\mathbb{E}(\varepsilon|X))}{\sigma^4}\\[2ex]
&amp;=-\frac{1}{n}\cdot 0=0,
\end{align*}
\]</span> since <span class="math inline">\(\mathbb{E}(\varepsilon|X)=0\)</span> is an <span class="math inline">\((n\times 1)\)</span> zero vector.</p>
<p>Collecting the above results, allows us to write down the expression for <span class="math inline">\((-1/n)\)</span> times the expectation of the Hessian matrix of <span class="math inline">\(\ell_n\)</span> which yields the <strong>Fisher Information (Matrix):</strong></p>
<p><span class="math display">\[
\begin{align*}
&amp;\mathcal{I}(\theta) :=\; -\frac{1}{n}\cdot\mathbb{E}\left(H_{\ell_n}(\beta',\sigma^2)\right)\\[2ex]
&amp;=
-\frac{1}{n}\cdot \mathbb{E}
\left[\begin{array}{cc}
\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta}(\beta',\sigma^2)\right) &amp;
\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta',\sigma^2)\right)\\
\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta',\sigma^2)\right) &amp;
\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta',\sigma^2) \right)
\end{array}\right]\\[2ex]
&amp;=\left[\begin{array}{cc}
\underset{(K\times K)}{\frac{1}{\sigma^2}\Sigma_{X'X}}
&amp;
\underset{(K\times 1)}{0}\\
\underset{(1\times K)}{0} &amp;
\underset{(1\times 1)}{\frac{1}{2\sigma^4}}
\end{array}\right]
\end{align*}
\]</span></p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-FisherInformMat" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1.5 (Fisher Information Matrix) </strong></span>The matrix <span class="math display">\[
\mathcal{I}(\theta) := -\frac{1}{n}\cdot\mathbb{E}\left(H_{\ell_n}(\theta)\right)
\]</span> is called <strong>Fisher Information Matrix</strong>.</p>
</div>
</div>
</div>
<section id="asymptotic-variance-and-fisher-information-matrix" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="asymptotic-variance-and-fisher-information-matrix">Asymptotic Variance and Fisher Information Matrix</h4>
<p>The asymptotic variance of the MLE <span class="math display">\[
\hat{\theta}_{ML}=\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)
\]</span> is given by the <strong>inverse of the Fisher information matrix</strong> evaluated at the true parameter values <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\sigma^2_0.\)</span> <span class="math display">\[
\begin{align*}
&amp;AVar\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)
=\lim_{n\to\infty} n Var\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)\\[2ex]
&amp;=\left(\mathcal{I}(\beta'_0,\sigma^2_0)\right)^{-1}\\[2ex]
&amp;=\left(-\frac{1}{n}\cdot\mathbb{E}\left(H_{\ell_n}(\beta'_0,\sigma^2_0)\right)\right)^{-1}\\[2ex]
&amp;=
\left[\begin{array}{cc}
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta}(\beta'_0,\sigma^2_0)\right) &amp;
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta'_0,\sigma^2_0)\right)\\
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta'_0,\sigma^2_0)\right) &amp;
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta'_0,\sigma^2_0) \right)
\end{array}\right]^{-1}\\[2ex]
&amp;=\left[\begin{array}{cc}
\underset{(K\times K)}{\frac{1}{\sigma^2_0}\Sigma_{X'X}}
&amp;
\underset{(K\times 1)}{0}\\
\underset{(1\times K)}{0} &amp;
\underset{(1\times 1)}{\frac{1}{2\sigma^4_0}}
\end{array}\right]^{-1}\\[2ex]
&amp;=\left[\begin{array}{cc}
\underset{(K\times K)}{\sigma^2_0\Sigma_{X'X}^{-1}}
&amp;
\underset{(K\times 1)}{0}\\
\underset{(1\times K)}{0} &amp;
\underset{(1\times 1)}{2\sigma^4_0}
\end{array}\right]
\end{align*}
\]</span></p>
<!-- where $\mathcal{I}(\beta',\sigma^2)$ is called the **Fisher information matrix**. 

From our above derivations we know that
$$
\begin{align*}
&\mathcal{I}\left(\beta, \sigma^2\right)\\[2ex]
&=
\left[\begin{array}{cc}
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta}(\beta',\sigma^2)\right) & 
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta',\sigma^2)\right)\\
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta',\sigma^2)\right) & 
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta',\sigma^2) \right)
\end{array}\right]\\[2ex]
% &=
% \left[\begin{array}{cc}
% \frac{1}{\sigma^2}E(X'X) & 0 \\
% 0 & \frac{n}{2\sigma^4}
% \end{array}\right]\\[2ex]
&=
\left[\begin{array}{cc}
\dfrac{n}{\sigma^2}\Sigma_{X'X} & 0 \\[2ex]
0 & \ \dfrac{n}{2\sigma^4}
\end{array}\right],
\end{align*}
$$ -->
<p>That is, <span id="eq-FIMVar"><span class="math display">\[
\begin{align*}
AVar\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)
&amp;=\lim_{n\to\infty} n Var\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)\\[2ex]
&amp;=
\left[\begin{array}{cc}
\sigma^2_0\Sigma_{X'X}^{-1} &amp; 0 \\[2ex]
0 &amp; \ 2\sigma^4_0
\end{array}\right].
\end{align*}
\tag{1.5}\]</span></span></p>
<!-- While the upper left element of the Fisher information matrix is easily seen, the derivation of the lower right element is rather tedious and thus omitted.
[^1]: See [https://www.statlect.com/fundamentals-of-statistics/linear-regression-maximum-likelihood](https://www.statlect.com/fundamentals-of-statistics/linear-regression-maximum-likelihood) for more details. -->
<!-- Taking the inverse of the Fisher information matrix $\mathcal{I}\left(\beta, \sigma^2\right)$ gives the variance-covariance matrix of the vector of estimators $(\hat\beta_{ML}, s_{ML}^2)$
$$
\begin{align*}
Var\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right) 
& \approx \left(\mathcal{I}\left(\beta, \sigma^2\right)\right)^{-1}\\[2ex]
& =
\left[\begin{array}{cc}
\dfrac{\sigma^2}{n}\Sigma_{X'X}^{-1} & 0 \\
0 & \ \dfrac{2\sigma^4}{n}
\end{array}\right],
\end{align*}
$${#eq-FIMVar}
where the approximation error becomes small as $n\to\infty.$ That is, 
$$
n Var\left(\hat\beta_{ML}\right) \to \sigma^2\Sigma_{X'X}^{-1}\quad\text{as}\quad n\to\infty,
$$
and
$$
n Var\left(s_{ML}^2\right) \to 2\sigma^4\quad\text{as}\quad n\to\infty.
$$


Given this result, it is easy to see that 
$$
Var(\hat\beta_{ML}) \to 0\quad\text{and}\quad Var(s_{ML}^2) \to 0
$$ 
as $n\to\infty$. -->
<p>Of course, the variance expressions in <a href="#eq-FIMVar">Equation&nbsp;<span>1.5</span></a> contain unknown quantities and thus are not directly usable in practice. However, we can plug in estimates of the unknown quantities: <span class="math display">\[
s_{ML}^2                         \quad\text{for}\quad \sigma^2_0
\]</span> and <span class="math display">\[
S_{X'X}^{-1}=\left(\frac{1}{n}\sum_{i=1}^nX_i X_i'\right)^{-1} \quad \text{for}\quad \Sigma_{X'X}^{-1}.
\]</span></p>
<p>This leads to estimators of the asymptotic variances of <span class="math inline">\(\hat{\beta}_{ML}\)</span> and <span class="math inline">\(s_{ML}^2:\)</span> <span class="math display">\[
\begin{align}
\widehat{AVar}(\hat{\beta}_{ML})
&amp;=s_{ML}^2 S_{X'X}^{-1}\\[2ex]
&amp;=s_{ML}^2 \left(\frac{1}{n}\sum_{i=1}^nX_i X_i'\right)^{-1}\\[2ex]
\widehat{AVar}(s^2_{ML})
&amp;=2\left(s_{ML}^2\right)^2
\end{align}
\]</span> and thus to estimators of the variances of <span class="math inline">\(\hat{\beta}_{ML}\)</span> and <span class="math inline">\(s_{ML}^2:\)</span> <span class="math display">\[
\begin{align}
\widehat{Var}(\hat{\beta}_{ML})
=\frac{1}{n}\widehat{AVar}(\hat{\beta}_{ML})
&amp;=s_{ML}^2 \frac{1}{n}S_{X'X}^{-1}\\[2ex]
&amp;=s_{ML}^2 \left(\sum_{i=1}^nX_i X_i'\right)^{-1}\\[2ex]
\widehat{Var}(s^2_{ML})
=\frac{1}{n}\widehat{AVar}(s^2_{ML})
&amp;=\frac{1}{n}2\left(s_{ML}^2\right)^2.
\end{align}
\]</span></p>
<!-- ### Consistency of $\hat\beta_{ML}$ and $s_{ML}^2$ {#sec-MLconsistency}

If $E[\varepsilon|X]=0$ (strict exogeneity, follows from the random design (@def-RandomFixedDesign) assumption), then the bias of $\hat\beta$ is zero since $E[\hat\beta_{ML}]=\beta$
$$
\begin{align*}
E[\hat\beta_{ML}]&=E[(X'X)^{-1}X'(X\beta + \varepsilon)] \\
                 &=E[E[(X'X)^{-1}X'(X\beta + \varepsilon)|X]] \\
                 &=E[E[(X'X)^{-1}X'X\beta|X]] + E[E[(X'X)^{-1}X'\varepsilon|X]] \\
                 &=E[E[\beta|X]] + E[(X'X)^{-1}X'E[\varepsilon|X]] \\
                 &=        \beta + E[(X'X)^{-1}X'E[\varepsilon|X]] \\
                 &=        \beta  \\
\Leftrightarrow E[\hat\beta_{ML}]-\beta&=\operatorname{Bias}(\hat\beta_{ML})=0
\end{align*}
$$
Of course, from this it also follows that the squared bias is equal to zero 
$$
\text{Bias}^2(\hat\beta_{ML})=0.
$$  
This implies that the mean square error (MSE) of the ML estimator $\hat\beta_{ML}$ equals the variance of the ML estimator $\hat\beta_{ML}$: 
$$
\operatorname{MSE}(\hat\beta_{ML})=\underbrace{E[(\hat\beta_{ML}-\beta)^2]=Var(\hat\beta_{ML})}_{\text{MSE}(\hat\beta_{ML})=Var(\hat\beta_{ML})\text{ since }\hat\beta_{ML}\text{ is unbiased.}}\to 0\quad\text{as}\quad n\to\infty.
$$
Since convergence in mean square implies convergence in probability, we have established that the ML-estimator $\hat\beta_{ML}$ is a (weakly) consistent estimator of $\beta$
$$
\hat\beta_{ML}\to_p \beta\quad\text{as}\quad n\to\infty.
$$

Moreover, one can also show that $s_{ML}^2$ is a biased but *asymptotically unbiased* estimator, that is 
$$
\left(\operatorname{Bias}(s^2_{ML})\right)^2\to 0
$$ 
as $n\to\infty$. Together with the result that $Var(s^2_{ML})\to 0$ as $n\to\infty$ we have that
$$
\begin{align*}
\operatorname{MSE}(s^2_{ML})&=E[(s^2_{ML}-\sigma^2)^2]\\
&=\operatorname{Bias}^2(s^2_{ML})+Var(s^2_{ML})\to 0\quad\text{as}\quad n\to\infty.
\end{align*}
$$
Again, since convergence in mean square implies convergence in probability, we have established that the ML-estimator $s^2_{ML}$ is a (weakly) consistent estimator of $\sigma^2$
$$
s^2_{ML}\to_p \sigma^2\quad\text{as}\quad n\to\infty.
$$ -->
<!-- In practice, however, one usually works with the unbiased (and consistent) alternative $s_{UB}^2=\dfrac{1}{n-K}\sum_{i=1}^n \hat{\varepsilon}_i^2$ even though one can show that $\operatorname{MSE}(s^2_{ML})<\operatorname{MSE}(\hat\sigma^2_{UB})$ for sufficiently large $n$. -->
</section>
</section>
</section>
<section id="sec-MLAsymp" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="sec-MLAsymp"><span class="header-section-number">1.4</span> Asymptotic Theory of Maximum-Likelihood Estimators</h2>
<p>In the following, we consider the asymptotic distribution of ML-estimators.</p>
<p>We only consider the simplest situation: Assume a random sample<br>
<span class="math display">\[
X_1,\dots,X_n\overset{\text{i.i.d.}}{\sim}X,
\]</span> where <span class="math inline">\(X\in\mathbb{R}\)</span> is a univariate random variable with density function <span class="math display">\[f(x;\theta_0),
\]</span> where the true (unknown, univariate) parameter <span class="math inline">\(\theta_0\in\Theta\)</span> is an interior point of a compact parameter interval <span class="math display">\[\Theta=[\theta_l,\theta_u]\subset\mathbb{R}.
\]</span> <strong>Note:</strong> <span class="math inline">\(\theta_0\)</span> is an “interior point” of <span class="math inline">\(\Theta\)</span> if <span class="math inline">\(\theta_l&lt;\theta_0&lt;\theta_u.\)</span></p>
<p>Moreover, we consider the following setup.</p>
<ul>
<li>Likelihood function: <span class="math display">\[
\mathcal{L}_n(\theta)=\prod_{i=1}^n f(X_i;\theta)
\]</span></li>
<li>Log-likelihood function: <span class="math display">\[
\ell_n(\theta)=\ln\mathcal{L}(\theta)=\sum_{i=1}^n \ln f(X_i;\theta)
\]</span></li>
<li>Maximum-likelihood estimator <span class="math inline">\(\hat{\theta}_n\)</span> <span class="math display">\[
\hat{\theta}_n=\arg\max_{\theta\in\Theta}\ell_n(\theta)
\]</span></li>
<li>The maximum-likelihood estimator <span class="math inline">\(\hat{\theta}_n\)</span> maximizes <span class="math inline">\(\ell_n(\theta)\)</span> uniquely such that <span class="math display">\[
\left.\ell_n'(\theta)\right|_{\theta=\hat\theta_n}=0\quad\text{and}\quad\left.\ell_n''(\theta)\right|_{\theta=\hat\theta_n}&lt;0
\]</span></li>
<li>It is assumed that the partial derivatives <span class="math display">\[
\frac{\partial}{\partial\theta}f(x;\theta)\quad\text{and}\quad \frac{\partial^2}{\partial\theta^2}f(x;\theta)
\]</span> exist and that these partial derivatives can be passed under the integral such that <span class="math display">\[
\begin{align*}
\frac{\partial}{\partial\theta}\int f(x;\theta)dx
&amp;=\int\frac{\partial}{\partial\theta} f(x;\theta)dx\\
\frac{\partial^2}{\partial\theta^2}\int f(x;\theta)dx
&amp;=\int\frac{\partial^2}{\partial\theta^2} f(x;\theta)dx
\end{align*}
\]</span> for all <span class="math inline">\(\theta\in\Theta.\)</span></li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<p>An <strong>example</strong> that fits into the above setup is the density of the exponential distribution <span class="math display">\[
f(x;\theta)=\left\{
    \begin{matrix}
    \theta\exp(- \theta x)&amp; \text{for }x\geq 0\\
    0                     &amp; \text{for }x &lt; 0\\
    \end{matrix}\right.
\]</span> with unknown “rate” parameter <span class="math inline">\(\theta&gt;0.\)</span></p>
<p>Or, more generally, the densities of the one-parameter, <span class="math inline">\(\theta\in\Theta\subset\mathbb{R},\)</span> exponential family<br>
<span class="math display">\[
f(x;\theta)=h(x)\exp(\eta(\theta) T(x) - B(\theta))
\]</span> where <span class="math inline">\(h:\)</span> <span class="math inline">\(\mathbb{R}\to\mathbb{R},\)</span> <span class="math inline">\(T:\)</span> <span class="math inline">\(\mathbb{R}\to\mathbb{R},\)</span> <span class="math inline">\(\eta:\)</span> <span class="math inline">\(\Theta\to\mathbb{R},\)</span> and <span class="math inline">\(B:\)</span> <span class="math inline">\(\Theta\to\mathbb{R}.\)</span></p>
</div>
</div>
<p>The derivation of the asymptotic distribution of the ML estimator, <span class="math inline">\(\hat\theta_n,\)</span> relies on a Taylor expansion of the derivative of the log-likelihood function, <span class="math display">\[
\ell_n'(\cdot),
\]</span> around <span class="math inline">\(\theta_0\)</span> (see <a href="#eq-MVT">Equation&nbsp;<span>1.6</span></a>). To derive this expression, we use the mean value theorem (<a href="#thm-MVT">Theorem&nbsp;<span>1.2</span></a>).</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="thm-MVT" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1.2 (Mean Value Theorem) </strong></span><em>Let <span class="math inline">\(f\)</span> be continuous over the closed interval <span class="math inline">\([a,b]\)</span> and differentiable over the open interval <span class="math inline">\((a,b).\)</span> Then, there exists at least one point <span class="math inline">\(c\in(a,b)\)</span> such that</em> <span class="math display">\[
f'(c) = \frac{f(b)-f(a)}{b-a}
\]</span> <em>or equivalently</em> <span class="math display">\[
f(b)=f(a) + f'(c)(b-a).
\]</span></p>
</div>
</div>
</div>
<p>By the Mean Value Theorem (<a href="#thm-MVT">Theorem&nbsp;<span>1.2</span></a>), we know that <span id="eq-MVT"><span class="math display">\[
\ell_n'(\hat{\theta}_n)=\ell_n'(\theta_0)+\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0)
\tag{1.6}\]</span></span> for some <span class="math inline">\(\psi_n\)</span> between <span class="math inline">\(\hat{\theta}_n\)</span> and <span class="math inline">\(\theta_0;\)</span> i.e.</p>
<ul>
<li><span class="math inline">\(\psi_n\in(\theta_0,\hat{\theta}_n)\quad\)</span> if <span class="math inline">\(\quad\theta_0&lt;\hat{\theta}_n\)</span></li>
<li><span class="math inline">\(\psi_n\in(\hat{\theta}_n,\theta_0)\quad\)</span> if <span class="math inline">\(\quad\hat{\theta}_n&lt;\theta_0\)</span></li>
</ul>
<p>Note: <a href="#eq-MVT">Equation&nbsp;<span>1.6</span></a> is simply the first-order version of the mean-value form of Taylor’s theorem (<a href="#thm-TaylorThm">Theorem&nbsp;<span>1.1</span></a>).</p>
<p>Since <span class="math inline">\(\hat{\theta}_n\)</span> maximizes the log-Likelihood function it follows that <span class="math display">\[
\ell_n'(\hat{\theta}_n)=0.
\]</span> Together with <a href="#eq-MVT">Equation&nbsp;<span>1.6</span></a>, this implies that <span class="math display">\[
\overbrace{\ell_n'(\hat{\theta}_n)}^{=0}=\ell_n'(\theta_0)+\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0)
\]</span> <span id="eq-ml2"><span class="math display">\[
\Rightarrow\quad \ell_n'(\theta_0)=-\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0).
\tag{1.7}\]</span></span> Now, note that necessarily <span class="math display">\[
\int_{-\infty}^{\infty} f(x;\theta)dx=1
\]</span> for <em>all possible values</em> of <span class="math inline">\(\theta\in\Theta,\)</span> since <span class="math inline">\(f\)</span> is a density function.</p>
<p>Therefore, <span class="math display">\[
\begin{align*}
\frac{\partial}{\partial \theta}\int_{-\infty}^{\infty} f(x;\theta)dx&amp;=\frac{\partial}{\partial \theta}1 = 0,\quad\text{for all}\quad\theta\in\Theta.
\end{align*}
\]</span> Using that we can here pass the partial derivative under the integral sign, we thus have <span id="eq-zero1"><span class="math display">\[
\int_{-\infty}^{\infty} \frac{\partial}{\partial \theta}f(x;\theta)dx=0,\quad\text{for all}\quad\theta\in\Theta.
\tag{1.8}\]</span></span> And likewise, <span class="math display">\[
\begin{align*}
\frac{\partial^2}{\partial \theta^2}\int_{-\infty}^{\infty} f(x;\theta)dx&amp;=\frac{\partial^2}{\partial \theta^2}1 = 0,\quad\text{for all}\quad\theta\in\Theta.
\end{align*}
\]</span> Using again that we can here pass the partial derivative under the integral sign, we thus have <span id="eq-zero2"><span class="math display">\[
\int_{-\infty}^{\infty} \frac{\partial^2}{\partial \theta^2}f(x;\theta)dx=0,\quad\text{for all}\quad\theta\in\Theta.
\tag{1.9}\]</span></span></p>
<p>Using <a href="#eq-zero1">Equation&nbsp;<span>1.8</span></a> and <a href="#eq-zero2">Equation&nbsp;<span>1.9</span></a>, we can now show that the average <span class="math display">\[
\frac{1}{n}\ell_n'(\theta_0)=\frac{1}{n}\underbrace{\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)}_{\ell_n'(\theta_0)}
\]</span> is <strong>asymptotically normal</strong>.</p>
<p>This is done in the following by checking the three conditions for applying the Lindeberg-Lévy central limit theorem.</p>
<p>Firstly, for the mean one gets: <span id="eq-Mean"><span class="math display">\[
\begin{align*}
\mathbb{E}\left(\frac{1}{n}\ell_n'(\theta_0)\right)
&amp;=\mathbb{E}\left(\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)\right)\\[2ex]
&amp;=\frac{n}{n}\mathbb{E}\left(\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)\right)\quad[\text{i.i.d.}]\\[2ex]
&amp;=\mathbb{E}\left(\frac{\frac{\partial}{\partial \theta}f(X_i;\theta_0)}{f(X_i;\theta_0)}\right)\quad[\text{chain rule}]\\[2ex]
&amp;=\int_{-\infty}^{\infty} \frac{\frac{\partial}{\partial \theta}  f(x;\theta_0)}
{f(x;\theta_0)}f(x;\theta_0)dx\quad[\text{Def. of $\mathbb{E}$}]\\[2ex]
&amp;=\int_{-\infty}^{\infty} \frac{\partial}{\partial \theta}  f(x;\theta_0)dx\\[2ex]
&amp;=0,
\end{align*}
\tag{1.10}\]</span></span> where the last step follows from <a href="#eq-zero1">Equation&nbsp;<span>1.8</span></a>.</p>
<p>Secondly, for the variance one gets: <span class="math display">\[
\begin{align*}
Var\left(\frac{1}{n}\ell_n'(\theta_0)\right)
&amp;=Var\left(\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)\right)\\
&amp;=\frac{1}{n}Var\left(\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)\right)\quad[\text{i.i.d.}]\\
&amp;=\frac{1}{n}Var\left(\frac{\frac{\partial}{\partial \theta} f(X_i;\theta_0)}{f(X_i|\theta)}\right)\quad[\text{chain rule}]\\
&amp;=\frac{1}{n}\mathbb{E}\left(\left(\frac{\frac{\partial}{\partial \theta}  f(X_i;\theta_0)}{f(X_i;\theta_0)}\right)^2\right)\\
&amp;=:\frac{1}{n}\mathcal{I}(\theta_0),
\end{align*}
\]</span> where the simplification of the variance expression to a second moment expression follows from <a href="#eq-Mean">Equation&nbsp;<span>1.10</span></a>.</p>
<p><span class="math inline">\(\mathcal{I}(\theta_0)\)</span> is the Fisher information (here a scalar) evaluated at <span class="math inline">\(\theta_0.\)</span></p>
<p>Thirdly, the average <span class="math display">\[
\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)
\]</span> is taken over i.i.d. random variables: <span class="math display">\[
\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0),\quad i=1,\dots,n.
\]</span> Thus, we can apply the <strong>Lindeberg-Lévy central limit theorem</strong> from which it follows that <span class="math display">\[
\frac{\frac{1}{n}\ell_n'(\theta_0)-\overbrace{\mathbb{E}\left(\frac{1}{n}\ell_n'(\theta_0)\right)}^{=0}}{\sqrt{\frac{1}{n}\mathcal{I}(\theta_0)} } = \frac{\ell_n'(\theta_0)}{\sqrt{n\mathcal{I}(\theta_0)} } \to_d \mathcal{N}(0,1)
\]</span> as <span class="math inline">\(n\to\infty.\)</span></p>
<p>Thus, that by our mean value expression in <a href="#eq-ml2">Equation&nbsp;<span>1.7</span></a> <span class="math display">\[
\ell_n'(\theta_0)=-\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0)
\]</span> we thus have <span class="math display">\[
\frac{-\ell_n''(\psi_n)}{\sqrt{n \mathcal{I}(\theta_0)}}\left(\hat{\theta}_n-\theta_0\right) \to_d \mathcal{N}(0,1),
\]</span> which is equivalent to <span id="eq-MLNorm"><span class="math display">\[
\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)\;\sqrt{n}\left(\hat{\theta}_n-\theta_0\right) \to_d \mathcal{N}(0,1).
\tag{1.11}\]</span></span> The <span class="math inline">\(\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)\)</span>-part in <a href="#eq-MLNorm">Equation&nbsp;<span>1.11</span></a> is our object of interest.</p>
<p>The further analysis requires us to study the asymptotic behavior of<br>
<span class="math display">\[
-\frac{1}{n}\ell_n''(\psi_n)
\]</span> which will help us to understand the behavior of <span class="math inline">\(\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)\)</span> in <a href="#eq-MLNorm">Equation&nbsp;<span>1.11</span></a>.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before we consider <span class="math inline">\(-\frac{1}{n}\ell_n''(\psi_n),\)</span> we begin with studying the mean and the variance of the simpler statistic <span class="math display">\[
-\frac{1}{n}\ell_n''(\theta_0).
\]</span></p>
</div>
</div>
<p>First, the mean of <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0):\)</span> <span class="math display">\[
\begin{align*}
-\frac{1}{n}\ell_n''(\theta_0)
&amp;=-\frac{1}{n}\sum_{i=1}^n\frac{\partial^2}{\partial \theta\partial \theta}\ln f(X_i;\theta_0)\\[2ex]
&amp;=-\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta}\left(\frac{\partial}{\partial\theta}\ln f(X_i;\theta_0)\right)\\[2ex]
&amp;=-\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta}\left(\frac{\frac{\partial}{\partial \theta}f(X_i;\theta_0)}{f(X_i;\theta_0)}\right)\quad[\text{chain rule}]
\end{align*}
\]</span> Applying the quotient rule yields <span class="math display">\[
\begin{align*}
-\frac{1}{n}\ell_n''(\theta_0)
&amp;=-\frac{1}{n}\sum_{i=1}^n
\left(
\frac{\left(\frac{\partial^2}{\partial \theta\partial \theta}f(X_i;\theta_0)\right) f(X_i;\theta_0)-\frac{\partial}{\partial\theta}f(X_i;\theta_0)\frac{\partial}{\partial\theta} f(X_i;\theta_0)}{\left(f(X_i;\theta_0)\right)^2}\right)\\[2ex]
&amp;=-\frac{1}{n}\sum_{i=1}^n
\left(
\frac{\frac{\partial^2}{\partial \theta^2}  f(X_i;\theta_0)}
{f(X_i;\theta_0)}-\left( \frac{\frac{\partial}{\partial \theta}  f(X_i;\theta_0)}
{f(X_i;\theta_0)}\right)^2  
\right).
\end{align*}
\]</span> Taking the mean of <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0)\)</span> yields that <span class="math display">\[
\begin{align*}
\mathbb{E}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)
&amp;=\frac{n}{n}\mathbb{E}\left(-\frac{\frac{\partial^2}{\partial \theta^2}  f(X_i;\theta_0)}
{f(X_i;\theta_0)}+\left( \frac{\frac{\partial}{\partial \theta}  f(X_i;\theta_0)}
{f(X_i;\theta_0)}\right)^2\right)\quad[\text{i.i.d.}]\\[2ex]
&amp;=\frac{n}{n}\mathbb{E}\left(-\frac{\frac{\partial^2}{\partial \theta^2}  f(X_i;\theta_0)}{f(X_i;\theta_0)}\right)+\mathbb{E}\left(\left( \frac{\frac{\partial}{\partial \theta}  f(X_i;\theta_0)}
{f(X_i;\theta_0)}\right)^2\right)
\end{align*}
\]</span> From <a href="#eq-Mean">Equation&nbsp;<span>1.10</span></a>, we know that <span class="math inline">\(\mathbb{E}\left(-\frac{\frac{\partial^2}{\partial \theta^2} f(X_i;\theta_0)}{f(X_i;\theta_0)}\right)=0\)</span> thus <span class="math display">\[
\begin{align*}
\mathbb{E}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)
&amp;=0 + \mathbb{E}\left(\left( \frac{\frac{\partial}{\partial \theta}  f(X_i;\theta_0)}{f(X_i;\theta_0)}\right)^2\right)\\[2ex]
&amp;=\mathcal{I}(\theta_0),
\end{align*}
\]</span> <span class="math display">\[
\Rightarrow \qquad \mathbb{E}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)=\mathcal{I}(\theta_0)\qquad
\]</span></p>
<p>This means that <span class="math display">\[
-\frac{1}{n}\ell_n''(\theta_0)
\]</span> is an <strong>unbiased estimator</strong> of the Fisher information <span class="math inline">\(\mathcal{I}(\theta_0).\)</span> <!-- $$
\begin{align*}
\operatorname{Bias}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)
&=\mathbb{E}\left(\frac{1}{n}\ell_n''(\theta_0)\right)-\left(\mathcal{I}(\theta_0)\right)\\[2ex]
&=0. 
\end{align*}
$$ --></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Multivariate Settings
</div>
</div>
<div class="callout-body-container callout-body">
<p>For multivariate (<span class="math inline">\(p\)</span>-dimensional) parameters <span class="math inline">\(\theta_0,\)</span> the Fisher information <span class="math inline">\(\mathcal{I}(\theta_0)=(-1)\cdot \mathbb{E}\left(\ell_n''(\theta_0)\right)\)</span> becomes the (<span class="math inline">\(p\times p\)</span>) Fisher information matrix (see <a href="#sec-varMLE"><span>Section&nbsp;1.3.1</span></a>).</p>
</div>
</div>
<p>Second, the variance of variance of <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0):\)</span> <span class="math display">\[
\begin{align*}
Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)
&amp;=Var\left(-\frac{1}{n}\sum_{i=1}^n\frac{\partial^2}{\partial \theta\partial \theta}\ln f(X_i;\theta_0)\right)\\[2ex]
&amp;=\frac{n}{n^2}
\underbrace{Var\left(\frac{\partial^2}{\partial \theta \partial \theta}  \ln f(X_i;\theta_0)\right)}_{=\texttt{constant}}\\[2ex]
&amp;=\frac{1}{n}\texttt{constant},
\end{align*}
\]</span> which implies that <span class="math display">\[
Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\to 0\quad\text{as}\quad n\to\infty.
\]</span></p>
<p>With these mean and variance results for <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0),\)</span> we can write down the Mean Squared Error (MSE) of the estimator <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0)\)</span> of <span class="math inline">\(\mathcal{I}(\theta_0):\)</span> <span class="math display">\[
\begin{align*}
&amp;\operatorname{MSE}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\\[2ex]
&amp;=
\mathbb{E}\left(\left(-\frac{1}{n}\ell_n''(\theta_0) -\mathcal{I}(\theta_0)\right)^2\right)\\[2ex]
&amp;=\underbrace{\left(\operatorname{Bias}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\right)^2}_{=0}+Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\\[3ex]
&amp;=Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\to 0\quad\text{as}\quad n\to\infty.
\end{align*}
\]</span></p>
<p>That is, the estimator <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0)\)</span> is a <strong>mean square consistent</strong> estimator, i.e. <span class="math display">\[
-\frac{1}{n}\ell_n''(\theta_0)\to_{m.s.} \mathcal{I}(\theta_0)\quad \hbox{as}\quad n\to\infty,
\]</span> which implies that <span class="math inline">\(\frac{1}{n}\ell_n''(\theta_0)\)</span> is also a <strong>(weakly) consistent</strong> estimator, i.e.&nbsp; <span class="math display">\[
-\frac{1}{n}\ell_n''(\theta_0)\to_p \mathcal{I}(\theta_0)\quad \hbox{as}\quad n\to\infty,
\]</span> since mean square convergence implies convergence in probability.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>🤔 Remember, we wanted to study <span class="math inline">\(-\frac{1}{n}\ell_n''(\psi_n)\)</span> in <a href="#eq-MLNorm">Equation&nbsp;<span>1.11</span></a> <strong>not</strong> <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0).\)</span> Studying <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0)\)</span> was only the simpler thing to do.</p>
<p>Luckily, we are actually close now.</p>
</div>
</div>
<p>Next, we use that ML estimators <span class="math inline">\(\hat\theta_n\)</span> are (weakly) <strong>consistent</strong>, i.e., <span class="math display">\[
\hat\theta_n\to_p\theta_0\quad\text{as}\quad n\to\infty;
\]</span> this is, for instance, implied by our results in <a href="#sec-LinRegNorm"><span>Section&nbsp;1.3</span></a> for the case of ML estimation in linear regression under normality.</p>
<p>Since <span class="math inline">\(\psi_n\)</span> is a <strong>mean value</strong> between <span class="math inline">\(\theta_0\)</span> and <span class="math inline">\(\hat{\theta}_n\)</span> (<a href="#eq-MVT">Equation&nbsp;<span>1.6</span></a>), consistency of <span class="math inline">\(\hat{\theta}_n\)</span> implies that <span class="math display">\[
\psi_n\to_p\theta_0\quad\text{as}\quad n\to\infty.
\]</span></p>
<p>Therefore, we have by the <strong>continuous mapping theorem</strong> that <span class="math display">\[
\begin{align}
-\frac{1}{n}\ell_n''(\psi_n) &amp; \to_p \phantom{-}\mathcal{I}(\theta_0)\quad \hbox{ as }\quad n\to\infty\\[2ex]
\Rightarrow\qquad
\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)&amp;\to_p \sqrt{\mathcal{I}(\theta_0)} \quad \hbox{ as }\quad n\to\infty.
\end{align}
\]</span></p>
<p>Now, using <strong>Slutsky’s theorem</strong>, we can connect the above consistency result with the asymptotic normality result in <a href="#eq-MLNorm">Equation&nbsp;<span>1.11</span></a> such that <span class="math display">\[
\begin{align*}
\underbrace{\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)}_{\to_p \sqrt{\mathcal{I}(\theta_0)} }\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)\to_d\mathcal{N}(0,1)
\end{align*}
\]</span> or equivalently <span id="eq-AsymNormMLE"><span class="math display">\[
\begin{align*}
\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)\to_d N\left(0,\frac{1}{\mathcal{I}(\theta_0)}\right),
\end{align*}
\tag{1.12}\]</span></span> where <span class="math inline">\(1/\mathcal{I}(\theta_0)\)</span> is the <strong>asymptotic variance</strong> of the ML estimator <span class="math inline">\(\hat{\theta}_n\)</span> and equals the inverse of the (here scalar valued) Fisher information <span class="math display">\[
\mathcal{I}(\theta_0)=-\frac{1}{n}\mathbb{E}(\ell_n''(\theta_0)).
\]</span></p>
<p><a href="#eq-AsymNormMLE">Equation&nbsp;<span>1.12</span></a> is the asymptotic normality result we aimed for.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Multivariate Settings
</div>
</div>
<div class="callout-body-container callout-body">
<p>The above arguments can easily be generalized to multivariate (<span class="math inline">\(p\)</span>-dimensional) parameter vectors <span class="math inline">\(\theta\in\mathbb{R}^p\)</span>. In this case, <span class="math inline">\(\mathcal{I}(\theta_0)\)</span> becomes a <span class="math inline">\(p\times p\)</span> matrix, and <span class="math display">\[
\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)\to_d \mathcal{N}_p\left(0, \mathcal{I}(\theta_0)^{-1}\right),
\]</span> where <span class="math inline">\(\mathcal{I}(\theta_0)=-\frac{1}{n}\mathbb{E}\left(H_{\ell_n}(\theta_0)\right)\)</span> is the <span class="math inline">\((p\times p)\)</span> Fisher information matrix with <span class="math inline">\(H_{\ell_n}(\theta_0)\)</span> denoting the Hesse matrix of <span class="math inline">\(\ell_n(\cdot)\)</span> evaluated at <span class="math inline">\(\theta_0.\)</span></p>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
ML-Theory and Machine learning
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Fisher information is used in machine learning techniques such as elastic weight consolidation, which reduces catastrophic forgetting in artificial neural networks (<span class="citation" data-cites="Kirkpatrick_2017">Kirkpatrick et al. (<a href="#ref-Kirkpatrick_2017" role="doc-biblioref">2017</a>)</span>).</p>
<p>Fisher information can be used as an alternative to the Hessian of the loss function in second-order gradient descent network training (<span class="citation" data-cites="Martens_2020">Martens (<a href="#ref-Martens_2020" role="doc-biblioref">2020</a>)</span>).</p>
</div>
</div>
</section>
<section id="equivariance-property-of-the-ml-estimator" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="equivariance-property-of-the-ml-estimator"><span class="header-section-number">1.5</span> Equivariance Property of the ML-Estimator</h2>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="thm-EVP" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1.3 (Equivariance (or Invariance) Property of the ML-Estimator) </strong></span>Let <span class="math display">\[
\tau_0=g(\theta_0),
\]</span> where <span class="math inline">\(g(\theta)\)</span> is a <strong>one-to-one (or injective) function</strong> of <span class="math inline">\(\theta\in\Theta;\)</span> i.e.&nbsp;<span class="math inline">\(g\)</span> maps distinct elements of its domain to distinct elements such that the outputs never repeat. (One-to-one functions are invertible.)</p>
<p>Let <span class="math inline">\(\hat{\theta}_{n}\)</span> be the maximum likelihood estimator of <span class="math inline">\(\theta_0.\)</span></p>
<p>Then <span class="math display">\[
\hat{\tau}_{n} = g\left(\hat{\theta}_{n}\right)
\]</span> is the maximum likelihood estimator of <span class="math inline">\(\tau_0.\)</span></p>
</div>
</div>
</div>
<p><strong>Proof of <a href="#thm-EVP">Theorem&nbsp;<span>1.3</span></a>:</strong></p>
<p>Since <span class="math inline">\(g\)</span> is a one-to-one function, it possesses an inverse <span class="math inline">\(g^{-1}.\)</span></p>
<p>Thus <span class="math display">\[
\hat{\theta}_{n} = g^{-1}(\hat{\tau}_{n})
\]</span> and <span class="math display">\[
\theta = g^{-1}(\tau)\quad\text{for all}\quad\theta\in\Theta.
\]</span> This allows us to express the likelihood function <span class="math inline">\(\mathcal{L}_n(\theta)\)</span> used for estimating <span class="math inline">\(\theta_0\)</span> in terms of a likelihood function <span class="math inline">\(\tilde{\mathcal{L}}_n(\tau)\)</span> in <span class="math inline">\(\tau\)</span>: <span class="math display">\[
\mathcal{L}_n(\theta) = \mathcal{L}_n(g^{-1}(\tau)) = \tilde{\mathcal{L}}_n(\tau).
\]</span> for all <span class="math inline">\(\theta\in\Theta.\)</span> At <span class="math inline">\(\hat{\theta}_n\)</span> we thus have <span class="math display">\[
\mathcal{L}_n(\hat{\theta}_n) = \mathcal{L}_n(\overbrace{g^{-1}(\hat{\tau}_n)}^{=\hat{\theta}_n})=\tilde{\mathcal{L}}_n(\hat{\tau}_n).
\]</span> To show now that <span class="math inline">\(\hat\tau\)</span> is the maximum likelihood estimator of <span class="math inline">\(\tau_0,\)</span> we need to show that <span class="math display">\[
\tilde{\mathcal{L}}_n(\tau)\leq\tilde{\mathcal{L}}_n(\hat\tau_n)\quad\text{for all}\quad\tau.
\]</span></p>
<p>Since <span class="math inline">\(\hat\theta_n\)</span> denotes the ML estimator of <span class="math inline">\(\theta_0,\)</span> we know that <span class="math display">\[
\mathcal{L}_n(\theta)\leq\mathcal{L}_n(\hat\theta_n)\quad\text{for all}\quad\theta\in\Theta.
\]</span> But since for any <span class="math inline">\(\tau=g(\theta)\)</span> <span class="math display">\[
\tilde{\mathcal{L}}(\tau)   = \mathcal{L}(\theta)
\leq
\mathcal{L}(\hat{\theta}_n) = \tilde{\mathcal{L}}(\hat{\tau}_{n}),
\]</span> we know also that <span class="math display">\[
\tilde{\mathcal{L}}_n(\tau)\leq\tilde{\mathcal{L}}_n(\hat\tau_n)\quad\text{for all}\quad\tau;
\]</span> i.e., <span class="math inline">\(\hat{\tau}_n\)</span> is indeed a maximum likelihood estimator of <span class="math inline">\(\tau_0.\)</span></p>
<!-- The likelihood function with respect to $\tau$ can be expressed the likelihood function with respect to $\theta = h(\tau)\in\Theta,$ i.e. 
$$
\begin{align*}
\tilde{\mathcal{L}}(\tau) = \mathcal{L}(h(\tau)) 
& = \prod_{i=1}^n f(X_{i,obs}|h(\tau))\\[2ex]
& = \prod_{i=1}^n f(X_{i,obs}|\theta)  = \mathcal{L}(\theta).
\end{align*}
$$
Thus
$$
\begin{align*}
\tilde{\mathcal{L}}(\hat{\tau}_{n})
%&= \mathcal{L}(h(\hat{\tau}_{n}))\\[2ex]
&= \mathcal{L}(\hat{\theta}_n)
\end{align*}
$$
and for any $\tau$
$$
\tilde{\mathcal{L}}(\tau)   = \mathcal{L}(\theta) 
\leq 
\mathcal{L}(\hat{\theta}_n) = \tilde{\mathcal{L}}(\hat{\tau}_{n}),
$$
which shows the statement of @thm-EVP:
$$
\hat{\tau}_n=\arg\max_\tau\tilde{\mathcal{L}}(\tau).
$$ -->
</section>
<section id="exercises" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="exercises">Exercises</h2>
<section id="exercise-1." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="exercise-1.">Exercise 1.</h4>
<p>Program the Newton-Raphson algorithm for a numerical computation of the ML estimate <span class="math inline">\(\hat\theta\)</span> of the parameter <span class="math inline">\(\theta=P(\text{Coin}=\texttt{HEAD})\)</span> in our coin toss example of this chapter. Replicate the results shown in <a href="#tbl-NR">Table&nbsp;<span>1.1</span></a>.</p>
</section>
<section id="exercise-2." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="exercise-2.">Exercise 2.</h4>
<p>Assume an i.i.d. random sample <span class="math inline">\(X_1,\dots,X_n\)</span> from an exponential distribution, i.e.&nbsp;the underlying density of <span class="math inline">\(X_i\)</span> is given by <span class="math display">\[
f(x;\theta_0)=
\left\{\begin{array}{ll}\theta_0\exp(-\theta_0 x),&amp;x\geq 0\\0,&amp;x&lt;0\end{array}\right.
\]</span> with <span class="math inline">\(\theta_0&gt;0,\)</span> where <span class="math display">\[
\mu:=\mathbb{E}(X_i)=\frac{1}{\theta_0}
\]</span> and <span class="math display">\[
Var(X_i)=\frac{1}{\theta_0^2}.
\]</span></p>
<ol type="a">
<li>What is the log-likelihood function for the i.i.d. random sample <span class="math inline">\(X_1,\dots,X_n\)</span>?</li>
<li>Derive the maximum likelihood (ML) estimator <span class="math inline">\(\hat\theta_n\)</span> of <span class="math inline">\(\theta_0.\)</span></li>
<li>From maximum likelihood theory we know that <span class="math display">\[
\sqrt{n}(\hat\theta_n-\theta_0)\to_d \mathcal{N}\left(0,\frac{1}{\mathcal{I}(\theta_0)}\right).
\]</span> Derive the expression for the Fischer information <span class="math inline">\(\mathcal{I}(\theta_0).\)</span> Use the Fisher information to give the <em>explicit</em> formula for the asymptotic distribution of <span class="math inline">\(\hat\theta_n\)</span>.</li>
</ol>
</section>
<section id="exercise-3." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="exercise-3.">Exercise 3.</h4>
<!-- From All of Statistics p 151 -->
<p>Let <span class="math inline">\(X_1,\dots,X_n\overset{\text{i.i.d.}}{\sim}X\)</span> with <span class="math inline">\(X\sim\mathcal{Unif}(0,\theta_0).\)</span></p>
<ol type="a">
<li><p>What is the likelihood function?</p></li>
<li><p>What is the maximum likelihood estimator of <span class="math inline">\(\theta_0\)</span>?</p></li>
</ol>
</section>
<section id="exercise-4." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="exercise-4.">Exercise 4.</h4>
<p>Let <span class="math inline">\(X_1,\dots,X_n\overset{\text{i.i.d.}}{\sim}X\)</span> with <span class="math inline">\(X\sim\mathcal{Poisson}(\lambda_0).\)</span> That is <span class="math inline">\(X\sim f\)</span> with density function <span class="math display">\[
f(x|\lambda_0) = \frac{\lambda_0^x \exp(-\lambda_0)}{x!}.
\]</span></p>
<ol type="a">
<li><p>Find the maximum likelihood estimator, <span class="math inline">\(\hat{\lambda},\)</span> of <span class="math inline">\(\lambda_0.\)</span></p></li>
<li><p>Let <span class="math inline">\(0&lt;\lambda_0\leq 4.\)</span> Find the maximum likelihood estimator, <span class="math inline">\(\hat{P}(X=4),\)</span> of <span class="math inline">\(P(X=4).\)</span></p></li>
</ol>
</section>
<section id="exercise-5." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="exercise-5.">Exercise 5.</h4>
<p>Show that the Newton-Raphson algorithm converges under the setup outlined in <a href="#sec-ConvNR"><span>Section&nbsp;1.2.2</span></a>.</p>
<p><strong>Tip:</strong> Use the first-order Taylor expansion of <span class="math inline">\(\ell'(\theta_{root})\)</span> around <span class="math inline">\(\theta_{(m)}\)</span> with <strong>explicit reminder</strong> term <span class="math inline">\(R\)</span> given by <span class="math display">\[
\begin{align*}
\overset{\theta_{(m)}+(\theta_{root}-\theta_{(m)})}{\ell'\big(\;\overbrace{\theta_{root}}\;\big)}
&amp; = \ell'(\theta_{(m)}) + \ell''(\theta_{(m)})(\theta_{root}-\theta_{(m)}) + R,
\end{align*}
\]</span> where <span class="math display">\[
R=\frac{1}{2}\ell'''(\xi_{(m)})(\theta_{root}-\theta_{(m)})^2
\]</span> for a mean-value <span class="math inline">\(\xi_{(m)}\)</span> between <span class="math inline">\(\theta_{(m)}\)</span> and <span class="math inline">\(\theta_{root}\)</span>. This is called the Lagrange form of the Taylor-Series reminder term and follows from the Mean-Value Theorem <a href="#thm-MVT">Theorem&nbsp;<span>1.2</span></a>.</p>
<!-- {{< include Ch1_MaximumLikelihood_Solutions.qmd >}} -->
</section>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>
<!-- **Example::** Assume an i.i.d. sample $X_1,\dots,X_n$ from an exponential distribution, i.e. the underlying density of $X_i$ is given by $f(x;\theta)=\theta\exp(-\theta x)$. We then have $\mu:=E(X_i)=\frac{1}{\theta}$ as well as $\sigma^2_X:=\textrm{var}(X_i)=\frac{1}{\theta^2}$. The -->
<!-- log-likelihood functions is given by  -->
<!-- $$l(\theta)=\sum_{i=1}^n \ln (\theta\exp(-\theta X_i)))=n \ln \theta -\sum_{i=1}^n \theta X_i$$ -->
<!-- $$\Rightarrow \quad \ell_n'(\theta)=n\frac{1}{\theta} + \sum_{i=1}^n X_i.$$ -->
<!-- As already mentioned above, the maximum-likelihood estimator of $\theta$ then is $\hat\theta_n=\frac{1}{\bar X}$. -->
<!-- Inference may then be based on likelihood-theory. We have -->
<!-- $$\mathcal{J}(\theta)=-\frac{1}{n}E(\ell''(\theta))=\frac{1}{\theta^2},$$ -->
<!-- and by the above theorem -->
<!-- $$\frac{1}{\bar X}-\theta\sim AN(0,\frac{1}{n \mathcal{J}(\theta)})\overset{a}{\sim}AN(0,\frac{\theta^2}{n}).$$ -->
<!-- This obviously coincides with the result obtained by the delta-method. -->
<!-- ## Discussion of Assumptions and Results {-} -->
<!-- \begin{itemize} -->
<!-- \item **Strict exogeneity**:  Needed to assume $\E[\varepsilon | X]=0$ to show consistency of $\hat\beta_{ML}$.  -->
<!-- \item **Homoskedasticity and non-autocorrelation**:  We used the assumption that $\E[\varepsilon eps']\sim(0, \sigma^2 I)$ to derive estimator of $\sigma^2$.   -->
<!-- \item **Normality**:  The normality assumption is used **only** to derive small-sample properties of the estimators. By using asymptotic arguments one can show that both $\hat\beta_{ML}$ and $s_{ML}^2$ will be distributed -->
<!-- asymptotically normally also without the normality assumption. -->
<!-- \end{itemize} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Best Linear Unbiased Estimator} -->
<!-- Given our assumptions, then by the Gauss-Markov theorem, it is possible to show that  -->
<!-- \begin{itemize}  -->
<!-- \item<1->$\hat\beta$ is the Best Linear Unbiased (BLUE) estimator of $\beta$ -->
<!-- \item<2-> The best linear unbiased estimator of any linear combination of the $\beta$'s is the same linear combination -->
<!-- of the $\hat\beta$'s. -->
<!-- \item<3-> The Best Linear Unbiased Predictor (BLUP) of $Y$ based on the vector $X_s$ is $\hat y_s=X'_s\hat\beta$ -->
<!-- \end{itemize} -->
<!-- \end{frame} -->
<!-- ## Hypothesis Testing -->
<!-- ### Testing Hypotheses about One Parameter -->
<!-- \noindent**Definition of the Score** -->
<!-- Define the **score of the log likelihood** (also known as the **gradient vector** -->
<!-- for observation $i$ -->
<!-- \begin{equation*} -->
<!-- s_i(\beta)\equiv \left(\dfrac{\partial L_i}{\partial \beta_0}(\beta), \dfrac{\partial L_i}{\partial \beta_1}(\beta), \dots, \dfrac{\partial L_i}{\partial \beta_k}(\beta)\right)' -->
<!-- \end{equation*} -->
<!-- %In the logit and probit cases, this can be shown to be -->
<!-- %\begin{equation*} -->
<!-- %s_i(\beta)\equiv\dfrac{g(x_i\beta)[y_i-G(x_i\beta)]} -->
<!-- %{G(x_i\beta)[1-G(x_i\beta)]}x_i' -->
<!-- %\end{equation*} -->
<!-- %Since $x_i$ is $1 \times (k+1)$, the score is a $(k+1) \times 1$ vector.  Recalling that in the probit %case -->
<!-- %\begin{center} -->
<!-- %$g(z)=\phi(z)$ and $G(z)=\Phi(z)$ -->
<!-- %\end{center} -->
<!-- %while with logit -->
<!-- %\begin{center} -->
<!-- %$g(z)=\exp(z)/[1+\exp(z)]^2$ and $G(z)=\exp(z)/[1+\exp(z)]$. -->
<!-- %\end{center} -->
<!-- #### Variance-Covariance Matrix {-} -->
<!-- Using the standard maximum likelihood theory it can be -->
<!-- show that the asymptotic-variance covariance matrix of the MLE $\hat\beta_{ML}$ is given by -->
<!-- \begin{equation*} -->
<!-- \text{Asy.~Var}(\hat\beta_{ML})=\left[\sum_{i=1}^N s_i(\hat\beta)s_i(\hat\beta)'\right]^{-1} -->
<!-- \end{equation*} -->
<!-- %and therefore in our case we have -->
<!-- %\begin{equation*} -->
<!-- %\text{Asy. Var-Cov}(\hat\beta)=\left[\sum_{i=1}^N\dfrac{[g(x_i\hat\beta)]^2 x_i' x_i}{G(x_i\hat\beta) -->
<!-- %[1-G(x_i\hat\beta)]}\right]^{-1} -->
<!-- %\end{equation*} -->
<!-- %with $g(\cdot)$ and $G(\cdot)$ defined as above. -->
<!-- %\vskip .1in -->
<!-- The square roots of the diagonals of this matrix will give us the -->
<!-- **standard errors** of the estimates. -->
<!-- \frametitle{Cramer-Rao Lower Bound} -->
<!-- Fisher, Cramer, and Rao showed that for any unbiased estimator $\hat\theta$, its variance-covariance -->
<!-- matrix cannot be smaller than $I^{-1}(\theta)$ where $I(\theta)$ is the **information matrix** -->
<!-- of the estimator, given by  -->
<!-- $$I(\theta) \equiv E[s(y,\theta)s(y,\theta)']$$ -->
<!-- where $s(\cdot)$ is the gradient or score.  Thus, the MLE attains the Cramer-Rao lower bound and will therefore be asymptotically efficient. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Asymptotic Distribution} -->
<!-- Now, by the usual asymptotic theory, we have -->
<!-- \begin{equation*} -->
<!-- \dfrac{\hat\beta_j - \beta_j^0}{\text{std. err.}(\hat\beta_j)}\stackrel{a}{\sim} \mathcal{N}(0,1) -->
<!-- \end{equation*} -->
<!-- where $\beta_j^0$ is the value of the parameter under the null hypothesis. -->
<!-- So, we can do our usual "$t$-tests" although because we rely on asymptotics, -->
<!-- they should probably be more properly called $z$-tests. -->
<!-- \end{frame} -->
<!-- \subsection{Testing Hypotheses about Multiple Parameters} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Testing Joint Hypotheses} -->
<!-- We may also want to test hypotheses about multiple parameters.  Here it will -->
<!-- be useful to think about the regressions implied by imposing the restrictions. -->
<!-- So, for example,  -->
<!-- \begin{equation*} -->
<!-- \begin{array}{ll} -->
<!-- H_0: & R\beta - r = 0\\ -->
<!-- H_A: & H_0 \text{ is not true} \\ -->
<!-- \end{array} -->
<!-- \end{equation*} -->
<!-- where $R$ is a $q \times (k+1)$ matrix that defines the $q$ restrictions placed on the parameters -->
<!-- under the null hypothesis and $r$ is a $q \times 1$ vector of constants. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Restricted and Unrestricted Regressions} -->
<!-- We will define the **restricted regression** as one in which we force -->
<!-- the $R\hat\beta$ to be equal to  -->
<!-- $r$ (i.e. under the null hypothesis), and the -->
<!-- **unrestricted regression** to be one in which we allow the data to tell -->
<!-- us what the values of $\beta$ should be. -->
<!-- \vskip .2in -->
<!-- Define $L_r$ as the log-likelihood corresponding to the restricted regeression -->
<!-- and $L_u$ as the log-likelihood corresponding to the unrestricted regression. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Three Asymptotically Equivalent Tests} -->
<!-- We will discuss three asymptotically equivalent tests: -->
<!-- \begin{itemize} -->
<!-- \item **Wald test**: based on the unrestricted regression -->
<!-- \item **Likelihood ratio test**: based on both the restricted and unrestrcited regressions -->
<!-- \item **Lagrange multiplier test**: based on the restricted regression. -->
<!-- \end{itemize} -->
<!-- All three tests will give us the same answer asymptotically, but will differ -->
<!-- in their values in finite samples. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Wald Test (1)} -->
<!-- From maximum likelihood theory, we know that  -->
<!-- \begin{equation*} -->
<!-- \hat\beta \adist \mathcal{N}(\beta,V) -->
<!-- \end{equation*} -->
<!-- and therefore that $R\hat\beta$ also has an asymptotically normal distribution -->
<!-- (since it is just a linear combination of asymptotically normal variables): -->
<!-- \begin{equation*} -->
<!-- (R\hat\beta - R\beta) \adist \mathcal{N}(0, RVR') -->
<!-- \end{equation*} -->
<!-- This suggests a quadratic form which we can use to test hypotheses -->
<!-- \begin{equation*} -->
<!-- W\equiv(R\hat\beta - r)'[R \hat V_u R']^{-1}(R\hat\beta - r) \adist \chi_q^2 -->
<!-- \end{equation*} -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Wald Test (2)} -->
<!-- Thus, with the **Wald test**, we need only estimate the *unrestricted* regression. -->
<!-- \vskip .25in -->
<!-- It measures how far apart the estimated parameters are from the values of  -->
<!-- the parameters under the null hypothesis. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Likelihood Ratio Test} -->
<!-- More conceptually simple, perhaps, is the **Likelihood Ratio Test**. -->
<!-- \vskip .15in -->
<!-- If the null hypothesis holds, imposing restrictions on the data should lead -->
<!-- to values of $L_r$ and $L_u$ that are ``close''.  The question then, is what -->
<!-- metric to use to judget how ``close '' they are. -->
<!-- \vskip .15in -->
<!-- It can be shown that -->
<!-- \begin{equation*} -->
<!-- LR\equiv -2 [L_r - L_u] \adist \chi^2_q -->
<!-- \end{equation*} -->
<!-- Therefore the $\chi^2_q$ distribution is the proper metric for judging how close -->
<!-- the likelihoods are. -->
<!-- \vskip .15in -->
<!-- We must fit both models to calculate the differences between the restricted -->
<!-- and restricted likelihoods. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Motivation} -->
<!-- The **Lagrange Multiplier Test** (also called the **Score Test**) is based -->
<!-- on the score, or gradient, vector (as defined earlier).  The idea is to measure -->
<!-- how far away from the peak of the *unrestricted* likelihood imposing the -->
<!-- restrctions forces us, which is some akin to the notion of the likelihood ratio -->
<!-- test.  -->
<!-- \vskip.15in -->
<!-- At the peak of the unrestricted log likelihood, the score would be a vector of -->
<!-- zeros.  Intuitively, then, the Lagrante Multiplier Test will measure how ``close'' -->
<!-- the score vector when we estimate the *restricted* regression is to  -->
<!-- the vector of zeroes. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Derivation (1)} -->
<!-- We can think about finding the maximum of the log likelihood subject to -->
<!-- the constraints imposed by the null hypothesis.  To simplify things, suppose we have only two -->
<!-- parameters, $\beta_1$ and $\beta_2$ with $H_0: \beta_2=c$. -->
<!-- Then: -->
<!-- \begin{equation*} -->
<!-- H(\beta, \lambda)=\sum_{i=1}^N  L_i(\beta) - \lambda'(\beta_2-c) -->
<!-- \end{equation*} -->
<!-- where $\lambda$ is the Lagrange multiplier.  Then the first order conditions -->
<!-- are -->
<!-- \begin{align*} -->
<!-- \sum_{i=1}^N  \dfrac{\partial L_i (\beta)}{\partial \beta_1} \big\vert_{\tilde\beta} -->
<!-- &=\sum_{i=1}^N s_{i1}(\tilde\beta)=0\\ -->
<!-- \tilde\lambda=\sum_{i=1}^N \dfrac{\partial L_i (\beta)}{\partial \beta_1} \big\vert_{\tilde\beta} &=\sum_{i=1}^N s_{i2}(\tilde\beta)\\ -->
<!-- \end{align*} -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Derivation (2)} -->
<!-- Define $s_{i1}$ and $s_{i2}$ are the subvectors of $s_i(\beta)$ corresponding to  -->
<!-- $\beta_1$ and $\beta_2$, respectively. -->
<!-- \vskip .15in -->
<!-- So we are in some sense testing whether $\tilde\lambda$ is ``close'' to zero or -->
<!-- not, evaluated at the restricted values of the parameters. -->
<!-- \vskip .15in -->
<!-- It's possible to show, then, that -->
<!-- \begin{equation*} -->
<!-- LM\equiv  s'(\tilde\beta) \tilde V_r^{-1} s(\tilde\beta) \adist \chi^2_q -->
<!-- \end{equation*} -->
<!-- where $s(\tilde\beta)$ is the score evaluated at the *restricted* estimates of -->
<!-- the parameters, and $\tilde V_r$ is the estimated variance-covariance matrix from the *restricted* regression. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Relationshiop between W, LR, and LM tests} -->
<!-- \includegraphics[angle=90, scale=.60]{wald-lm-lr.ps} -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Relationship between W, LR, and LM} -->
<!-- While all three tests are asymptotically equivalent, it can be shown that in finite -->
<!-- samples -->
<!-- \begin{center} -->
<!-- $LM < LR < W$ -->
<!-- \end{center} -->
<!-- meaning that LM tests will favor not rejecting the null and W tests will favor rejecting -->
<!-- the null. -->
<!-- \end{frame} -->
<!-- \end{document} -->
<!-- \section{Goodness of Fit Measures} -->
<!-- \subsection{Goodness of Fit Measures} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Goodness of Fit in Probit and Logit} -->
<!-- As in the linear regression model, we would like to have some measure -->
<!-- of how well our model fits the data.  Unlike linear models, however, where -->
<!-- $R^2$ serves as the primary goodness-of-fit measure, there is no -->
<!-- standard metric that is used. -->
<!-- \vskip .15in -->
<!-- Now, define $L_0$ as the log likelihood of a model in which we constrain -->
<!-- all of the coefficients (except the constant) to be equal to zero. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- %------------------------------------------------- -->
<!-- %\begin{frame} -->
<!-- %\frametitle{A Note on $L_0$} -->
<!-- %Note that we do not actually need to run a  regression to estimate $L_0$. -->
<!-- %\vskip .15in -->
<!-- %With just a constant term in the model, the likelihood function is given by -->
<!-- %\begin{align*} -->
<!-- %L_0&=\sum y_i \ln(N_1/N) + \sum (1-y_i) \ln(1-N_1/N)\\ -->
<!--  %    &=N_1 \ln(N_1/N) + N_0\ln(N_0/N)\\ -->
<!-- %\end{align*} -->
<!-- %where $N_1$ indicates the number of success and $N_0$ is the number of failures. -->
<!-- %\end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Pseudo-$R^2$} -->
<!-- The first goodness-of-fit measure is meant as an analog to the $R^2$ from -->
<!-- linear regression, called the pseudo-$R^2$.  It is defined as -->
<!-- \begin{equation*} -->
<!-- \text{pseudo}-R^2=1-\dfrac{1}{1+2(L_u - L_0)/N} -->
<!-- \end{equation*} -->
<!-- Intuitively, the greater the distance between the restricted and -->
<!-- unrestricted log likelihoods, the more the model explains the variation -->
<!-- in $y$, and the greater the pseudo-$R^2$ will be. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{McFadden's $R^2$} -->
<!-- McFadden suggested an alternative goodness of fit-measures: -->
<!-- \begin{equation*} -->
<!-- \text{McFadden}-R^2= 1- L_u/L_0 -->
<!-- \end{equation*} -->
<!-- since the log likelihood is just the sum of log probabilities, it must be that -->
<!-- $L_0 < L_u < 0$. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- %\begin{frame} -->
<!-- %\frametitle{Proportion of Correct Predictions} -->
<!-- %An additional measure of the fit of the model is the number of observations for -->
<!-- %which the model correctly predicts the outcome. -->
<!-- %\end{frame} -->


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Kirkpatrick_2017" class="csl-entry" role="doc-biblioentry">
Kirkpatrick, James, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, et al. 2017. <span>“Overcoming Catastrophic Forgetting in Neural Networks.”</span> <em>Proceedings of the National Academy of Sciences</em> 114 (13): 3521–26.
</div>
<div id="ref-Martens_2020" class="csl-entry" role="doc-biblioentry">
Martens, James. 2020. <span>“New Insights and Perspectives on the Natural Gradient Method.”</span> <em>The Journal of Machine Learning Research</em> 21 (1): 5776–5851.
</div>
<div id="ref-White1982" class="csl-entry" role="doc-biblioentry">
White, Halbert. 1982. <span>“Maximum Likelihood Estimation of Misspecified Models.”</span> <em>Econometrica</em>, 1–25.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Organization of the Course</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Ch2_EMAlgorithmus.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">EM Algorithm &amp; Cluster Analysis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>